<html><head><title>niplav</title>
<link href="./favicon.png" rel="shortcut icon" type="image/png">
<link href="main.css" rel="stylesheet" type="text/css">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">


<style type="text/css">
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
</style>
<script>
document.addEventListener('DOMContentLoaded', function () {
	// Change the title to the h1 header
	var title = document.querySelector('h1')
	if(title) {
		var title_elem = document.querySelector('title')
		title_elem.textContent=title.textContent + " â€“ niplav"
	}
});
</script>
<style type="text/css">
                            .mjpage .MJX-monospace {
                            font-family: monospace
                            }

                            .mjpage .MJX-sans-serif {
                            font-family: sans-serif
                            }

                            .mjpage {
                            display: inline;
                            font-style: normal;
                            font-weight: normal;
                            line-height: normal;
                            font-size: 100%;
                            font-size-adjust: none;
                            text-indent: 0;
                            text-align: left;
                            text-transform: none;
                            letter-spacing: normal;
                            word-spacing: normal;
                            word-wrap: normal;
                            white-space: nowrap;
                            float: none;
                            direction: ltr;
                            max-width: none;
                            max-height: none;
                            min-width: 0;
                            min-height: 0;
                            border: 0;
                            padding: 0;
                            margin: 0
                            }

                            .mjpage * {
                            transition: none;
                            -webkit-transition: none;
                            -moz-transition: none;
                            -ms-transition: none;
                            -o-transition: none
                            }

                            .mjx-svg-href {
                            fill: blue;
                            stroke: blue
                            }

                            .MathJax_SVG_LineBox {
                            display: table!important
                            }

                            .MathJax_SVG_LineBox span {
                            display: table-cell!important;
                            width: 10000em!important;
                            min-width: 0;
                            max-width: none;
                            padding: 0;
                            border: 0;
                            margin: 0
                            }

                            .mjpage__block {
                            text-align: center;
                            margin: 1em 0em;
                            position: relative;
                            display: block!important;
                            text-indent: 0;
                            max-width: none;
                            max-height: none;
                            min-width: 0;
                            min-height: 0;
                            width: 100%
                            }</style></head><body><h2 id="home"><a href="./index.html">home</a></h2>
<p><em>author: niplav, created: 2025-02-27, modified: 2025-03-21, language: english, status: notes, importance: 1, confidence: joke</em></p>
<blockquote>
<p><strong>New philosophical position/Effective Altruism cause area
dropped. Benefits of pursuing the creation of libertarian free will
likely not worth the costs, based on a Monte-Carlo estimate.</strong></p>
</blockquote><div class="toc"><div class="toc-title">Contents</div><ul><li><a href="#Fermi_CostBenefit_Estimate">Fermi Cost-Benefit Estimate</a><ul><li><a href="#Tractability">Tractability</a><ul></ul></li><li><a href="#Importance">Importance</a><ul></ul></li><li><a href="#Neglectedness">Neglectedness</a><ul></ul></li></ul></li><li><a href="#Risks">Risks</a><ul></ul></li><li><a href="#Other_Ontological_Entities_It_Would_Potentially_Be_Good_To_Create">Other Ontological Entities It Would Potentially Be Good To Create</a><ul></ul></li><li><a href="#See_Also">See Also</a><ul></ul></li></ul></div>
<h1 id="Creating_Libertarian_Free_Will"><a class="hanchor" href="#Creating_Libertarian_Free_Will">Creating Libertarian Free Will</a></h1>
<p>The philosophical literature is rich in discussions about <a href="https://en.wikipedia.org/wiki/Free-Will">free
will</a>: Whether beings (usually
humans<sup id="fnref1"><a href="#fn1" rel="footnote">1</a></sup>) can make choices that are not, in some sense, "completely
determined" by the causal forces of nature. I won't take
any position in that debate here, but instead will ask a
far less explored question:</p>
<p><strong>If <a href="https://en.wikipedia.org/wiki/Libertarian_free_will">libertarian free
will</a> <em>does not</em>
exist, would it be good to bring it into existence?</strong></p>
<p>Clearly, humans value freedom in various:
<a href="https://en.wikipedia.org/wiki/Libertarianism">Libertarianism</a> makes
it the central tenet of its political philosophy, mundane forms of
unfreedom (slavery, imprisonement, social pressure &amp;c) are usually
regarded as undesirable, at least in WEIRD morality; the <a href="https://en.wikipedia.org/wiki/Capability_Approach">capability
approach</a> and the
<a href="https://en.wikipedia.org/wiki/Will_To_Power">will to power</a> both take
as central object the value of expanded actions and some theories of
life and artificial intelligence take expanded empowerment/control over
the environment as <em>the</em> feature defining successful existence.</p>
<p>Therefore, it's just natural to extend the desire for an expanded
action space to the ontological level; if we could, would we
not want to be able to act <em>counter</em> to the laws of physics,
peskily constraining each of us to a single future? (<a href="https://en.wikipedia.org/wiki/Many-Worlds_Interpretation">Many
worlds</a>
notwithstanding, since it also produces a pre-defined multiverse, and
<a href="https://en.wikipedia.org/wiki/Quantum_randomness">quantum randomness</a>
(if it exists) also does not count, as outlined in the debate around
the existence of libertarian free will.)</p>
<p>One can call this the <strong>constructive axiological free will hypothesis</strong>
(CAFWH): "<em>If libertarian free will doesn't (yet) exist, it would be
good to create it and imbue humans with it</em>".</p>
<h2 id="Fermi_CostBenefit_Estimate"><a class="hanchor" href="#Fermi_CostBenefit_Estimate">Fermi Cost-Benefit Estimate</a></h2>
<p>The ITN framework<!--TODO: link--> is ready-to-hand for evaluating whether
working on the CAWFH is a good idea.</p>
<h3 id="Tractability"><a class="hanchor" href="#Tractability">Tractability</a></h3>
<p>Starting with the weakest point. It is currently not clear how to bring
about new ontological entities. One can weakly estimate the cost from
taking the number of basic ontological categories in existence and
dividing them by the work that was involved in bringing them about.</p>
<p>As for basic ontological categories,
my estimate ranges from 0 (<a href="https://en.wikipedia.org/wiki/Ontological_nihilism">ontological
nihilism</a>)
to ~10 (list: mathematical objects, God and/or gods, qualia,
<a href="https://en.wikipedia.org/wiki/Matter-energy_relation">matterenergy</a>,
<a href="https://en.wikipedia.org/wiki/Spacetime">spacetime</a>, <a href="https://en.wikipedia.org/wiki/Abstract_object">abstract
objects</a>,
<a href="https://en.wikipedia.org/wiki/Soul">souls</a>, <a href="https://en.wikipedia.org/wiki/Moral_Realism">moral
facts</a> and likely others
I have forgotten to consider).</p>
<p>The total work needed to bring those about is difficult to estimate, as
it may range from no work (in the case of ontological nihilism) up to
<a href="https://en.wikipedia.org/wiki/Absolute_Infinite">absolute infinity</a>
if supernatural beings created existence. I'll take as a mean the
matter-energy content of the observable universe multiplied by four
(since matter-energy and spacetime are only two of the eight basic
ontological categories listed above).</p>
<p>The amount of <a href="https://en.wikipedia.org/wiki/Baryonic_matter">baryonic
matter</a>
in the observable universe is <a href="https://en.wikipedia.org/wiki/Observable_Universe">estimated
at</a> ~<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.201ex" height="2.676ex" style="vertical-align: -0.338ex;" viewBox="0 -1006.6 1808.8 1152.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">10^{53}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-30" x="500" y="0"></use>
<g transform="translate(1001,393)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-33" x="500" y="0"></use>
</g>
</g>
</svg></span> kg,
but since baryonic matter only makes up 4.5% of the total mass-energy
in the universe, I'll adjust the estimate (not leaving out dark energy &amp;
dark matter).</p>
<p>Using <a href="https://github.com/rethinkpriorities/squigglepy">squigglepy</a>:</p>
<pre><code>import squigglepy as sq
num_ontological_categories=sq.to(0, 10)
cost_new_entity=sq.lognorm(lognorm_mean=(1/0.045)*10**53, lognorm_sd=20)
prop_universe_entities=num_ontological_categories/sq.to(1, 3)
new_entity_cost=cost_new_entity/prop_universe_entities
</code></pre>
<p>Usually, a new ontological entity costs the mass-energy of <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.201ex" height="2.676ex" style="vertical-align: -0.338ex;" viewBox="0 -1006.6 1808.8 1152.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-2-Title">
<title id="MathJax-SVG-2-Title">10^{53}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-30" x="500" y="0"></use>
<g transform="translate(1001,393)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-33" x="500" y="0"></use>
</g>
</g>
</svg></span> kg:</p>
<pre><code>&gt;&gt;&gt; sq.sample(new_entity_cost, 10)
array([2.96996124e+53, 7.18535888e+53, 2.98417566e+54, 1.11103257e+54,
       6.09266737e+53, 8.39602018e+53, 4.08215136e+53, 5.01485048e+53,
       4.63852243e+53, 3.93717114e+53])
</code></pre>
<h3 id="Importance"><a class="hanchor" href="#Importance">Importance</a></h3>
<p>It would likely be valuable to create libertarian free will. (Though
see the list of <a href="#Risks">possible risks</a> below.)</p>
<p>As a proxy, one can try to estimate how much time and energy humans
expand on broadening the list of possible choices available to them;
examples include education, migration to more democratic and liberal
countries, buying transport, many health interventions &amp;c. Philosophical
intuition points me to ~10% of human effort being spent on pure expansion
of mundane freedoms.</p>
<p>Assuming that libertarian free will would be ~5Ã— more valuable, and a
~20% chance that humans already have libertarian free will, together with
a <a href="https://en.wikipedia.org/wiki/Gross_World_Product">gross world product</a>
of ~<span>$</span>100T, we can arrive at the value humanity should be willing to
pay for libertarian free will:</p>
<pre><code>gwp=sq.norm(mean=10**14, sd=1)
prop_spent_on_freedom=sq.beta(a=2, b=8)
real_freewill_mult=sq.to(4, 20)
chance_freewill_exists=sq.beta(a=1, b=4)
total_value=prop_spent_on_freedom*gwp*real_freewill_mult*(1-chance_freewill_exists)
</code></pre>
<p>Sampling, we usually get a few tens of trillions of dollars in value:</p>
<pre><code>&gt;&gt;&gt; sq.sample(total_value, 10)
array([9.96797785e+13, 4.23572584e+13, 8.24106658e+13, 4.32935165e+14,
       2.43818602e+14, 1.26017517e+14, 1.86109674e+14, 1.43918708e+14,
       4.01545018e+13, 2.40841431e+14])
</code></pre>
<h3 id="Neglectedness"><a class="hanchor" href="#Neglectedness">Neglectedness</a></h3>
<p>As far as I know, no being is working on creating libertarian free will
de novo, and philosophers have not yet discussed the possibility and
desirability<sup id="fnref2"><a href="#fn2" rel="footnote">2</a></sup>. It is possible that hidden supernatural entities are
engaged in the process, but that seems unlikely<sub>4%</sub>, and it's
not clear they would imbue humans specifically with the capability if
they created it.</p>
<hr>
<p>Unfortunately, it seems like the cost for new ontological basic entities
is too high: It is implausible that we will be able to bring up the
equivalent of ~<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.243ex" height="2.843ex" style="vertical-align: -0.505ex;" viewBox="0 -1006.6 4840.6 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-3-Title">
<title id="MathJax-SVG-3-Title">10^{53}-10^{54}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-30" x="500" y="0"></use>
<g transform="translate(1001,393)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-33" x="500" y="0"></use>
</g>
 <use xlink:href="#MJMAIN-2212" x="2031" y="0"></use>
<g transform="translate(3031,0)">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-30" x="500" y="0"></use>
<g transform="translate(1001,393)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34" x="500" y="0"></use>
</g>
</g>
</g>
</svg></span> kg of massenergy with an investment
of ~<span>$</span><span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.243ex" height="2.843ex" style="vertical-align: -0.505ex;" viewBox="0 -1006.6 4840.6 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-4-Title">
<title id="MathJax-SVG-4-Title">10^{13}-10^{14}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-30" x="500" y="0"></use>
<g transform="translate(1001,393)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-33" x="500" y="0"></use>
</g>
 <use xlink:href="#MJMAIN-2212" x="2031" y="0"></use>
<g transform="translate(3031,0)">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-30" x="500" y="0"></use>
<g transform="translate(1001,393)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34" x="500" y="0"></use>
</g>
</g>
</g>
</svg></span>.</p>
<p>However, due to the small amount of thought that has gone into ontological
engineering, there is the potential that creating new ontological
categories is much cheaper than estimated here, and the neglectedness
leaves space for a few experimental philosophers.</p>
<h2 id="Risks"><a class="hanchor" href="#Risks">Risks</a></h2>
<p>Drastic changes to the structure of existence are not without their
risks. Creating libertarian free will may induce multiple hazards:</p>
<ol>
<li><em>Choosing evil</em>: Imbuing humans with free will may cause them to deliberately choose evil (instead of simply being compelled to by the laws of physics), leaving them uniquely culpable of their harmful deeds.</li>
<li><em>Making the world less predictable</em>: Free agents interacting with the world may make it less stable and predictable, leading to overall lower welfare.</li>
<li><em>Being smitten by God for choosing evil</em>: If God or other supernatural beings have a plan that involves Him or them keeping control over which entities have free will, or if entities are only smitten if they actively choose evil, then giving humans free will may cause God or gods to smite humans, potentially even as a collective. Thus introducing libertarian free will poses a small existential risk.</li>
</ol>
<h2 id="Other_Ontological_Entities_It_Would_Potentially_Be_Good_To_Create"><a class="hanchor" href="#Other_Ontological_Entities_It_Would_Potentially_Be_Good_To_Create">Other Ontological Entities It Would Potentially Be Good To Create</a></h2>
<ul>
<li>Moral Facts (â€¦)</li>
<li>God, which would pose novel alignment challenges.</li>
<li><a href="https://en.wikipedia.org/wiki/Dasein">Dasein</a></li>
<li>Qualia</li>
<li><a href="https://en.wikipedia.org/wiki/Hypercomputation">Hypercomputation</a>, if it is not already possible via <a href="https://en.wikipedia.org/wiki/Malament-Hogarth_spacetime">Malament-Hogarth spacetimes</a>.</li>
</ul>
<h2 id="See_Also"><a class="hanchor" href="#See_Also">See Also</a></h2>
<ul>
<li><a href="http://bactra.org/notebooks/some-meta-ethical-positions.html">Some Unattractive Meta-Ethical Positions, Free to a Good Home (Cosma Shalizi, 2024)</a></li>
<li><a href="https://schwitzsplinters.blogspot.com/2025/02/zombie-is-to-human-as-human-is-to-xxx_26.html">Zombie is to Human as Human is to XXX? (Eric Schwitzgebel, 2025)</a></li>
</ul>
<div class="footnotes">
<hr>
<ol>
<li id="fn1">
<p>Though even here we may consider possibilities similar to the ones <a href="http://bactra.org/notebooks/some-meta-ethical-positions.html">Shalizi</a> discusses: What if free will is possible, but only a few species in the past had it, or only a few species in the future will have it, but not <em>homo sapiens</em>? What if there are inanimate objects that <em>have</em> free will, but choose not to exercise it? What if some humans<!--TODO: link Aaronson anecdote--> have free will, but others don't, or if all humans have free will as a latent ability, but have failed to notice and deploy it? How about the hypothesis that figuring out whether something/someone has free will is <a href="https://en.wikipedia.org/wiki/Undecidable">undecidable</a>, or at least <a href="https://en.wikipedia.org/wiki/EXPTIME-complete">EXPTIME-complete</a>? Humans may not have free will themselves, but be theoretically able to create beings with free willâ€¦ it's just that, by the way the universe is structured, we never will.&nbsp;<a href="#fnref1" rev="footnote">â†©</a></p>
</li>
<li id="fn2">
<p>Based on a short websearch using Google Scholar &amp; Perplexity, and a conversation with ChatGPT with web search enabled.&nbsp;<a href="#fnref2" rev="footnote">â†©</a></p>
</li>
</ol>
</div>

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs id="MathJax_SVG_glyphs"><path stroke-width="1" id="MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="1" id="MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path stroke-width="1" id="MJMAIN-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path stroke-width="1" id="MJMAIN-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path stroke-width="1" id="MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="1" id="MJMAIN-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></defs></svg></body></html>