<html><head><style type="text/css">
                            .mjpage .MJX-monospace {
                            font-family: monospace
                            }

                            .mjpage .MJX-sans-serif {
                            font-family: sans-serif
                            }

                            .mjpage {
                            display: inline;
                            font-style: normal;
                            font-weight: normal;
                            line-height: normal;
                            font-size: 100%;
                            font-size-adjust: none;
                            text-indent: 0;
                            text-align: left;
                            text-transform: none;
                            letter-spacing: normal;
                            word-spacing: normal;
                            word-wrap: normal;
                            white-space: nowrap;
                            float: none;
                            direction: ltr;
                            max-width: none;
                            max-height: none;
                            min-width: 0;
                            min-height: 0;
                            border: 0;
                            padding: 0;
                            margin: 0
                            }

                            .mjpage * {
                            transition: none;
                            -webkit-transition: none;
                            -moz-transition: none;
                            -ms-transition: none;
                            -o-transition: none
                            }

                            .mjx-svg-href {
                            fill: blue;
                            stroke: blue
                            }

                            .MathJax_SVG_LineBox {
                            display: table!important
                            }

                            .MathJax_SVG_LineBox span {
                            display: table-cell!important;
                            width: 10000em!important;
                            min-width: 0;
                            max-width: none;
                            padding: 0;
                            border: 0;
                            margin: 0
                            }

                            .mjpage__block {
                            text-align: center;
                            margin: 1em 0em;
                            position: relative;
                            display: block!important;
                            text-indent: 0;
                            max-width: none;
                            max-height: none;
                            min-width: 0;
                            min-height: 0;
                            width: 100%
                            }</style></head><body><h2 id="home"><a href="./index.html">home</a></h2>


<title>niplav</title>
<link href="./favicon.png" rel="shortcut icon" type="image/png">
<link href="main.css" rel="stylesheet" type="text/css">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<script src="footnotes.js"></script>
<style type="text/css">
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
</style>
<script>
document.addEventListener('DOMContentLoaded', function () {
	// Change the title to the h1 header
	var title = document.querySelector('h1')
	if(title) {
		var title_elem = document.querySelector('title')
		title_elem.textContent=title.textContent + " – niplav"
	}
});
</script>
<p><em>author: niplav, created: 2023-12-04, modified: 2023-12-04, language: english, status: maintenance, importance: 3, confidence: certain</em></p>
<blockquote>
<p><strong>I remain unconvinced by preference utilitarianism. Here's why.</strong></p>
</blockquote><div class="toc"><div class="toc-title">Contents</div><ul><li><a href="#The_Identification_Argument">The Identification Argument</a><ul></ul></li><li><a href="#PreferenceAltering_Actions_Disallowed">Preference-Altering Actions Disallowed</a><ul></ul></li><li><a href="#Possible_People">Possible People</a><ul><li><a href="#SideNote_Philosophers_Underestimate_the_Strangeness_of_Maximization">Side-Note: Philosophers Underestimate the Strangeness of Maximization</a><ul></ul></li><li><a href="#PreferenceCreating_Preferences">Preference-Creating Preferences</a><ul></ul></li></ul></li><li><a href="#Summary">Summary</a><ul></ul></li><li><a href="#See_Also">See Also</a><ul></ul></li></ul></div>
<h1 id="Arguments_Against_Preference_Utilitarianism"><a class="hanchor" href="#Arguments_Against_Preference_Utilitarianism">Arguments Against Preference Utilitarianism</a></h1>
<div>
        <span class="mjpage mjpage__block"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="17.365ex" height="3.843ex" style="vertical-align: -1.338ex;" viewBox="0 -1078.4 7476.7 1654.5" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\text{argmax} \sum ☺-☹</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-61"></use>
 <use xlink:href="#MJMAIN-72" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-67" x="893" y="0"></use>
 <use xlink:href="#MJMAIN-6D" x="1393" y="0"></use>
 <use xlink:href="#MJMAIN-61" x="2227" y="0"></use>
 <use xlink:href="#MJMAIN-78" x="2727" y="0"></use>
 <use xlink:href="#MJSZ2-2211" x="3422" y="0"></use>
<g transform="translate(5033,0)">
<text font-family="monospace" stroke="none" transform="scale(71.759) matrix(1 0 0 -1 0 0)">☺</text>
</g>
 <use xlink:href="#MJMAIN-2212" x="5866" y="0"></use>
<g transform="translate(6866,0)">
<text font-family="monospace" stroke="none" transform="scale(71.759) matrix(1 0 0 -1 0 0)">☹</text>
</g>
</g>
</svg></span>
</div>
<p><em>—Anders Sandberg, <a href="https://static1.squarespace.com/static/660e95991cf0293c2463bcc8/t/661a3fc3cecceb2b8ffce80d/1712996303164/FHI+Final+Report.pdf#page=52">FHI Final Report</a> p. 52, 2024</em></p>
<p><a href="https://en.wikipedia.org/wiki/Preference_utilitarianism">Preference
utilitarianism</a>
enjoys great popularity among utilitarians<!--TODO: citation
needed? How does it compare to other utilitarianisms?-->,
and I tend to agree that it is a <a href="./notes_on_politics_especially_economics.html#What_Politics_Is_For">very good pragmatic
compromise</a>
especially in the context of politics.</p>
<p>However, most formulations I have encountered bring up some problems
that I have not seen mentioned or addressed elsewhere.</p>
<h2 id="The_Identification_Argument"><a class="hanchor" href="#The_Identification_Argument">The Identification Argument</a></h2>
<p>One issue with preference utilitarianism concerns the word
“preference”, and especially where in the world these preferences
are located and how they can be identified. What kinds of physical
structures can be identified as having preferences (we might call this
the <em>identification problem</em>), and where exactly are those preferences
located (one might call this the <em>location problem</em>)? If one is purely
behavioristic about this question, then every physical system can be said
to have preferences, with the addition that if it is in equilibrium, it
seems to have achieved those prefereneces. This is clearly nonsensical,
as also explored in <a href="https://www.lesswrong.com/posts/26eupx3Byc8swRS7f/bottle-caps-aren-t-optimisers" title="Bottle Caps Aren't Optimisers">Filan
2018</a>.</p>
<p>If we argue that this is pure distinction-mongering, and that we "know
an agent when we see one", it might still be argued that evolution is
agent-like enough to fall into our category of an agent, but that we are
not necessarily obligated to spend a significant part of our resources
on copying and storing large amounts of DNA molecules.</p>
<p>Even restricting ourselves to humans, we still have issue with identifying
the computation inside human brains that could be said to be those
preferences, see e.g. <a href="https://nivlab.princeton.edu/publications/case-against-economic-values-brain" title="The case against economic values in the orbitofrontal cortex (or anywhere else in the brain)">Hayden &amp; Niv
2021</a>.
If we instead go with revealed preferences, unless we assume a
certain level of irrationality, we wouldn't be able to ascertain which
preferences of humans were <em>not</em> fulfilled (since we could just assume
that at each moment, each human is <a href="https://arxiv.org/abs/1712.05812">perfectly fulfilling their own
preferences</a>).</p>
<p>These are, of course, standard problems in value learning <a href="./doc/cs/ai/alignment/value_learning/the_value_learning_problem_soares_2016.pdf" title="The Value Learning Problem">Soares
2018</a>.</p>
<h2 id="PreferenceAltering_Actions_Disallowed"><a class="hanchor" href="#PreferenceAltering_Actions_Disallowed">Preference-Altering Actions Disallowed</a></h2>
<p>Even if agents bearing preferences can be identified and the preferences
they bear can be located, ethical agents are faced with a dubious
demand: Insofar only the preferences of existing agents matter (i.e. our
population axiology is person-affecting), the ethical agent is forced
to stabilize existing consistent prefereneces (and perhaps also to
<a href="./turning.html">make inconsistent preferences consistent</a>), because
every stable preference implies a "meta-preference" of its own continued
existence <a href="./doc/cs/ai/alignment/the_basic_ai_drives_omohundro_2008.pdf" title="The Basic AI Drives">Omohundro
2008</a>.</p>
<p>However, this conflicts with ethical intuitions: We would like to allow
ethical patients to undergo moral growth and reflect on their values.</p>
<p>(I do not expect this to be a practical issue, since at least in
human brains, I expect there to be no actually consistent internal
preferences. With simpler organisms or very simple physical systems, this
might become an issue, but one wouldn't expect them to have undergone
significant moral growth in any case.)</p>
<!--TODO

What about preferences we *really* don't like?

Interpersonal preference strength comparison?

#### Second-Order Preference

Maybe we can solve this by positing preferences over preferences? But
then we allow nosy preferences, i.e. preferences by one agent over the
preferences of another one.

#### Reflective Equilibrium
-->
<h2 id="Possible_People"><a class="hanchor" href="#Possible_People">Possible People</a></h2>
<p>If we allow the preferences of possible people to influence our decision
procedure, we run into trouble <em>very quickly</em>.</p>
<p>In the most realistic case, imagine we can perform genetic editing
(or <a href="https://www.gwern.net/Embryo-selection">embryo selection</a>) to
select for traits in new humans, and assume that the psychological
profile of people who really want to have been born is at least
somewhat genetically determined, and we can identify and modify
those genes. (Alternatively, imagine that we have found out how
to raise people so that they have a great preference for having
been born, perhaps by an unanticipated leap in <a href="https://en.wikipedia.org/wiki/Developmental_psychology">developmental
psychology</a>).</p>
<p>Then it seems like preference utilitarianism that includes possible
people demands that we try to grow humanity as quickly as possible,
with most people being modified in such a way that they strongly prefer
being alive and having been born (if they are unusually inept in one or
more ways, we would like to have some people around who can support them).</p>
<p>However, this <em>preference</em> for having been born doesn't guarantee
an <em>enjoyment of life</em> in the commonsense way. It might be that
while such people really prefer being alive, they're not really
happy while being alive. Indeed, since most of the time <a href="https://www.lesswrong.com/posts/asmZvCPHcB4SkSCMW" title="The Tails Coming Apart As Metaphor For Life">the tails
come apart</a>,
I would make the guess that those people wouldn't be much
happier than current humans (an example of <a href="./doc/cs/ai/alignment/agent_foundations/categorizing_variants_of_goodharts_law_manheim_garrabrant_2019.pdf" title="Categorizing Variants of Goodhart's Law">causal
Goodhart</a>).</p>
<p>Preference utilitarians who respect possible preferences might just bite
this bullet and argue that this indeed the correct thing to do.</p>
<p>But, depending on the definition of an ethical patient <a href="./notes_on_ethics.html#The_Identification_Argument">who displays
preferences</a>, the
moral patient who maximally prefers existing might look nothing like a
typical human, and more like an intricate e-coli-sized web of diamond
or a very fast rotating blob of strange matter. The only people I can
imagine willing to bite this bullet probably are too busy running around
robbing ammunition stores.</p>
<h3 id="SideNote_Philosophers_Underestimate_the_Strangeness_of_Maximization"><a class="hanchor" href="#SideNote_Philosophers_Underestimate_the_Strangeness_of_Maximization">Side-Note: Philosophers Underestimate the Strangeness of Maximization</a></h3>
<p>Often in arguments with philosophers, especially about consequentialism,
I find that most of them underappreciate the strangeness of
results of very strong optimization algorithms. Whenever there's
an <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.562ex" height="2.009ex" style="vertical-align: -0.671ex;" viewBox="0 -576.1 3256 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-2-Title">
<title id="MathJax-SVG-2-Title">\text{argmax}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-61"></use>
 <use xlink:href="#MJMAIN-72" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-67" x="893" y="0"></use>
 <use xlink:href="#MJMAIN-6D" x="1393" y="0"></use>
 <use xlink:href="#MJMAIN-61" x="2227" y="0"></use>
 <use xlink:href="#MJMAIN-78" x="2727" y="0"></use>
</g>
</svg></span> in your function, the result is probably
going to look <em>nothing like</em> what you imagine it looking like,
especially if the optimization doesn't have <a href="https://arbital.com/p/inductive_ambiguity/">conservative concept
boundaries</a>.</p>
<h3 id="PreferenceCreating_Preferences"><a class="hanchor" href="#PreferenceCreating_Preferences">Preference-Creating Preferences</a></h3>
<p>If you restrict your preference utilitarianism to currently existing
preferences, you might get lucky and avoid this kind of scenario. But
also maybe you won't: If there are any currently existing preferences
of the form P="I want there to be as many physically implemented
instances of P to exist as possible" (these are possible to represent as
<a href="https://en.wikipedia.org/wiki/Quine_(computing)">quines</a>), you have
two choices:</p>
<ul>
<li>Either you weight preferences by how strong they were at a single point in time <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.84ex" height="2.009ex" style="vertical-align: -0.338ex;" viewBox="0 -719.6 361.5 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-3-Title">
<title id="MathJax-SVG-3-Title">t</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-74" x="0" y="0"></use>
</g>
</svg></span>, and just maximize the preferences existing at <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.84ex" height="2.009ex" style="vertical-align: -0.338ex;" viewBox="0 -719.6 361.5 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-4-Title">
<title id="MathJax-SVG-4-Title">t</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-74" x="0" y="0"></use>
</g>
</svg></span>.</li>
<li>Or you maximize <em>currently existing preferences</em>, weighted by how strong they are right now.</li>
</ul>
<p>In the latter case, you land in a universe filled with physical systems
implementing the preference P.</p>
<h2 id="Summary"><a class="hanchor" href="#Summary">Summary</a></h2>
<p>All forms of preference utilitarianism face the challenge of identifying
which systems have preferences, and how those preferences are implemented.</p>
<ul>
<li>Preference utilitarianisms
<ul>
<li>Face the challenge of identifying which systems have preferences, and how those preferences are implemented.</li>
<li>That don't respect possible preferences:
<ul>
<li>Will attempt to "freeze" current preferences and prevent any moral progress.</li>
<li>If they always maximize the currently existing preferences, and self-replicating preferences exist in the universe, they will tile the universe with those preferences.</li>
</ul></li>
<li>That respect possible preferences:
<ul>
<li>Will get mercilessly exploited by the strongest preferences they include in the domain of moral patients.</li>
</ul></li>
</ul></li>
</ul>
<h2 id="See_Also"><a class="hanchor" href="#See_Also">See Also</a></h2>
<ul>
<li><a href="https://reducing-suffering.org/fuzzy-nested-minds-problematize-utilitarian-aggregation/">Fuzzy, Nested Minds Problematize Utilitarian Aggregation (Brian Tomasik, 2015)</a></li>
</ul>
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs id="MathJax_SVG_glyphs"><path stroke-width="1" id="MJMAIN-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path stroke-width="1" id="MJMAIN-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path stroke-width="1" id="MJMAIN-67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path><path stroke-width="1" id="MJMAIN-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="1" id="MJMAIN-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path><path stroke-width="1" id="MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path><path stroke-width="1" id="MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="1" id="MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs></svg></body></html>