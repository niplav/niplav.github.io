<html><head><title>niplav</title>
<link href="./favicon.png" rel="shortcut icon" type="image/png"/>
<link href="main.css" rel="stylesheet" type="text/css"/>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<!DOCTYPE HTML>

<style type="text/css">
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
</style>
<script async="" src="./mathjax/latest.js?config=TeX-MML-AM_CHTML" type="text/javascript">
</script>
<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	extensions: ["tex2jax.js"],
	jax: ["input/TeX", "output/HTML-CSS"],
	tex2jax: {
		inlineMath: [ ['$','$'], ["\\(","\\)"] ],
		displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
		processEscapes: true,
		skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
	},
	"HTML-CSS": { availableFonts: ["TeX"] }
	});
</script>
<script>
document.addEventListener('DOMContentLoaded', function () {
	// Change the title to the h1 header
	var title = document.querySelector('h1')
	if(title) {
		var title_elem = document.querySelector('title')
		title_elem.textContent=title.textContent + " – niplav"
	}
});
</script>
</head><body><h2 id="home"><a href="./index.html">home</a></h2>
<p><em>author: niplav, created: 2024-04-22, modified: 2024-07-07, language: english, status: in progress, importance: 5, confidence: highly likely</em></p>
<blockquote>
<p><strong>How to compare how similarly programs compute their outputs.</strong></p>
</blockquote>
<h1 id="Logical_Correlation"><a class="hanchor" href="#Logical_Correlation">Logical Correlation</a></h1>
<!--TODO: wentworth post about eding programs as causal diagrams-->
<p>In the <a href="https://www.lesswrong.com/tag/psychological-twin-prisoner-s-dilemma">twin prisoners
dilemma</a>,
I cooperate with my twin because we're implementing the same algorithm. If
we modify the twin slightly, for example to have a slightly longer right
index-finger-nail, I would still cooperate, even though we're different
algorithms, since little enough has been changed about our algorithms
that the internal states and the output are basically the same.</p>
<p>But it could be that I'm in a prisoner's dilemma with some program
<code>$p^{\star}$</code> that, given some inputs, returns the same outputs as I do,
but for completely different "reasons"—that is, the internal states
are very different, and a slight change in input would cause the output
to be radically different. Intuitively, my similarity to <code>$p^{\star}$</code>
is pretty small, because even though it gives the same output, it gives
that output for very different reasons, so I don't have much control
over its outputs by controlling my own computations.</p>
<p>Let's call this similarity of two algorithms the <strong>logical correlation</strong>
between the two algorithms, a term also used in <a href="./cs/ai/alignment/agent_foundations/embedded_agency_demski_garrabrant_2020.pdf">Demski &amp; Garrabrant
2020</a>:</p>
<blockquote>
<p>One idea is that exact copies should be treated as 100% under
your “logical control”. For approximate models of you, or merely
similar agents, control should drop off sharply as logical correlation
decreases. But how does this work?</p>
</blockquote>
<p><em>—Abram Demski &amp; Scott Garrabrant, <a href="./cs/ai/alignment/agent_foundations/embedded_agency_demski_garrabrant_2020.pdf">“Embedded Agency”</a> p. 12, 2020</em></p>
<p>Similarly:</p>
<blockquote>
<p>The reasoning behind cooperation does not involve a common cause of
all collaborators' decisions. Instead, the correlation may be viewed
as logical (Garrabrant et al., 2016): if I cooperate, then this implies
that all other implementations of my decision algorithm also cooperate.</p>
</blockquote>
<p><em>—Caspar Oesterheld, “Multiverse-wide Cooperation via Correlated Decision Making” p. 18, 2018</em></p>
<p>We don't yet have a way of estimating the logical correlation between
different decision algorithms.</p>
<p>Thus: Consider proposing the most naïve formula (which we'll designate
by <code>$合$</code><sup id="fnref1"><a href="#fn1" rel="footnote">1</a></sup>) for logical correlation<sup id="fnref2"><a href="#fn2" rel="footnote">2</a></sup>: Something that takes in
two programs and returns a number that quantifies how similarly the two
programs compute what they compute.</p>
<h3 id="Setup"><a class="hanchor" href="#Setup">Setup</a></h3>
<p>Let a program <code>$p$</code> be a tuple of code for a <a href="https://en.wikipedia.org/wiki/Turing_Machine">Turing
machine</a>, intermediate
tape states after each command execution, and output. All in binary.</p>
<p>That is <code>$p=(c, t, o)$</code>, with <code>$c \in \{0, 1\}^+, t \in (\{0, 1\}^+)^+$</code> and <code>$o \in \{0, 1\}^+$</code>.
Let <code>$l=|t|$</code> be the number of steps that <code>$p$</code> takes to halt.</p>
<h3 id="Possible_Desiderata"><a class="hanchor" href="#Possible_Desiderata">Possible Desiderata</a></h3>
<ol>
<li>If possible, we would want our formula for logical correlation to be a <a href="https://en.wikipedia.org/wiki/Metric_space">metric</a> or a <a href="https://en.wikipedia.org/wiki/Pseudometric_space">pseudometric</a> on the space of programs:
<ol>
<li><code>$合(p, p)=0$</code>.</li>
<li><a href="https://en.wikipedia.org/wiki/Symmetric_function">Symmetry</a>: <code>$合(p_1, p_2)=合(p_2, p_1)$</code>.</li>
<li>If <code>$p_1 \not=p_2$</code>, then <code>$合(p_1, p_2)&gt;0$</code>. This condition is dropped if we're fine with <code>$合$</code> being a pseudometric.</li>
<li>The <a href="https://en.wikipedia.org/wiki/Triangle_Inequality">triangle inequality</a>: <code>$合(p_1, p_3) \le 合(p_1, p_2)+合(p_2, p_3)$</code>.</li>
</ol></li>
<li>If <code>$p_1$</code> and <code>$p_2$</code> have very similar outputs, and <code>$p_3$</code> has a very different output, then <code>$合(p_1, p_2)&lt;合(p_1, p_3)$</code> (and <code>$合(p_1, p_2)&lt;合(p_2, p_3)$</code>).
<ol>
<li>I'm not <em>so sure</em> about this one: Let's say there's <code>$p$</code>, which outputs a binary string <code>$o \in \{0, 1\}$</code>, and <code>$p^{\not \sim}$</code>, which computes <code>$o$</code> in a completely different way, as well as <code>$p^{\lnot}$</code>, which first runs <code>$p$</code>, and then flips every bit on the tape, finally returning the negation of <code>$o$</code>. In this case, it seems that if <code>$p$</code> is a decision algorithm, it has far more "control" over the output of <code>$p^{\lnot}$</code> than over <code>$p^{\not \sim}$</code>.</li>
<li>For the time being, I'm going to accept this, though ideally there'd be some way of handling the tradeoff between "computed the same output in a different way" and "computed a different output in a similar way".</li>
</ol></li>
</ol>
<h3 id="Formal_Definition"><a class="hanchor" href="#Formal_Definition">Formal Definition</a></h3>
<p>Then a formula for the logical correlation <code>$合$</code> of two halting
programs <code>$p_1=(c_1, t_1, o_1), p_2=(c_2, t_2, o_2)$</code>, a tape-state
discount factor <code>$γ$</code><sup id="fnref3"><a href="#fn3" rel="footnote">3</a></sup>, and a <a href="https://en.wikipedia.org/wiki/String_similarity_metric">string-distance metric</a>
<code>$d: \{0, 1\}^+ \times \{0, 1\}^+ \rightarrow ℕ$</code> could be</p>
<div>
        $$合(p_1, p_2, γ)=d(o_1, o_2)+0.5-\frac{1}{2+\sum_{k=0}^{\min(l_1, l_2)} γ^k \cdot d(t_1(l_1-k), t_2(l_2-k))}$$
</div>
<p>The lower <code>$合$</code>, the higher the logical correlation between <code>$p_1$</code>
and <code>$p_2$</code>.</p>
<p>If <code>$d(o_1, o_2)&lt;d(o_1, o_3)$</code>, then it's also the case that <code>$合(p_1, p_2, γ)&lt;合(p_1, p_3, γ)$</code>.</p>
<p>One might also want to be able to deal with the fact that programs have
different trace lengths, and penalize that, e.g. amending the formula:</p>
<div>
        $$合'(p_1, p_2, γ)=合(p_1, p_2, γ)+2^{|l_1-l_2|}$$
</div>
<p>I'm a bit unhappy that the code doesn't factor into the logical
correlation, and ideally one would want to be able to compute the logical
correlation without having to run the program.</p>
<p>How does this relate to
<a href="https://wiki.c2.com/?DataAndCodeAreTheSameThing">data=code</a>?</p>
<h4 id="Desiderata_Fulfilled"><a class="hanchor" href="#Desiderata_Fulfilled">Desiderata Fulfilled?</a></h4>
<p>Does this fulfill our desiderata from earlier? I'll assume that the
string distance <code>$d$</code> is a metric, in the mathematical sense.</p>
<ol>
<li><code>$合(p, p)=0$</code>. (The minimal logical correlation is 0.)</li>
</ol>
<!--TODO: check with brainfuck-->
<!--TODO: prove or disprove that this is a metric (or maybe a
pseudometric?—seems like there could the different programs with the
exactly same tape states…)-->
<div class="footnotes">
<hr/>
<ol>
<li id="fn1">
<p>Suggested by GPT-4. Stands for <a href="https://en.wiktionary.org/wiki/%E5%90%88#Definitions">joining, combining, uniting</a>. Also "to suit; to fit", "to have sexual intercourse", "to fight, to have a confrontation with", or "to be equivalent to, to add up". Maybe I could've used one of the <a href="https://en.wikipedia.org/wiki/Ghost_characters">ghost characters</a>. <a href="#fnref1" rev="footnote">↩</a></p>
</li>
<li id="fn2">
<p>Actually not explained in detail anywhere, as far as I can tell. <a href="#fnref2" rev="footnote">↩</a></p>
</li>
<li id="fn3">
<p>Which is needed because tape states close to the output are more important than tape states early on. <a href="#fnref3" rev="footnote">↩</a></p>
</li>
</ol>
</div>
</body></html>
