<html><head><title>niplav</title>
<link href="./favicon.png" rel="shortcut icon" type="image/png">
<link href="main.css" rel="stylesheet" type="text/css">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">


<style type="text/css">
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
</style>
<script>
document.addEventListener('DOMContentLoaded', function () {
	// Change the title to the h1 header
	var title = document.querySelector('h1')
	if(title) {
		var title_elem = document.querySelector('title')
		title_elem.textContent=title.textContent + " – niplav"
	}
});
</script>
<style type="text/css">
                            .mjpage .MJX-monospace {
                            font-family: monospace
                            }

                            .mjpage .MJX-sans-serif {
                            font-family: sans-serif
                            }

                            .mjpage {
                            display: inline;
                            font-style: normal;
                            font-weight: normal;
                            line-height: normal;
                            font-size: 100%;
                            font-size-adjust: none;
                            text-indent: 0;
                            text-align: left;
                            text-transform: none;
                            letter-spacing: normal;
                            word-spacing: normal;
                            word-wrap: normal;
                            white-space: nowrap;
                            float: none;
                            direction: ltr;
                            max-width: none;
                            max-height: none;
                            min-width: 0;
                            min-height: 0;
                            border: 0;
                            padding: 0;
                            margin: 0
                            }

                            .mjpage * {
                            transition: none;
                            -webkit-transition: none;
                            -moz-transition: none;
                            -ms-transition: none;
                            -o-transition: none
                            }

                            .mjx-svg-href {
                            fill: blue;
                            stroke: blue
                            }

                            .MathJax_SVG_LineBox {
                            display: table!important
                            }

                            .MathJax_SVG_LineBox span {
                            display: table-cell!important;
                            width: 10000em!important;
                            min-width: 0;
                            max-width: none;
                            padding: 0;
                            border: 0;
                            margin: 0
                            }

                            .mjpage__block {
                            text-align: center;
                            margin: 1em 0em;
                            position: relative;
                            display: block!important;
                            text-indent: 0;
                            max-width: none;
                            max-height: none;
                            min-width: 0;
                            min-height: 0;
                            width: 100%
                            }</style></head><body><h2 id="home"><a href="./index.html">home</a></h2>
<p><em>author: niplav, created: 2020-03-24, modified: 2024-10-17, language: english, status: maintenance, importance: 6, confidence: possible</em></p>
<blockquote>
<p><strong>This text looks at the accuracy of forecasts in
relation to the time between forecast and resolution, and
asks three questions: First; is the accuracy higher <a href="#Judging_Between_Forecasts">between
forecasts</a>; Second; is the accuracy higher
<a href="#Judging_Between_Questions">between questions</a>; Third; is the accuracy
higher <a href="#Judging_Within_Questions">within questions</a>? These questions are
analyzed using data from <a href="https://predictionbook.com/">PredictionBook</a>
and <a href="https://www.metaculus.com/questions/">Metaculus</a>, the answers turn
out to be yes, unclear and yes for Metaculus data; and no, no and yes
for PredictionBook data. Possible reasons are discussed. I also try to
find out how far humans can look into the future, leading to various
different results. I personally conclude that humans can on average look
5 years into the future<sub>28%</sub>.</strong></p>
</blockquote><div class="toc"><div class="toc-title">Contents</div><ul><li><a href="#Definitions">Definitions</a><ul></ul></li><li><a href="#Results">Results</a><ul></ul></li><li><a href="#Related_Work">Related Work</a><ul></ul></li><li><a href="#Three_Different_Analyses_An_Illustrative_Example">Three Different Analyses: An Illustrative Example</a><ul><li><a href="#Judging_Between_Forecasts">Judging Between Forecasts</a><ul></ul></li><li><a href="#Judging_Between_Questions">Judging Between Questions</a><ul></ul></li><li><a href="#Judging_Within_Questions">Judging Within Questions</a><ul></ul></li></ul></li><li><a href="#Metaculus_and_PredictionBook">Metaculus and PredictionBook</a><ul></ul></li><li><a href="#Getting_the_Data">Getting the Data</a><ul><li><a href="#For_Metaculus">For Metaculus</a><ul></ul></li><li><a href="#For_PredictionBook">For PredictionBook</a><ul></ul></li></ul></li><li><a href="#Accuracy_Between_Forecasts">Accuracy Between Forecasts</a><ul><li><a href="#Analysis">Analysis</a><ul><li><a href="#Why_Some_Negative_Ranges">Why Some Negative Ranges?</a><ul></ul></li></ul></li><li><a href="#Results_1">Results</a><ul><li><a href="#NonLinear_CurveFitting">Non-Linear Curve-Fitting</a><ul><li><a href="#Fitting_a_Logistic_Function">Fitting a Logistic Function</a><ul></ul></li><li><a href="#Fitting_an_Exponential_Function">Fitting an Exponential Function</a><ul></ul></li><li><a href="#This_Is_Cool">This Is Cool</a><ul><li><a href="#The_Horizon">The Horizon</a><ul></ul></li></ul></li></ul></li></ul></li><li><a href="#Why_Assume_Accuracy_will_Increase">Why Assume Accuracy will Increase?</a><ul></ul></li><li><a href="#Possible_Explanations">Possible Explanations</a><ul><li><a href="#Range_and_Biased_Questions">Range and Biased Questions</a><ul><li><a href="#Simpsons_Paradox">Simpson's Paradox</a><ul></ul></li></ul></li><li><a href="#Low_Sample_Sizes_With_High_Ranges">Low Sample Sizes With High Ranges</a><ul><li><a href="#Statistical_Significance_of_Truncated_Datasets">Statistical Significance of Truncated Datasets</a><ul></ul></li></ul></li></ul></li></ul></li><li><a href="#Accuracy_Between_Questions">Accuracy Between Questions</a><ul><li><a href="#Determining_the_Range_of_a_Question">Determining the Range of a Question</a><ul></ul></li><li><a href="#Analysis_1">Analysis</a><ul></ul></li><li><a href="#Results_2">Results</a><ul><li><a href="#NonLinear_CurveFitting_1">Non-Linear Curve-Fitting</a><ul></ul></li><li><a href="#Why_Longer_Range_Questions_More_Accurate">Why Longer Range Questions More Accurate?</a><ul></ul></li><li><a href="#This_Partially_Explains_the_Result_Between_Forecasts">This Partially Explains the Result Between Forecasts</a><ul></ul></li></ul></li></ul></li><li><a href="#Accuracy_Within_Questions">Accuracy Within Questions</a><ul><li><a href="#Analysis_2">Analysis</a><ul></ul></li><li><a href="#Results_3">Results</a><ul><li><a href="#Linear_Regression">Linear Regression</a><ul><li><a href="#Aggregating_Linear_Regressions">Aggregating Linear Regressions</a><ul></ul></li></ul></li><li><a href="#Logistic_CurveFit">Logistic Curve-Fit</a><ul><li><a href="#Logistic_Forecast_Horizons_for_Questions">Logistic Forecast Horizons for Questions</a><ul></ul></li></ul></li><li><a href="#Exponential_CurveFit">Exponential Curve-Fit</a><ul><li><a href="#Exponential_Forecast_Horizons_for_Questions">Exponential Forecast Horizons for Questions</a><ul></ul></li></ul></li></ul></li><li><a href="#Sample_Sizes">Sample Sizes</a><ul><li><a href="#Interlude_Its_Under_102">Interlude: It's Under 102</a><ul></ul></li></ul></li></ul></li><li><a href="#Limitations">Limitations</a><ul><li><a href="#Metaculus_Dataset_is_Only_Community_Timeseries">Metaculus Dataset is Only Community Timeseries</a><ul></ul></li><li><a href="#PredictionBook_Forecasts_can_be_Resolved_by_Anyone">PredictionBook Forecasts can be Resolved by Anyone</a><ul></ul></li></ul></li><li><a href="#Acknowledgements">Acknowledgements</a><ul></ul></li><li><a href="#Miscellaneous">Miscellaneous</a><ul></ul></li><li><a href="#See_Also">See Also</a><ul></ul></li><li><a href="#Appendix_A_Replicating_Metaculus_Findings_With_Full_Data">Appendix A: Replicating Metaculus Findings With Full Data</a><ul><li><a href="#Some_Predictions_About_The_Results">Some Predictions About The Results</a><ul></ul></li><li><a href="#Analysis__Results">Analysis &amp; Results</a><ul><li><a href="#Analysis_Between_Forecasts">Analysis Between Forecasts</a><ul></ul></li><li><a href="#Analysis_Between_Questions">Analysis Between Questions</a><ul></ul></li></ul></li><li><a href="#Analysis_Within_Questions">Analysis Within Questions</a><ul></ul></li><li><a href="#Replication_Inbound">Replication Inbound?</a><ul></ul></li></ul></li><li><a href="#Appendix_B_Statistical_Significance_of_Truncated_Datasets">Appendix B: Statistical Significance of Truncated Datasets</a><ul></ul></li><li><a href="#Appendix_C_Quotes_About_the_Horizon_of_Forecasts">Appendix C: Quotes About the Horizon of Forecasts</a><ul></ul></li></ul></div>
<h1 id="Range_and_Forecasting_Accuracy"><a class="hanchor" href="#Range_and_Forecasting_Accuracy">Range and Forecasting Accuracy</a></h1>
<blockquote>
<p>Above all, don’t ask what to believe—ask what to anticipate. Every
question of belief should flow from a question of anticipation, and that
question of anticipation should be the center of the inquiry. Every guess
of belief should begin by flowing to a specific guess of anticipation,
and should continue to pay rent in future anticipations. If a belief
turns deadbeat, evict it.</p>
</blockquote>
<p><em>— <a href="https://en.wikipedia.org/wiki/Eliezer_Yudkowsky">Eliezer Yudkowsky</a>, <a href="https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences">“Making Beliefs Pay Rent (in Anticipated Experiences)“</a>, 2007</em></p>
<p><a href="https://en.wikipedia.org/wiki/Forecasting#Judgmental_methods">Judgmental
forecasting</a>
in which humans aggregate both <a href="https://en.wikipedia.org/wiki/Forecasting#Qualitative_vs._quantitative_methods">qualitative and quantitative
methods</a>
to make predictions, and become better at doing so, is a comparatively
simple idea. Basically, one needs to have only a few tools at one's
disposal to being ready to start forecasting:</p>
<!--TODO: give more weight to the fact that it is humans doing this-->
<ul>
<li>View of belief as probabilistic (perhaps with some bayesian epistemology)</li>
<li>Track records (grading results of forecasts using for example brier scores or log scores)</li>
<li>Probability theory (a concept of probabilities, and maybe some simple probability distributions)</li>
</ul>
<p>Since the 1980s, forecasting has slowly but surely matured from "X is
going to happen because divine revelation told me so" to "my probability
distribution on the outcome of this random variable is an X distribution
with the following parameters", or alternatively "I assign a probability
of X% to this event".</p>
<p>However, since this kind of forecasting is relatively recent, information
about the accuracy of long-range forecasting is basically non-existent:</p>
<blockquote>
<ol>
<li>Long-range forecasts are often stated
too imprecisely to be judged for accuracy.
<a href="https://www.openphilanthropy.org/blog/how-feasible-long-range-forecasting#Imprecisely_stated_forecasts">More</a></li>
<li>Even if a forecast is stated precisely, it might be difficult to
find the information needed to check the forecast for accuracy.
<a href="https://www.openphilanthropy.org/blog/how-feasible-long-range-forecasting#Practically_uncheckable_forecasts">More</a></li>
<li>Degrees of confidence for long-range
forecasts are rarely quantified.
<a href="https://www.openphilanthropy.org/blog/how-feasible-long-range-forecasting#Non-quantified_degrees_of_confidence">More</a></li>
<li>In most cases, no comparison to a “baseline method”
or “null model” is possible, which makes it difficult
to assess how easy or difficult the original forecasts were.
<a href="https://www.openphilanthropy.org/blog/how-feasible-long-range-forecasting#No_comparison_to_a_baseline_method_or_null_model_is_feasible">More</a></li>
<li>Incentives for forecaster accuracy are usually unclear or weak.
<a href="https://www.openphilanthropy.org/blog/how-feasible-long-range-forecasting#Unclear_or_weak_incentives_for_accuracy">More</a></li>
<li>Very few studies have been designed so as to allow confident
inference about which factors contributed to forecasting accuracy.
<a href="https://www.openphilanthropy.org/blog/how-feasible-long-range-forecasting#Weak_strategy_for_causal_identification">More</a></li>
<li>It’s difficult to know how comparable past forecasting exercises
are to the forecasting we do for grantmaking purposes, e.g. because the
forecasts we make are of a different type, and because the forecasting
training and methods we use are different.
<a href="https://www.openphilanthropy.org/blog/how-feasible-long-range-forecasting#Unclear_relevance_to_our_own_long-range_forecasting">More</a></li>
</ol>
</blockquote>
<p><em>— <a href="http://lukemuehlhauser.com">Luke Muehlhauser</a>, <a href="https://www.openphilanthropy.org/blog/how-feasible-long-range-forecasting">“How Feasible Is Long-range Forecasting?”</a>, 2019</em></p>
<!--TODO: put in info where Metaculus and PredictionBook fit into this-->
<p>In this text, I will try to look at the accuracy of short-term and
mid-term forecasting, which may shine some light on the relation between
the range of forecasts and their accuracy in general.</p>
<h3 id="Definitions"><a class="hanchor" href="#Definitions">Definitions</a></h3>
<p>The <strong>range</strong> of a forecast is defined as the length of the timespan
between the forecast and the resolution of the forecast (i.e.,
when we know the outcome of the forecast). Keeping with <a href="https://www.openphilanthropy.org/blog/how-feasible-long-range-forecasting" title="How Feasible Is Long-range Forecasting?">Muehlhauser
2019</a>,
I define short-term forecasts as forecasts with a range of less than
a year, mid-range forecasts as forecasts with a range between 1 and 10
years, and long-term forecasts as forecasts with a range of more than 10
years (this distinction is not central to the following analysis, though).</p>
<p>The <strong>horizon</strong> of a set of forecasts is the range at which these
forecasts are as good as chance, i.e. as random guessing. Similarly,
one can speak of the horizon of a forecaster (the range at which
the forecaster could just as well guess the predictions) and of a
forecasting platform. It's conceptually similar to the <a href="https://en.wikipedia.org/wiki/Lyapunov_time">Lyapunov
time</a>.</p>
<hr>
<p>Fortunately, for short- and mid-range forecasts, two easily accessible
sources of forecasts and their resolutions are available online: The two
forecasting websites <a href="https://predictionbook.com">PredictionBook</a> and
<a href="https://www.metaculus.com">Metaculus</a>, frequented mostly by hobbyists.</p>
<p>I am not aware of large-scale datasets with resolved long-range forecasts.</p>
<p>To find out about the range of forecasts, I download, parse &amp; analyse
forecasting data from these sites, and then analyze the data with <a href="https://en.wikipedia.org/wiki/Python_(programming_language)">Python
3</a>, using
<a href="https://numpy.org/">NumPy</a>, <a href="https://scipy.org/scipylib/">SciPy</a> and
<a href="https://matplotlib.org/">Matplotlib</a>.</p>
<!--
Make a point here that making forecasts is one of the best existing
practical method of rationality verification & exercises:
https://www.lesswrong.com/s/pvim9PZJ6qHRTMqD3/p/5K7CMa6dEL7TN7sae

Not necessary, move elsewhere.
-->
<!--
Distinction between {probabilistic,non-probabilistic}
{model-based,judgmental} forecasting
-->
<h2 id="Results"><a class="hanchor" href="#Results">Results</a></h2>
<p>Using two datasets with both ~45k predictions, having ranges between
1 day and 10 years (thereby containing forcasts with short and medium
range). I investigate the relation between the accuracy of predictions
and their range (that is, the time between the prediction being made
and the result of the prediction being known).</p>
<p>I find that the data indicates the following conclusions (if any
of the terms don't make sense, perhaps reading the <a href="#Three_Different_Analyses_An_Illustrative_Example">illustrative
example</a> can help):</p>
<ol>
<li> Comparing <strong>all forecasts on all questions</strong>, irrespective of the
question (<a href="#Accuracy_Between_Forecasts">more</a>):
<ol>
<li> Predictions made <em>a long time before their resolution</em>
are generally <em>less accurate</em> than predictions made
<em>a shorter time before their resolution</em> (<a href="#Results_1">more</a>).
<ol>
<li>The results for PredictionBook and Metaculus disagree here. This can be partially,
but not completely, explained by the
fact that questions with a longer
range receive more accurate forecasts
(<a href="#This_Partially_Explains_the_Result_Between_Forecasts">more</a>).</li>
<li> The correlations (0.02 for Metaculus, -0.02 for
PredictionBook) and
<a href="https://en.wikipedia.org/wiki/Slope">slopes</a>
of the <a href="https://en.wikipedia.org/wiki/Linear_regression">linear
regressions</a>
are close to 0.</li>
</ol></li>
<li> The timespan into the future at which our forecasts
become <em>approximately random</em> (the
<em><a href="#The_Horizon">horizon</a></em>) is <em>not easily estimated
from the data</em> (<a href="#This_Is_Cool">more</a>).
<ol>
<li> Fitting a logistic function
(<a href="##Fitting_a_Logistic_Function">more</a>), the
expected horizon is ~3.6 years for Metaculus
and ~18 years for PredictionBook</li>
<li> Fitting an exponential function
(<a href="#Fitting_an_Exponential_Function">more</a>),
the expected horizon is ~75 days for Metaculus,
and ~0.5 days for PredictionBook</li>
</ol></li>
</ol></li>
<li>Aggregating <strong>the forecasts on each question, and then comparing the
questions</strong> to one another (<a href="#Accuracy_Between_Questions">more</a>):
<ol>
<li> Questions with a longer range (that is, <em>time between the question
being written and the question being resolved</em>) generally receive
predictions with a higher accuracy than questions with a shorter
range (<a href="#Results_2">more</a>).
<ol>
<li> Again, the correlation coefficients (-0.01 for
Metaculus (though p&gt;0.8), and -0.05 for
PredictionBook) and the slopes of the linear
regressions are close to 0.</li>
</ol></li>
<li> The <a href="#The_Horizon">horizon</a> is <em>only a few days</em> in this
scenario (<a href="#NonLinear_CurveFitting_1">more</a>), which <a href="#Why_Longer_Range_Questions_More_Accurate">might
make sense</a>.</li>
</ol></li>
<li> Comparing <strong>only predictions on the same question</strong>, for all
questions (<a href="#Accuracy_Within_Questions">more</a>):
<ol>
<li> Predictions made <em>on the same question closer to
resolution time</em> are generally <em>more accurate</em> than
predictions that are made <em>long before resolution time</em>
(<a href="#Aggregating_Linear_Regressions">more</a>).</li>
<li> The distribution of horizons is
<em>long-tailed</em>, perhaps distributed logarithmically
(<a href="#Logistic_Forecast_Horizons_for_Questions">more</a> and
<a href="#Exponential_Forecast_Horizons_for_Questions">more</a>)
<ol>
<li>Most expected horizons are very short (&lt;10 days)</li>
<li> For logistic curve-fits, the mean horizon over
questions is improbably high (10²³ days)
(<a href="#Logistic_Forecast_Horizons_for_Questions">more</a>).</li>
<li> For exponential curve-fits, the mean
horizon over questions is ~4.5 years for
Metaculus and ~120 years for PredictionBook
(<a href="#Exponential_Forecast_Horizons_for_Questions">more</a>).</li>
</ol></li>
</ol></li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>Logistic fit horizon (PredictionBook)</th>
<th>Logistic fit horizon (Metaculus)</th>
<th>Exponential fit horizon (PredictionBook)</th>
<th>Exponential fit horizon (Metaculus)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Between Forecasts</td>
<td>18 years</td>
<td>3.6 years</td>
<td>75 days</td>
<td>1 day</td>
</tr>
<tr>
<td>Between Questions</td>
<td>4.5 days</td>
<td>1 day</td>
<td>9 days</td>
<td>&lt;1 day</td>
</tr>
<tr>
<td>Within Questions mean</td>
<td>1.08·10²¹ years</td>
<td>5.28·10²⁰ years</td>
<td>123.4 years</td>
<td>4.42 years</td>
</tr>
</tbody>
</table>
<p>These results suggest what to expect with questions with even greater
range: That later predictions (closer to resolution time) on them will
generally be more accurate, and that the kinds of questions with a
high range might engender predictions with an even higher accuracy than
questions with short and medium ranges.</p>
<p>However, there are plausible reasons to expect the trend from <em>2</em>.
to reverse: The questions asked with high range are not very
different from questions with medium range, and have a lot less
information available to make useful predictions on them; <a href="https://en.wikipedia.org/wiki/Butterfly_effect">butterfly
effects</a> start kicking
in systems that are relatively slow moving on human timescales (thus
easier to predict on medium timescales), but nearly completely random at
the scale of decades and/or centuries; the questions asked about longer
timescales are of a different kind and much less predictable.</p>
<p>Furthermore, estimating the length of forecast horizons has returned
ambiguous results, and more research in that area is needed. It appears
plausible that horizon lengths follow a logarithmic distribution, and
over all forecasts assume values of at most several decades.</p>
<!--TODO: in 1/2/5/10 years, will the linear regression coefficients for
these datasets still be positive/negative?-->
<p>I hope to update this analysis in the future, when data from predictions
with higher ranges has become available, and to check whether the findings
in this analysis continue to be correct.</p>
<h2 id="Related_Work"><a class="hanchor" href="#Related_Work">Related Work</a></h2>
<p><a href="https://rethinkpriorities.org/publications/data-on-forecasting-accuracy-across-different-time-horizons" title="Data on forecasting accuracy across different time horizons and levels of forecaster experience">Dillon
2021</a>
investigates the quality of predictions in relation to the number
of predictions a forecaster has made (finding that more experienced
forecasters are less overconfident), and investigates the relation between
Brier score and range; finding, as in this analysis, that surprisingly
predictions with longer horizons were <em>more accurate</em>. The latter finding
is likely not caused by more experienced forecasters making more
long-term predictions.</p>
<h2 id="Three_Different_Analyses_An_Illustrative_Example"><a class="hanchor" href="#Three_Different_Analyses_An_Illustrative_Example">Three Different Analyses: An Illustrative Example</a></h2>
<p>In this text, I analyze the relation between accuracy and range in
forecasting, considering three different aspects:</p>
<ul>
<li>Between forecasts</li>
<li>Between questions</li>
<li>Within questions</li>
</ul>
<p>What exactly does this mean?</p>
<p>Let's say there are two people: Bessie and Heloïse. They are trying
to make predictions about the weather about different time horizons
(it is currently midnight):</p>
<ol>
<li>Will it rain tomorrow? (resolution: no/0), which has a range of 1 day</li>
<li>Will the average temperature in a week be higher than 20°C? (resolution: no/0), which has a range of 7 days</li>
</ol>
<p>Let's say that they make the following predictions:</p>
<ul>
<li>Bessie: 0.3 for 1, 0.95 for 2</li>
<li>Heloïse: 0.1 for 1, 0.6 for 2</li>
</ul>
<p>Let's also say that they make their predictions in alphabetical order
of their names, eight hours after another (Bessie at 00:00 and Heloïse at
10:00).</p>
<p>The following chart shows that, in this scenario, later predictions on the
same question are more accurate, and also that predictions on questions
with a shorter range are more accurate (for simplicity's sake, I don't
use a <a href="https://en.wikipedia.org/wiki/Scoring_rule">proper scoring rule</a>
here to judge the accuracy of forecasts, but simply the probability
assigned to the correct outcome (here the vertical distance of the
probability to the outcome)).</p>
<p><img alt="Chart showing the forecasts on the day-range question and the week-range question. One can see that questions with a shorter range assign a higher probability to the correct outcome (i.e. 0), and also predictions on the question with the shorter range are more accurate." src="./img/range_and_forecasting_accuracy/example.png" title="Chart showing the forecasts on the day-range question and the week-range question. One can see that questions with a shorter range assign a higher probability to the correct outcome (i.e. 0), and also predictions on the question with the shorter range are more accurate."></p>
<h3 id="Judging_Between_Forecasts"><a class="hanchor" href="#Judging_Between_Forecasts">Judging Between Forecasts</a></h3>
<p>Evaluating the relation between forecasts would be as following: Each
forecast, its resolution and its timespan are independently analyzed.</p>
<p>We have four predictions:</p>
<ol>
<li>One with a range of 14 hours, a probability of 0.1 (Heloïse's prediction on 1), and a resolution of 0</li>
<li>One with a range of 24 hours, a probability of 0.3, (Bessie's prediction on 1) and a resolution of 0</li>
<li>One with a range of <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="24.529ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 10560.9 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">24h/d \cdot 7d-10h=158h</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-32"></use>
 <use xlink:href="#MJMAIN-34" x="500" y="0"></use>
 <use xlink:href="#MJMATHI-68" x="1001" y="0"></use>
 <use xlink:href="#MJMAIN-2F" x="1577" y="0"></use>
 <use xlink:href="#MJMATHI-64" x="2078" y="0"></use>
 <use xlink:href="#MJMAIN-22C5" x="2823" y="0"></use>
 <use xlink:href="#MJMAIN-37" x="3324" y="0"></use>
 <use xlink:href="#MJMATHI-64" x="3824" y="0"></use>
 <use xlink:href="#MJMAIN-2212" x="4570" y="0"></use>
<g transform="translate(5571,0)">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-30" x="500" y="0"></use>
</g>
 <use xlink:href="#MJMATHI-68" x="6572" y="0"></use>
 <use xlink:href="#MJMAIN-3D" x="7426" y="0"></use>
<g transform="translate(8482,0)">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-38" x="1001" y="0"></use>
</g>
 <use xlink:href="#MJMATHI-68" x="9984" y="0"></use>
</g>
</svg></span>, a probability of 0.6 (Heloïse's prediction on 2), and a resolution 0</li>
<li>One with a range of <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="18.024ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 7760.5 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-2-Title">
<title id="MathJax-SVG-2-Title">24h/d \cdot 7d=168h</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-32"></use>
 <use xlink:href="#MJMAIN-34" x="500" y="0"></use>
 <use xlink:href="#MJMATHI-68" x="1001" y="0"></use>
 <use xlink:href="#MJMAIN-2F" x="1577" y="0"></use>
 <use xlink:href="#MJMATHI-64" x="2078" y="0"></use>
 <use xlink:href="#MJMAIN-22C5" x="2823" y="0"></use>
 <use xlink:href="#MJMAIN-37" x="3324" y="0"></use>
 <use xlink:href="#MJMATHI-64" x="3824" y="0"></use>
 <use xlink:href="#MJMAIN-3D" x="4626" y="0"></use>
<g transform="translate(5682,0)">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-36" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-38" x="1001" y="0"></use>
</g>
 <use xlink:href="#MJMATHI-68" x="7183" y="0"></use>
</g>
</svg></span>, a probability of 0.95 (Bessie's prediction on 2), and a resolution 0</li>
</ol>
<p>The Brier scores for ranges are then 0.01 for 14h, 0.09 for 24h, 0.36
for 158h, and 0.9025 for 168h. Here, higher range between forecasts is
correlated with worse performance.</p>
<p>In the chart above, the relation of range and accuracy between forecasts
would be the black linear regression.</p>
<h3 id="Judging_Between_Questions"><a class="hanchor" href="#Judging_Between_Questions">Judging Between Questions</a></h3>
<p>Judging the performance between questions now means looking at the
forecasts made on each question and evaluating the performance
of forecasts on that question.</p>
<p>Question 1 has a range of 24h, and question 2 has a range of 168h.
The Brier score for predictions on question 1 is 0.05, and the Brier
score for predictions on question 2 is 0.63125. In this case, a higher
range seems to be worse for performance on questions (Brier scores are
lower/better for question 1).</p>
<p>In the chart above, the relation between range and accuracy between
questions would be the mauve line (which here turns out to be nearly
identical to the relation between range and accuracy between forecasts).</p>
<h3 id="Judging_Within_Questions"><a class="hanchor" href="#Judging_Within_Questions">Judging Within Questions</a></h3>
<p>Within questions one examines each question separately.</p>
<p>On question 1, the forecast with the higher range has a Brier score of
0.09, and the forecast with the lower range has a brier score of 0.01. So
for question 1, higher range is correlated with worse performance.</p>
<p>For question 2, it is similar, the forecast with the higher range (168h)
has a score of 0.9025, while the forecast with the lower range (158h)
has a score of 0.36. Here also higher range is correlated with worse
performance.</p>
<p>One can now try to aggregate the findings from the two questions and
could tentatively conclude that generally range within questions is
correlated negatively with accuracy of forecasts.</p>
<p>In the chart above, the relation between range and accuracy within
questions would be the cyan and mustard linear regressions.</p>
<hr>
<p>These were of course only illustrative examples, but I hope that now
the different approaches in this text are clearer than before.</p>
<p>If you're busy, you can stop reading here (or re-read <a href="#Results">the results
section</a>). This is a natural place to stop reading, everything
below is certainly interesting, but not central to understanding.</p>
<h2 id="Metaculus_and_PredictionBook"><a class="hanchor" href="#Metaculus_and_PredictionBook">Metaculus and PredictionBook</a></h2>
<p><a href="https://predictionbook.com">PredictionBook</a> and
<a href="https://www.metaculus.com">Metaculus</a> are both forecasting websites
for hobbyists.  They are not prediction markets, but rather function
on the base of merit and track records: although you don't win money
by being right, you can still boast about it (it is an open question
whether other people will be impressed). Besides that, these sites make
it easier to train ones calibration on real-world questions and become
less wrong in the process.</p>
<p>However, both sites differ in their approach to writing questions
and judging and scoring forecasts. PredictionBook is much older than
Metaculus: the former was first released in 2008, the latter started in 2015.
It is also much less formal than Metaculus: it doesn't require
stringent resolution criteria, making possible for everybody to judge
a question (unrelated to whether the person has even made a prediction
on the question themselves!), while Metaculus requires a short text
explaining the context and resolution criteria for a question, with
the questions being resolved by moderators or admins. This leads to
Metaculus having fewer questions than PredictionBook, but each question
having more predictions on it. Of the two, Metaculus is much more
featureful: It supports not only binary questions, but also range
questions with probability distributions, comment threads, closed
questions (questions that haven't yet been resolved, but that can't
be predicted on), three different kinds of scores (the
<a href="https://en.wikipedia.org/wiki/Brier_score">Brier score</a>,
and a <a href="https://en.wikipedia.org/wiki/Scoring_rule#Logarithmic_scoring_rule">logarithmic scoring
rule</a>
for discrete and continuous forecasts each), as well as the Metaculus
prediction, a weighted aggregation of the forecasts of the best
forecasters on the site.</p>
<p>Another significant difference between these two websites is the amount of
data they publish: PredictionBook shows every single forecast made, while
on Metaculus one can only see the community forecast (a the time-weighted
median of the forecasts made on the question). This is relevant for this
analysis: The two approaches must be analysed separately.</p>
<h2 id="Getting_the_Data"><a class="hanchor" href="#Getting_the_Data">Getting the Data</a></h2>
<p>First of all, the data for both platforms needs to be made available in
a reasonable format. This works nicer for Metaculus, and is a bit more
difficult to achieve for PredictionBook.</p>
<p>The resulting data from Metaculus is <a href="./data/met.csv">here</a>, for
PredictionBook it's available <a href="./data/pb.csv">here</a>.</p>
<h3 id="For_Metaculus"><a class="hanchor" href="#For_Metaculus">For Metaculus</a></h3>
<p>The Metaculus data is relatively easy to obtain:
The forecasts are available on a JSON API at
<code>https://www.metaculus.com/api2/questions/?page=</code>. Fortunately,
<a href="https://github.com/gimpf/">gimpf</a> has already published <a href="https://github.com/gimpf/Metaculus-question-stats">a collection of
scripts</a> for fetching &amp;
analysing Metaculus data. I reused their script <code>fetch</code> to download the
raw JSON. I then converted the distinct page objects in the generated
file to a list of questions:</p>
<pre><code>$ cd /usr/local/src
$ git clone https://github.com/gimpf/Metaculus-question-stats
$ cd Metaculus-question-stats
$ ./fetch
$ z site
$ jq -s '[.]|flatten' &lt;/usr/local/src/Metaculus/data-questions-raw.json &gt;data/metaculus.json
</code></pre>
<p>I then wrote a python script to convert the JSON data to CSV in the form
<code>id,questionrange,result,probability,range</code>, while also filtering out
yet unresolved questions and range questions. Here, <code>id</code> is a unique
numerical ID per question, which will come in handy later, <code>questionrange</code>
is the duration between the time for creating and resolving the question,
<code>result</code> is the result of the question (either 0 or 1), <code>probability</code>
is the probability given by the predictor <code>$]0;1[$</code>, and <code>range</code> is the
duration between the forecast and the resolution.</p>
<p>The script is not terribly interesting: It just reads in the JSON data,
parses and traverses it, printing the CSV in the process.</p>
<p>Code:</p>
<pre><code>#!/usr/bin/env python3

import json
import time

from time import mktime

f=open("../../data/metaculus.json")
jsondata=json.load(f)

for page in jsondata:
    for question in page["results"]:
        if question["possibilities"]["type"]=="binary" and (question["resolution"]==1 or question["resolution"]==0):
            try:
                restime=time.strptime(question["resolve_time"],"%Y-%m-%dT%H:%M:%S.%fZ")
            except:
                restime=time.strptime(question["resolve_time"],"%Y-%m-%dT%H:%M:%SZ")
            try:
                createtime=time.strptime(question["created_time"],"%Y-%m-%dT%H:%M:%S.%fZ")
            except:
                createtime=time.strptime(question["created_time"],"%Y-%m-%dT%H:%M:%SZ")
            for pred in question["prediction_timeseries"]:
                timediff=mktime(restime)-pred["t"]
                qtimediff=mktime(restime)-mktime(createtime)
                print("{},{},{},{},{}".format(question["id"], qtimediff, question["resolution"], pred["community_prediction"], timediff))
</code></pre>
<p>The resulting CSV file contains nearly 50k predictions.</p>
<h3 id="For_PredictionBook"><a class="hanchor" href="#For_PredictionBook">For PredictionBook</a></h3>
<p>PredictionBook publishes its data over an
<a href="https://github.com/bellroy/predictionbook/blob/master/API.html">API</a>,
which I will use in the future to get hold of the data.</p>
<p>Not knowing this when I initially wrote the code, I regressed
to barbaric behavior: I knew that all individual predictions are
visible on the web, which means I had to parse the HTML itself using
<a href="https://en.wikipedia.org/wiki/Beautiful_Soup_(HTML_parser)">BeautifulSoup</a>.</p>
<p>This time the code is more complex, but just slightly so: It starts at
the <a href="https://predictionbook.com/predictions/page/1">first page</a>
of predictions, and loops down to the <a href="https://predictionbook.com/predictions/page/326">last
one</a>, every time iterating
through the questions on that page.</p>
<p>It then loops through the predictions on each question and parses out
the date for the prediction and the credence.</p>
<p>Every question on PredictionBook has two dates related to its
resolution: the 'known on' date, for which the resolution was originally
planned, and by which the result should be known, and the 'judged on'
date, on which the resolution was actually made. I take the second date
to avoid predictions with negative differences between prediction and
resolution time.</p>
<!--
Also, the 'known on' date has the CSS class `date created_at`, which
doesn't seem right.
TODO: submit pull request to fix this.
-->
<p>The output of this script is in the same format as the one for Metaculus
data: <code>id,questionrange,result,probability,range</code> (although here
<code>probability</code> can also be 0 and 1, which Metaculus doesn't allow).</p>
<p>Code:</p>
<pre><code>#!/usr/bin/env python2

import urllib2
import sys
import time

from bs4 import BeautifulSoup
from time import mktime

def showforecasts(linkp, res):
    urlp="https://predictionbook.com{}".format(linkp)
    reqp=urllib2.Request(urlp, headers={"User-Agent" : "Firefox"})
    try:
        conp=urllib2.urlopen(reqp, timeout=10)
    except (urllib2.HTTPError, urllib2.URLError) as e:
        return
    datap=conp.read()
    soupp=BeautifulSoup(datap, "html.parser")

    timedata=soupp.find(lambda tag:tag.name=="p" and "Created by" in tag.text)
    resolved=timedata.find("span", class_="judgement").find("span", class_="date created_at").get("title")
    restime=time.strptime(resolved,"%Y-%m-%d %H:%M:%S UTC")
    created=timedata.find("span", class_="date").get("title")
    createtime=time.strptime(created,"%Y-%m-%d %H:%M:%S UTC")

    responses=soupp.find_all("li", class_="response")
    for r in responses:
        forecasts=r.find_all("span", class_="confidence")
        if forecasts!=[]:
            est=float(r.find_all("span", class_="confidence")[0].text.strip("%"))/100
        else:
            continue
        estimated=r.find("span", class_="date").get("title")
        esttime=time.strptime(estimated,"%Y-%m-%d %H:%M:%S UTC")
        print("{},{},{},{},{}".format(linkp.replace("/predictions/", ""), mktime(restime)-mktime(createtime), res, est, mktime(restime)-mktime(esttime)))

for page in range(1,400):
    url="https://predictionbook.com/predictions/page/{}".format(page)
    req=urllib2.Request(url, headers={"User-Agent" : "Firefox"})
    try:
        con=urllib2.urlopen(req)
    except (urllib2.HTTPError, urllib2.URLError) as e:
        continue
    data=con.read()
    soup=BeautifulSoup(data, "html.parser")
    predright=soup.find_all("li", {"class": "prediction right"})
    predwrong=soup.find_all("li", {"class": "prediction wrong"})
    for pred in predright:
        linkp=pred.span.a.get("href")
        showforecasts(linkp, "1.0")
    for pred in predwrong:
        linkp=pred.span.a.get("href")
        showforecasts(linkp, "0.0")
</code></pre>
<p>Surprisingly, both platforms had almost the same amount of individual
predictions on binary resolved questions: ~48k for Metaculus, and ~44k
for PredictionBook.</p>
<h2 id="Accuracy_Between_Forecasts"><a class="hanchor" href="#Accuracy_Between_Forecasts">Accuracy Between Forecasts</a></h2>
<p>The first approach I took was to simply take the probability and result
for each forecast, and calculate the Brier score for that one probability.
I then calculated the <a href="https://en.wikipedia.org/wiki/correlation_and_dependence">correlation</a> and the linear regression between that
Brier score and the range of the forecast.</p>
<h3 id="Analysis"><a class="hanchor" href="#Analysis">Analysis</a></h3>
<p>Now that the two datasets are available, they can be properly analyzed.</p>
<p>First, the raw data is loaded from the two CSV files, removing the first
line (the names of the variables, for other languages such as R). Then
the ID is converted to integer, and the rest of the fields are converted
to floats (the range is a float for some Metaculus questions, and while
the result can only take on 0 or 1, using float there makes it easier
to calculate the brier score later). After that, npegative ranges are
removed from the dataset, and ranges are converted from seconds to days,
making them slightly easier to plot:</p>
<pre><code>import csv
import numpy as np
import scipy.stats as sps
import scipy.optimize as spo

daysec=24*60*60

def getpreds(s):
    pfile=open(s)
    predreader=csv.reader(pfile)
    preds=[]
    for entry in predreader:
        if entry[0][0]=="#":
            continue
        else:
            preds.append([int(entry[0]), float(entry[1])/daysec, float(entry[2]), float(entry[3]), float(entry[4])/daysec])
    preds=list(filter(lambda x: x[4]&gt;0, preds))
    return np.array(preds).T

pb=getpreds("../../data/pb.csv")
met=getpreds("../../data/met.csv")
</code></pre>
<h4 id="Why_Some_Negative_Ranges"><a class="hanchor" href="#Why_Some_Negative_Ranges">Why Some Negative Ranges?</a></h4>
<p>This code filters out forecast ranges smaller than 0, which is necessary
because the data contains some forecasts with negative ranges. These
stem from two different sources:</p>
<p>In the Metaculus data, these are forecasts on questions that have resolved
retroactively. These occur in the scenario where forecasters predict on a
question where the resolution time is not clear, and the resolution occurs
before the question closes. To prevent an unfair advantage of people who
predicted while the resolution was unfolding (and therefore predicting on
an event that had happened in the past), the resolution date is set some
timespan before the resolving event (e.g. a day). However, the predictions
after the retroactive resolution are still included in the data.</p>
<p>Examples:</p>
<ul>
<li><a href="https://www.metaculus.com/questions/2926/will-iran-execute-or-be-targeted-in-a-national-military-attack-between-6-june-2019-and-5-october-2019/">Will Iran execute or be targeted in a national military attack between 6 June 2019 and 5 October 2019?</a></li>
<li><a href="https://www.metaculus.com/questions/3756/will-ea-global-san-francisco-be-cancelled-or-rescheduled-due-to-covid-19/">Will EA Global San Francisco be cancelled or rescheduled due to COVID-19?</a></li>
</ul>
<p>For PredictionBook, users can still predict after any resolution. The
script fetches the first resolution, making some predictions retroactive.
I could instead retrieve the result of the last resolution, but I don't
think it would be worth the effort, or improve the quality of the data
very much.</p>
<p>Examples:</p>
<ul>
<li><a href="https://predictionbook.com/predictions/198593">Total deaths due to coronavirus in the Netherlands will go over &gt;5000 by the end of April.</a></li>
<li><a href="https://predictionbook.com/predictions/155">Matt will be happy he will no longer be able to be instantly Rick rolled</a></li>
</ul>
<!--TODO: try this, and report back-->
<hr>
<p>In the next step, I extract the individual variables from the data
and give them names (handling the various indices is tiresome after
a while). <code>ress</code> stands for results, <code>fcs</code> for forecasts, and <code>rngs</code>
for ranges:</p>
<pre><code>pbress=pb[2]
pbfcs=pb[3]
pbrngs=pb[4]

metress=met[2]
metfcs=met[3]
metrngs=met[4]
</code></pre>
<p>The <a href="https://en.wikipedia.org/wiki/Brier_score">Brier Score</a> is a
scoring rule for binary forecasts. It takes into account both the
calibration and resolution of forecasts by calculating the <a href="https://en.wikipedia.org/wiki/Mean_squared_error">mean squared
error</a> of forecasts
(<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.965ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 846.1 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-3-Title">
<title id="MathJax-SVG-3-Title">f_{t}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-66" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-74" x="693" y="-213"></use>
</g>
</svg></span>) and outcomes (<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.954ex" height="2.009ex" style="vertical-align: -0.671ex;" viewBox="0 -576.1 841.1 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-4-Title">
<title id="MathJax-SVG-4-Title">o_{t}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-6F" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-74" x="686" y="-213"></use>
</g>
</svg></span>):</p>
<div>
    <span class="mjpage mjpage__block"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.626ex" height="7.343ex" style="vertical-align: -3.005ex;" viewBox="0 -1867.7 9741.8 3161.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-5-Title">
<title id="MathJax-SVG-5-Title">BS=\frac{1}{N}\sum_{t=1}^{N}(f_{t}-o_{t})^{2}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-42" x="0" y="0"></use>
 <use xlink:href="#MJMATHI-53" x="759" y="0"></use>
 <use xlink:href="#MJMAIN-3D" x="1682" y="0"></use>
<g transform="translate(2461,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="1008" height="60" x="0" y="220"></rect>
 <use xlink:href="#MJMAIN-31" x="254" y="676"></use>
 <use xlink:href="#MJMATHI-4E" x="60" y="-704"></use>
</g>
</g>
<g transform="translate(4154,0)">
 <use xlink:href="#MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(142,-1090)">
 <use transform="scale(0.707)" xlink:href="#MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-3D" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-31" x="1140" y="0"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-4E" x="577" y="1627"></use>
</g>
 <use xlink:href="#MJMAIN-28" x="5598" y="0"></use>
<g transform="translate(5988,0)">
 <use xlink:href="#MJMATHI-66" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-74" x="693" y="-213"></use>
</g>
 <use xlink:href="#MJMAIN-2212" x="7056" y="0"></use>
<g transform="translate(8057,0)">
 <use xlink:href="#MJMATHI-6F" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-74" x="686" y="-213"></use>
</g>
<g transform="translate(8898,0)">
 <use xlink:href="#MJMAIN-29" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-32" x="550" y="583"></use>
</g>
</g>
</svg></span>
</div>
<!--TODO: isn't there some function that implements the mean squared
error in numpy‽-->
<p>The Brier score is quite easy to implement:</p>
<pre><code>def brier(x, y):
    return np.mean((x-y)**2)
</code></pre>
<p>The first thing we can now do is to compare the forecasts from the
two websites, and it turns out that Metaculus forecasts are slightly
<em>less</em> good than PredictionBook forecasts:</p>
<pre><code>&gt;&gt;&gt; brier(metfcs, metress)
0.17085016230074224
&gt;&gt;&gt; brier(pbfcs, pbress)
0.16073690328405374
</code></pre>
<p>But this comparison is not telling us much, since the
questions on the two websites and the strictness for
resolving questions are radically different, as explained
<a href="./range_and_forecasting_accuracy.html#Limitations">here</a>.</p>
<p>Now, one can calculate the Brier score for each of the forecasts and
outcomes, with the mean being unnecessary, because we want to examine
the score of each forecast individually:</p>
<pre><code>pbbriers=(pbfcs-pbress)**2
metbriers=(metfcs-metress)**2
</code></pre>
<h3 id="Results_1"><a class="hanchor" href="#Results_1">Results</a></h3>
<p>First, one can check how high the range of these two datasets really is.
The PredictionBook forecasts with the highest range span 3730 days
(more than 10 years), for Metaculus it's 1387 days (nearly 4 years):</p>
<pre><code>&gt;&gt;&gt; np.max(metrngs)
1387.018779324351
&gt;&gt;&gt; np.max(pbrngs)
3730.0094560185184
</code></pre>
<p>One can now look at the correlation between range and Brier score first
for Metaculus, and then for PredictionBook:</p>
<pre><code>&gt;&gt;&gt; np.corrcoef(metbriers, metrngs)
array([[1.        , 0.02165924],
    [0.02165924, 1.        ]])
&gt;&gt;&gt; np.corrcoef(pbbriers, pbrngs)
array([[ 1.        , -0.02030743],
    [-0.02030743,  1.        ]])
</code></pre>
<p>For Metaculus, the results are not surprising: The positive correlation
tells us that the higher the range of a forecast, the lower the accuracy
(or, poetically, at Metaculus the fogs of time grow thicker the farther
you want to look into the future).</p>
<p>However, for PredictionBook, the opposite is true (on this dataset):
Forecasts with higher ranges give more accurate predictions, at least
on average.</p>
<p>However, these correlations are quite weak, 0.02 could just be random
noise. I would have to use a significance test to discern whether they
are statistically significant.</p>
<p>Now, one can also perform a linear regression to gauge what the relation
of range and accuracy of a forecast is:</p>
<pre><code>&gt;&gt;&gt; sps.linregress(metrngs, metbriers)
LinregressResult(slope=1.4921976403559925e-05, intercept=0.16753867328019442, rvalue=0.021659238937630332, pvalue=1.89939817752528e-06, stderr=3.1319561138899387e-06)
&gt;&gt;&gt; sps.linregress(pbrngs, pbbriers)
LinregressResult(slope=-8.921762030379796e-06, intercept=0.16351703198845793, rvalue=-0.020307433721919746, pvalue=1.913246393632673e-05, stderr=2.0868414512480246e-06)
</code></pre>
<p>We can see that the <code>rvalue</code> is just the correlation, and that the
<code>pvalue</code> is pretty good (&lt;0.00001 and &lt;.0001 for Metaculus and
PredictionBook, respectively).</p>
<p>These are not particularly surprising. The inferred brier score at range
0 (the forecast directly before resolution) is ~0.16, which seems a bit
pessimistic, but other than that, growth with higher ranges for Metaculus
data and lower accuracy for higher ranges for PredictionBook data match
the correlation. The steepness of the regression is quite low because
the ranges are in days.</p>
<p>Visualizing the accuracies of the forecasts with a
<a href="https://en.wikipedia.org/wiki/Scatter_plot">scatterplot</a> and <a href="https://en.wikipedia.org/wiki/Linear_regression">linear
regressions</a> shows a
similar picture (red dots are for Metaculus forecasts, blue dots are
for PredictionBook forecasts):</p>
<pre><code>fig=plt.figure(figsize=(8,8))
plt.xlabel("Range (days)")
plt.ylabel("Accuracy (Brier score)")

plt.plot(metrngs, metbriers, '.', color='red', markersize=1)
plt.plot(pbrngs, pbbriers, '.', color='blue', markersize=1)

plt.savefig("allscatter.png")
</code></pre>
<p><img alt="Scatterplot with linear regression for Metaculus &amp; PredictionBook forecasts by range (in days)" src="./img/range_and_forecasting_accuracy/allscatter.png" title="Scatterplot with linear regression for Metaculus &amp; PredictionBook forecasts by range (in days)"></p>
<p>The high amounts of noise are probably due to the low number of
predictions for single days (or, in the case of weeks and months, for
years/months with a high range, as not enough questions with this range
have resolved yet).</p>
<h4 id="NonLinear_CurveFitting"><a class="hanchor" href="#NonLinear_CurveFitting">Non-Linear Curve-Fitting</a></h4>
<!--TODO: MSE of the fits-->
<p>Using a linear regression on the Brier score here, however, carries
with it a deep issue: Unless the slope is 0, the linear regression will
be below 0 or above 1 for some positive range—so one can't use it to
predict forecaster performance on questions with very long ranges.</p>
<p>(There is also the additional issue that in non-0-slope regressions,
the linear regression might tell us that forecasters would perform <em>worse
than chance</em> at some point in the future, that is, give an expected Brier
score <code>&gt;0.25</code>, which is not what I expect to happen, unless reality is
actively preventing us from making accurate long-term predictions).</p>
<p>Instead, I want to use functions that for positive values of <code>x</code> don't
produce out-of-bounds errors (they at least return valid Brier scores).</p>
<p>I furthermore make some additional assumptions/desiderata about the function
<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.049ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 451.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-6-Title">
<title id="MathJax-SVG-6-Title">r</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-72" x="0" y="0"></use>
</g>
</svg></span> to fit to the data:</p>
<ol>
<li>For <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.591ex" height="2.343ex" style="vertical-align: -0.505ex;" viewBox="0 -791.3 2407.1 1008.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-7-Title">
<title id="MathJax-SVG-7-Title">x \ge 0</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-78" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-2265" x="850" y="0"></use>
 <use xlink:href="#MJMAIN-30" x="1906" y="0"></use>
</g>
</svg></span>, it returns values in <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.624ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 3282.7 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-8-Title">
<title id="MathJax-SVG-8-Title">[0, 0.25]</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-5B" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-30" x="278" y="0"></use>
 <use xlink:href="#MJMAIN-2C" x="779" y="0"></use>
<g transform="translate(1224,0)">
 <use xlink:href="#MJMAIN-30"></use>
 <use xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-32" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-35" x="1279" y="0"></use>
</g>
 <use xlink:href="#MJMAIN-5D" x="3004" y="0"></use>
</g>
</svg></span></li>
<li>For <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.591ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 2407.1 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-9-Title">
<title id="MathJax-SVG-9-Title">x=0</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-78" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-3D" x="850" y="0"></use>
 <use xlink:href="#MJMAIN-30" x="1906" y="0"></use>
</g>
</svg></span>, it returns <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.162ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 500.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-10-Title">
<title id="MathJax-SVG-10-Title">0</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-30" x="0" y="0"></use>
</g>
</svg></span> (at the time of resolution, we can predict the outcome perfectly, because we already know it)
<ol>
<li>It'd be technically elegant if for <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.449ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 3637.6 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-11-Title">
<title id="MathJax-SVG-11-Title">r(x)=0</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-72" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-28" x="451" y="0"></use>
 <use xlink:href="#MJMATHI-78" x="841" y="0"></use>
 <use xlink:href="#MJMAIN-29" x="1413" y="0"></use>
 <use xlink:href="#MJMAIN-3D" x="2080" y="0"></use>
 <use xlink:href="#MJMAIN-30" x="3137" y="0"></use>
</g>
</svg></span> for <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.591ex" height="2.343ex" style="vertical-align: -0.505ex;" viewBox="0 -791.3 2407.1 1008.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-12-Title">
<title id="MathJax-SVG-12-Title">x \le 0</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-78" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-2264" x="850" y="0"></use>
 <use xlink:href="#MJMAIN-30" x="1906" y="0"></use>
</g>
</svg></span> (since we can perfectly predict things from the past (although there's a philosophical discussion to be had here about how much we can actually know things from the past, and maybe it's even symmetric with the future)), but it's not super important</li>
</ol></li>
<li><span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.049ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 451.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-13-Title">
<title id="MathJax-SVG-13-Title">r</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-72" x="0" y="0"></use>
</g>
</svg></span> is <a href="https://en.wikipedia.org/wiki/Monotonic_function">monotonic</a> for <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.591ex" height="2.343ex" style="vertical-align: -0.505ex;" viewBox="0 -791.3 2407.1 1008.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-14-Title">
<title id="MathJax-SVG-14-Title">x \ge 0</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-78" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-2265" x="850" y="0"></use>
 <use xlink:href="#MJMAIN-30" x="1906" y="0"></use>
</g>
</svg></span>, that is <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="25.063ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 10790.8 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-15-Title">
<title id="MathJax-SVG-15-Title">x_1&gt;x_2 \Rightarrow r(x_1) \ge r(x_2)</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-31" x="809" y="-213"></use>
 <use xlink:href="#MJMAIN-3E" x="1304" y="0"></use>
<g transform="translate(2360,0)">
 <use xlink:href="#MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-32" x="809" y="-213"></use>
</g>
 <use xlink:href="#MJMAIN-21D2" x="3664" y="0"></use>
 <use xlink:href="#MJMATHI-72" x="4942" y="0"></use>
 <use xlink:href="#MJMAIN-28" x="5394" y="0"></use>
<g transform="translate(5783,0)">
 <use xlink:href="#MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#MJMAIN-29" x="6810" y="0"></use>
 <use xlink:href="#MJMAIN-2265" x="7477" y="0"></use>
 <use xlink:href="#MJMATHI-72" x="8533" y="0"></use>
 <use xlink:href="#MJMAIN-28" x="8985" y="0"></use>
<g transform="translate(9374,0)">
 <use xlink:href="#MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-32" x="809" y="-213"></use>
</g>
 <use xlink:href="#MJMAIN-29" x="10401" y="0"></use>
</g>
</svg></span>
<ol>
<li>This is the one I'd be most willing to drop, since there might be <a href="#Why_Assume_Accuracy_will_Increase">weird non-monotonic effects</a> in ability to predict.</li>
</ol></li>
</ol>
<h5 id="Fitting_a_Logistic_Function"><a class="hanchor" href="#Fitting_a_Logistic_Function">Fitting a Logistic Function</a></h5>
<p>The logistic function seems like an optimal candidate here: it fulfills
at least desideratum 1 (if shrunk) and 3, and with some fiddling may
even satisfy 2.</p>
<!--TODO: link Armstrong https://www.lesswrong.com/posts/6tErqpd2tDcpiBrX9/why-sigmoids-are-so-hard-to-predict on the problem of fitting sigmoids here!-->
<p>Because this is different from a <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic
regression</a> (scaled
values above the maximum (with a maximum of 0.25, some of the observed
Brier scores are greater), continuous values to predict), I curve-fit
explicitly using <code>scipy.optimize.curve_fit</code> (why did I only learn about
this function from scrolling through the scipy documentation‽ This
<a href="./notes.html#scipyoptimizecurvefit_Is_Awesome">is awesome</a>!) with
two parameters.</p>
<p>(Why not do a linear regression on the log-transformed data? Because
the corresponding transformation ends up with 0 inside a logarithm for
PredictionBook data: The inverse logistic is <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.447ex" height="3.676ex" style="vertical-align: -1.338ex;" viewBox="0 -1006.6 4498 1582.7" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-16-Title">
<title id="MathJax-SVG-16-Title">\log(\frac{1}{p}-1)</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-6C"></use>
 <use xlink:href="#MJMAIN-6F" x="278" y="0"></use>
 <use xlink:href="#MJMAIN-67" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-28" x="1279" y="0"></use>
<g transform="translate(1669,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="476" height="60" x="0" y="220"></rect>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-31" x="86" y="629"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-70" x="84" y="-488"></use>
</g>
</g>
 <use xlink:href="#MJMAIN-2212" x="2607" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="3607" y="0"></use>
 <use xlink:href="#MJMAIN-29" x="4108" y="0"></use>
</g>
</svg></span>,
and some PredictionBook Brier scores are 1).</p>
<p>So we instead use the following formula, which is just a squashed
logistic function that the maximum is at 0.25:</p>
<pre><code>def shrunk_logistic(x, slope, intercept):
    return 0.25*1/(1+np.exp(slope*x+intercept))
</code></pre>
<p>We can now fit a curve with those parameters to the data, limiting
the slope to negative values and the intercept to positive values
(we want the function to be <em>monotonically rising</em>, and we want the
<a href="https://en.wikipedia.org/wiki/y-intercept">y-intercept</a> to be below
0.125, that is we want the "middle" of the logistic function to be to the
right of 0, even if we can't guarantee that the function will be ~0 for
<code>x=0</code>).</p>
<pre><code>&gt;&gt;&gt; pblogifit=spo.curve_fit(shrunk_logistic, pbrngs, pbbriers, bounds=([-np.inf, 0], [0, np.inf]))
(array([-4.78706654e-04,  1.40345975e-20]), array([[ 1.69607043e-09, -4.52668529e-07],
    [-4.52668529e-07,  4.22860649e-04]]))
&gt;&gt;&gt; metlogifit=spo.curve_fit(shrunk_logistic, metrngs, metbriers, bounds=([-np.inf, 0], [0, np.inf]))
(array([-2.37260045e-03,  3.97380474e-19]), array([[ 7.35951274e-09, -1.08226199e-06],
    [-1.08226199e-06,  3.59766672e-04]]))
</code></pre>
<p>The result can be plotted:</p>
<pre><code>fig=plt.figure(figsize=(8,8))

plt.title("Scatterplot with logistic-ish regression for Metaculus &amp; PredictionBook forecasts by range (in days)")
plt.xlabel("Range (days)")
plt.ylabel("Accuracy (Brier score)")

fullrng=np.array(range(0, round(max(pbrngs))+1))

plt.plot(metrngs, metbriers, '.', color='red', markersize=1)
plt.plot(fullrng, shrunk_logistic(fullrng, metlogifit[0][0], metlogifit[0][1]), 'red', label='Metaculus shrunk logistic-ish regression', linewidth=2)
plt.plot(pbrngs, pbbriers, '.', color='blue', markersize=1)
plt.plot(fullrng, shrunk_logistic(fullrng, pblogifit[0][0], pblogifit[0][1]), 'blue', label='PredictionBook shrunk logistic-ish regression', linewidth=2)

plt.legend()

plt.savefig("allscatter_logi.png")
</code></pre>
<p><img alt="Scatter-plot of Metaculus &amp; PredictionBook data, with logistic-ish regressions (as described above)." src="./img/range_and_forecasting_accuracy/allscatter_logi.png" title="Scatter-plot of Metaculus &amp; PredictionBook data, with logistic-ish regressions (as described above). Both plots start at 0.125, and approach 0.25, but the Metaculus plot does so far quicker (=0.25 at ~1500 days), while the PredictionBook regression hasn't reached 0.25 by day ~4000"></p>
<p>I wonder whether the reason the Metaculus fit reaches the Metaculus
data so much faster is because the Metaculus data ends earlier? (Also,
yes, that is the logistic function and not a linear function for the
PredictionBook data, it's a really moderate slope).</p>
<p>Also, both plots start out with <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="12.416ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 5345.6 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-17-Title">
<title id="MathJax-SVG-17-Title">r(0)=0.125</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-72" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-28" x="451" y="0"></use>
 <use xlink:href="#MJMAIN-30" x="841" y="0"></use>
 <use xlink:href="#MJMAIN-29" x="1341" y="0"></use>
 <use xlink:href="#MJMAIN-3D" x="2008" y="0"></use>
<g transform="translate(3065,0)">
 <use xlink:href="#MJMAIN-30"></use>
 <use xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-32" x="1279" y="0"></use>
 <use xlink:href="#MJMAIN-35" x="1780" y="0"></use>
</g>
</g>
</svg></span>: not restricting the
intercept to positive values returns negative intercepts (meaning that
at 0, the value is of the logistic function is even higher than (in this
case) 0.125):</p>
<pre><code>&gt;&gt;&gt; pblogifit=spo.curve_fit(shrunk_logistic, pbrngs, pbbriers, bounds=([-np.inf, -np.inf], [0, np.inf]))
(array([-1.12830197e-14, -5.87766698e-01]), array([[ 1.32206792e-09, -4.11999218e-07],
    [-4.11999218e-07,  4.67829989e-04]]))
&gt;&gt;&gt; shrunk_logistic(0, -1.12830197e-1, -5.87766698e-01)
0.16071313965158385
&gt;&gt;&gt; metlogifit=spo.curve_fit(shrunk_logistic, metrngs, metbriers, bounds=([-np.inf, -np.inf], [0, np.inf]))
(array([-3.05026968e-04, -7.03162493e-01]), array([[ 3.73762741e-09, -7.74711069e-07],
    [-7.74711069e-07,  3.76596526e-04]]))
&gt;&gt;&gt; shrunk_logistic(0, -3.05026968e-04, -7.03162493e-01)
0.1672221410619337
</code></pre>
<p>Here, the slopes are much steeper than in the more restricted case above.</p>
<h5 id="Fitting_an_Exponential_Function"><a class="hanchor" href="#Fitting_an_Exponential_Function">Fitting an Exponential Function</a></h5>
<!--TODO: a is actually unnecessary, cut it out-->
<p>Another function we could fit to the data might be of the form
<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.57ex" height="4.009ex" style="vertical-align: -1.338ex;" viewBox="0 -1150.1 1967.5 1726.2" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-18-Title">
<title id="MathJax-SVG-18-Title">\frac{b^x -1}{-4}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(120,0)">
<rect stroke="none" width="1727" height="60" x="0" y="220"></rect>
<g transform="translate(60,503)">
 <use transform="scale(0.707)" xlink:href="#MJMATHI-62" x="0" y="0"></use>
 <use transform="scale(0.574)" xlink:href="#MJMATHI-78" x="529" y="469"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-2212" x="994" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-31" x="1772" y="0"></use>
</g>
<g transform="translate(411,-424)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34" x="778" y="0"></use>
</g>
</g>
</g>
</svg></span>, with some <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.006ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 3877.7 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-19-Title">
<title id="MathJax-SVG-19-Title">b \in (0, 1)</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-62" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-2208" x="707" y="0"></use>
 <use xlink:href="#MJMAIN-28" x="1652" y="0"></use>
 <use xlink:href="#MJMAIN-30" x="2042" y="0"></use>
 <use xlink:href="#MJMAIN-2C" x="2542" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="2987" y="0"></use>
 <use xlink:href="#MJMAIN-29" x="3488" y="0"></use>
</g>
</svg></span> (the function is
decaying exponentially, but flipped so that it approaches 0, and then
we scale it so that it always converges toward 0.25).</p>
<p>We can guarantee this function to fulfill all three desiderata:</p>
<div>
    <span class="mjpage mjpage__block"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="100ex" height="11.843ex" style="vertical-align: -8.005ex; max-width: 60000px;" viewBox="0 -1652.5 43055.4 5098.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-20-Title">
<title id="MathJax-SVG-20-Title">\frac{b^0 - 1}{-4}=\\
    =\frac{0}{-4}=0</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(19516,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="2726" height="60" x="0" y="220"></rect>
<g transform="translate(60,676)">
 <use xlink:href="#MJMATHI-62" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="607" y="513"></use>
 <use xlink:href="#MJMAIN-2212" x="1105" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="2106" y="0"></use>
</g>
<g transform="translate(723,-698)">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-34" x="778" y="0"></use>
</g>
</g>
 <use xlink:href="#MJMAIN-3D" x="3244" y="0"></use>
</g>
<g transform="translate(19262,-2555)">
 <use xlink:href="#MJMAIN-3D" x="0" y="0"></use>
<g transform="translate(778,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="1399" height="60" x="0" y="220"></rect>
 <use xlink:href="#MJMAIN-30" x="449" y="676"></use>
<g transform="translate(60,-698)">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-34" x="778" y="0"></use>
</g>
</g>
</g>
 <use xlink:href="#MJMAIN-3D" x="2973" y="0"></use>
 <use xlink:href="#MJMAIN-30" x="4029" y="0"></use>
</g>
</g>
</svg></span>
</div>
<p>and</p>
<div>
    <span class="mjpage mjpage__block"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="100ex" height="14.176ex" style="vertical-align: -10.671ex; max-width: 60000px;" viewBox="0 -1508.9 43055.4 6103.5" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-21-Title">
<title id="MathJax-SVG-21-Title"> \underset{x \rightarrow \infty}{\text{lim}} \frac{b^x - 1}{-4}=\\
    \frac{-1}{-4}=\\
    0.25</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(18580,0)">
<g transform="translate(214,0)">
 <use xlink:href="#MJMAIN-6C"></use>
 <use xlink:href="#MJMAIN-69" x="278" y="0"></use>
 <use xlink:href="#MJMAIN-6D" x="557" y="0"></use>
</g>
<g transform="translate(0,-601)">
 <use transform="scale(0.707)" xlink:href="#MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-2192" x="572" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-221E" x="1573" y="0"></use>
</g>
<g transform="translate(1819,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="2777" height="60" x="0" y="220"></rect>
<g transform="translate(60,676)">
 <use xlink:href="#MJMATHI-62" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-78" x="607" y="513"></use>
 <use xlink:href="#MJMAIN-2212" x="1156" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="2157" y="0"></use>
</g>
<g transform="translate(749,-698)">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-34" x="778" y="0"></use>
</g>
</g>
</g>
 <use xlink:href="#MJMAIN-3D" x="5115" y="0"></use>
</g>
<g transform="translate(20041,-2555)">
<g transform="translate(397,0)">
<rect stroke="none" width="1399" height="60" x="0" y="220"></rect>
<g transform="translate(60,676)">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="778" y="0"></use>
</g>
<g transform="translate(60,-698)">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-34" x="778" y="0"></use>
</g>
</g>
 <use xlink:href="#MJMAIN-3D" x="2194" y="0"></use>
</g>
<g transform="translate(20637,-4433)">
 <use xlink:href="#MJMAIN-30"></use>
 <use xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-32" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-35" x="1279" y="0"></use>
</g>
</g>
</svg></span>
</div>
<p>and (for <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.344ex" height="2.343ex" style="vertical-align: -0.505ex;" viewBox="0 -791.3 2301.1 1008.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-22-Title">
<title id="MathJax-SVG-22-Title">ε \ge 0</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-3B5" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-2265" x="744" y="0"></use>
 <use xlink:href="#MJMAIN-30" x="1800" y="0"></use>
</g>
</svg></span>)</p>
<div>
    <span class="mjpage mjpage__block"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="100ex" height="12.176ex" style="vertical-align: -8.505ex; max-width: 60000px;" viewBox="0 -1580.7 43055.4 5242.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-23-Title">
<title id="MathJax-SVG-23-Title"> \frac{b^x - 1}{-4} \le \frac{b^{x+ε} - 1}{-4} \Leftrightarrow (\text{signflip because multiplication with }-4) \\
    b^x - 1 \ge b^{x+ε} - 1 \Leftrightarrow \\
    b^x \ge b^{x+ε} </title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(7594,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="2777" height="60" x="0" y="220"></rect>
<g transform="translate(60,676)">
 <use xlink:href="#MJMATHI-62" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-78" x="607" y="513"></use>
 <use xlink:href="#MJMAIN-2212" x="1156" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="2157" y="0"></use>
</g>
<g transform="translate(749,-698)">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-34" x="778" y="0"></use>
</g>
</g>
 <use xlink:href="#MJMAIN-2264" x="3295" y="0"></use>
<g transform="translate(4074,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="3658" height="60" x="0" y="220"></rect>
<g transform="translate(60,676)">
 <use xlink:href="#MJMATHI-62" x="0" y="0"></use>
<g transform="translate(429,362)">
 <use transform="scale(0.707)" xlink:href="#MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-2B" x="572" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-3B5" x="1351" y="0"></use>
</g>
 <use xlink:href="#MJMAIN-2212" x="2036" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="3037" y="0"></use>
</g>
<g transform="translate(1189,-698)">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-34" x="778" y="0"></use>
</g>
</g>
</g>
 <use xlink:href="#MJMAIN-21D4" x="8527" y="0"></use>
 <use xlink:href="#MJMAIN-28" x="9805" y="0"></use>
<g transform="translate(10195,0)">
 <use xlink:href="#MJMAIN-73"></use>
 <use xlink:href="#MJMAIN-69" x="394" y="0"></use>
 <use xlink:href="#MJMAIN-67" x="673" y="0"></use>
 <use xlink:href="#MJMAIN-6E" x="1173" y="0"></use>
 <use xlink:href="#MJMAIN-66" x="1730" y="0"></use>
 <use xlink:href="#MJMAIN-6C" x="2036" y="0"></use>
 <use xlink:href="#MJMAIN-69" x="2315" y="0"></use>
 <use xlink:href="#MJMAIN-70" x="2593" y="0"></use>
 <use xlink:href="#MJMAIN-62" x="3400" y="0"></use>
 <use xlink:href="#MJMAIN-65" x="3956" y="0"></use>
 <use xlink:href="#MJMAIN-63" x="4401" y="0"></use>
 <use xlink:href="#MJMAIN-61" x="4845" y="0"></use>
 <use xlink:href="#MJMAIN-75" x="5346" y="0"></use>
 <use xlink:href="#MJMAIN-73" x="5902" y="0"></use>
 <use xlink:href="#MJMAIN-65" x="6297" y="0"></use>
 <use xlink:href="#MJMAIN-6D" x="6991" y="0"></use>
 <use xlink:href="#MJMAIN-75" x="7825" y="0"></use>
 <use xlink:href="#MJMAIN-6C" x="8381" y="0"></use>
 <use xlink:href="#MJMAIN-74" x="8660" y="0"></use>
 <use xlink:href="#MJMAIN-69" x="9049" y="0"></use>
 <use xlink:href="#MJMAIN-70" x="9328" y="0"></use>
 <use xlink:href="#MJMAIN-6C" x="9884" y="0"></use>
 <use xlink:href="#MJMAIN-69" x="10163" y="0"></use>
 <use xlink:href="#MJMAIN-63" x="10441" y="0"></use>
 <use xlink:href="#MJMAIN-61" x="10886" y="0"></use>
 <use xlink:href="#MJMAIN-74" x="11386" y="0"></use>
 <use xlink:href="#MJMAIN-69" x="11776" y="0"></use>
 <use xlink:href="#MJMAIN-6F" x="12054" y="0"></use>
 <use xlink:href="#MJMAIN-6E" x="12555" y="0"></use>
 <use xlink:href="#MJMAIN-77" x="13361" y="0"></use>
 <use xlink:href="#MJMAIN-69" x="14084" y="0"></use>
 <use xlink:href="#MJMAIN-74" x="14362" y="0"></use>
 <use xlink:href="#MJMAIN-68" x="14752" y="0"></use>
</g>
 <use xlink:href="#MJMAIN-2212" x="25976" y="0"></use>
 <use xlink:href="#MJMAIN-34" x="26976" y="0"></use>
 <use xlink:href="#MJMAIN-29" x="27477" y="0"></use>
</g>
<g transform="translate(17123,-2037)">
 <use xlink:href="#MJMATHI-62" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-78" x="607" y="583"></use>
 <use xlink:href="#MJMAIN-2212" x="1156" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="2157" y="0"></use>
 <use xlink:href="#MJMAIN-2265" x="2935" y="0"></use>
<g transform="translate(3991,0)">
 <use xlink:href="#MJMATHI-62" x="0" y="0"></use>
<g transform="translate(429,412)">
 <use transform="scale(0.707)" xlink:href="#MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-2B" x="572" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-3B5" x="1351" y="0"></use>
</g>
</g>
 <use xlink:href="#MJMAIN-2212" x="6028" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="7029" y="0"></use>
 <use xlink:href="#MJMAIN-21D4" x="7807" y="0"></use>
</g>
<g transform="translate(19486,-3433)">
 <use xlink:href="#MJMATHI-62" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-78" x="607" y="583"></use>
 <use xlink:href="#MJMAIN-2265" x="1212" y="0"></use>
<g transform="translate(2268,0)">
 <use xlink:href="#MJMATHI-62" x="0" y="0"></use>
<g transform="translate(429,412)">
 <use transform="scale(0.707)" xlink:href="#MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-2B" x="572" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-3B5" x="1351" y="0"></use>
</g>
</g>
</g>
</g>
</svg></span>
</div>
<p>which is the case.</p>
<p>In python, this is simply</p>
<pre><code>def shift_exp(x, b):
    return ((b**x)-1)/(-4)
</code></pre>
<p>We can now fit that kind of curve to the data:</p>
<pre><code>&gt;&gt;&gt; pbexpfit=spo.curve_fit(shift_exp, pbrngs, pbbriers, bounds=([0], [1]))
(array([1.22550795e-22]), array([[3.83266961e-18]]))
&gt;&gt;&gt; metexpfit=spo.curve_fit(shift_exp, metrngs, metbriers, bounds=([0], [1]))
(array([0.95788506]), array([[6.50321645e-07]]))
</code></pre>
<p><img alt="Scatter-plot of Metaculus &amp; PredictionBook data, with exponential-ish regressions (as described above)." src="./img/range_and_forecasting_accuracy/allscatter_exp.png" title="Scatter-plot of Metaculus &amp; PredictionBook data, with exponential-ish regressions (as described above). The PredictionBook exponential-ish plot looks more like a step-function, reaching 0.25 instantaneously, while the Metaculus data takes ~100 days to reach 0.25 (which is also quite quick)."></p>
<p>As one can see, fitting this kind of curve suggests that
the predictions become equivalent to random guesses almost
immediately for PredictionBook, and for ranges &gt;100 days for
Metaculus. Perhaps there are some problems with <a href="https://en.wikipedia.org/wiki/floating-point_arithmetic">floating-point
arithmetic</a>
at play here: the best fit <em>would</em> be at something like
<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.48ex" height="2.676ex" style="vertical-align: -0.338ex;" viewBox="0 -1006.6 2359.3 1152.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-24-Title">
<title id="MathJax-SVG-24-Title">10^{-78}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-30" x="500" y="0"></use>
<g transform="translate(1001,393)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-2212" x="0" y="0"></use>
<g transform="translate(550,0)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-37"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-38" x="500" y="0"></use>
</g>
</g>
</g>
</svg></span>, but <code>curve_fit</code> doesn't know how to <a href="https://acesounderglass.com/2021/10/20/i-dont-know-how-to-count-that-low/" title="I Don’t Know How To Count That Low (Elizabeth, 2021)">count that
low</a>?</p>
<h5 id="This_Is_Cool"><a class="hanchor" href="#This_Is_Cool">This Is Cool</a></h5>
<p>I believe that these findings are pretty cool: They give some
sense of how long the range of forecasts needs to be for them to be
approximately random.</p>
<p>We can do this by finding out at what point our function first
predicts Brier scores sufficiently close to 0.25, let's take 0.24 as an
arbitrary cutoff (which would be, on average, assigning a probability of
<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="17.306ex" height="3.009ex" style="vertical-align: -0.671ex;" viewBox="0 -1006.6 7451 1295.7" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-25-Title">
<title id="MathJax-SVG-25-Title">1-\sqrt{0.24} \approx 0.51</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-31" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-2212" x="722" y="0"></use>
<g transform="translate(1723,0)">
 <use xlink:href="#MJMAIN-221A" x="0" y="33"></use>
<rect stroke="none" width="1780" height="60" x="833" y="774"></rect>
<g transform="translate(833,0)">
 <use xlink:href="#MJMAIN-30"></use>
 <use xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-32" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-34" x="1279" y="0"></use>
</g>
</g>
 <use xlink:href="#MJMAIN-2248" x="4614" y="0"></use>
<g transform="translate(5670,0)">
 <use xlink:href="#MJMAIN-30"></use>
 <use xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-35" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="1279" y="0"></use>
</g>
</g>
</svg></span> to events that take place).</p>
<h6 id="The_Horizon"><a class="hanchor" href="#The_Horizon">The Horizon</a></h6>
<p>Let's call this number the <strong>horizon</strong>: beyond it, our forecasts
become random, we can neither steer nor see, the fogs of time have
grown too thick. From our perspective, only chaos reigns there, and
every decision-theoretic ship that sails it is never to return with
valuable information.</p>
<p>It is <a href="#Appendix_C_Quotes_About_the_Horizon_of_Forecasts">sometimes
invoked</a>
by people when they want to talk about the inherent unknowability of
the future, always without evidence of any <em>actual number</em>.</p>
<hr>
<p>Then, for the squashed logistic function, we have to find the <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.33ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 572.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-26-Title">
<title id="MathJax-SVG-26-Title">x</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMATHI-78" x="0" y="0"></use>
</g>
</svg></span> so that</p>
<div>
    <span class="mjpage mjpage__block"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="100ex" height="18.676ex" style="vertical-align: -15.338ex; max-width: 60000px;" viewBox="0 -1437.2 43055.4 8041" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-27-Title">
<title id="MathJax-SVG-27-Title">0.24=0.25 \cdot \frac{1}{1+\exp(s \cdot x + i)} \Leftrightarrow \\
    \frac{1}{0.96}-1=\exp(s \cdot x +i) \Leftrightarrow \\
    \frac{\ln(\frac{1}{0.96}-1)-i}{s}=x</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(14217,0)">
 <use xlink:href="#MJMAIN-30"></use>
 <use xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-32" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-34" x="1279" y="0"></use>
 <use xlink:href="#MJMAIN-3D" x="2057" y="0"></use>
<g transform="translate(3114,0)">
 <use xlink:href="#MJMAIN-30"></use>
 <use xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-32" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-35" x="1279" y="0"></use>
</g>
 <use xlink:href="#MJMAIN-22C5" x="5116" y="0"></use>
<g transform="translate(5394,0)">
<g transform="translate(342,0)">
<rect stroke="none" width="7485" height="60" x="0" y="220"></rect>
 <use xlink:href="#MJMAIN-31" x="3492" y="676"></use>
<g transform="translate(60,-771)">
 <use xlink:href="#MJMAIN-31" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-2B" x="722" y="0"></use>
<g transform="translate(1723,0)">
 <use xlink:href="#MJMAIN-65"></use>
 <use xlink:href="#MJMAIN-78" x="444" y="0"></use>
 <use xlink:href="#MJMAIN-70" x="973" y="0"></use>
</g>
 <use xlink:href="#MJMAIN-28" x="3252" y="0"></use>
 <use xlink:href="#MJMATHI-73" x="3642" y="0"></use>
 <use xlink:href="#MJMAIN-22C5" x="4334" y="0"></use>
 <use xlink:href="#MJMATHI-78" x="4834" y="0"></use>
 <use xlink:href="#MJMAIN-2B" x="5629" y="0"></use>
 <use xlink:href="#MJMATHI-69" x="6630" y="0"></use>
 <use xlink:href="#MJMAIN-29" x="6975" y="0"></use>
</g>
</g>
</g>
 <use xlink:href="#MJMAIN-21D4" x="13620" y="0"></use>
</g>
<g transform="translate(15329,-2796)">
<g transform="translate(397,0)">
<rect stroke="none" width="1900" height="60" x="0" y="220"></rect>
 <use xlink:href="#MJMAIN-31" x="699" y="676"></use>
<g transform="translate(60,-687)">
 <use xlink:href="#MJMAIN-30"></use>
 <use xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-39" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-36" x="1279" y="0"></use>
</g>
</g>
 <use xlink:href="#MJMAIN-2212" x="2640" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="3640" y="0"></use>
 <use xlink:href="#MJMAIN-3D" x="4419" y="0"></use>
<g transform="translate(5475,0)">
 <use xlink:href="#MJMAIN-65"></use>
 <use xlink:href="#MJMAIN-78" x="444" y="0"></use>
 <use xlink:href="#MJMAIN-70" x="973" y="0"></use>
</g>
 <use xlink:href="#MJMAIN-28" x="7004" y="0"></use>
 <use xlink:href="#MJMATHI-73" x="7394" y="0"></use>
 <use xlink:href="#MJMAIN-22C5" x="8086" y="0"></use>
 <use xlink:href="#MJMATHI-78" x="8586" y="0"></use>
 <use xlink:href="#MJMAIN-2B" x="9381" y="0"></use>
 <use xlink:href="#MJMATHI-69" x="10382" y="0"></use>
 <use xlink:href="#MJMAIN-29" x="10727" y="0"></use>
 <use xlink:href="#MJMAIN-21D4" x="11394" y="0"></use>
</g>
<g transform="translate(16993,-5805)">
<g transform="translate(397,0)">
<rect stroke="none" width="6644" height="60" x="0" y="220"></rect>
<g transform="translate(60,951)">
 <use xlink:href="#MJMAIN-6C"></use>
 <use xlink:href="#MJMAIN-6E" x="278" y="0"></use>
 <use xlink:href="#MJMAIN-28" x="835" y="0"></use>
<g transform="translate(1224,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="1378" height="60" x="0" y="220"></rect>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-31" x="724" y="629"></use>
<g transform="translate(60,-417)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-39" x="779" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-36" x="1279" y="0"></use>
</g>
</g>
</g>
 <use xlink:href="#MJMAIN-2212" x="3065" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="4066" y="0"></use>
 <use xlink:href="#MJMAIN-29" x="4566" y="0"></use>
 <use xlink:href="#MJMAIN-2212" x="5178" y="0"></use>
 <use xlink:href="#MJMATHI-69" x="6179" y="0"></use>
</g>
 <use xlink:href="#MJMATHI-73" x="3087" y="-686"></use>
</g>
 <use xlink:href="#MJMAIN-3D" x="7440" y="0"></use>
 <use xlink:href="#MJMATHI-78" x="8496" y="0"></use>
</g>
</g>
</svg></span>
</div>
<p>Then, the logistic-ish forecasting horizon gives</p>
<pre><code>&gt;&gt;&gt; (np.log((1/0.96)-1)-metlogifit[0][1])/metlogifit[0][0]
1339.4812558296296
&gt;&gt;&gt; (np.log((1/0.96)-1)-pblogifit[0][1])/pblogifit[0][0]
6638.833618277785
</code></pre>
<p>which is ~3.6 years for Metaculus, and ~18 years for PredictionBook.</p>
<p>With the exponential fit, we know that</p>
<div>
    <span class="mjpage mjpage__block"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="100ex" height="14.676ex" style="vertical-align: -11.171ex; max-width: 60000px;" viewBox="0 -1508.9 43055.4 6318.8" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-28-Title">
<title id="MathJax-SVG-28-Title">0.24=\frac{b^x -1}{-4} \Leftrightarrow \\
    -0.96=b^x -1 \Leftrightarrow \\
    -0.96+1=b^x \Leftrightarrow \\
    \log_b(0.04)=x</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(17822,0)">
 <use xlink:href="#MJMAIN-30"></use>
 <use xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-32" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-34" x="1279" y="0"></use>
 <use xlink:href="#MJMAIN-3D" x="2057" y="0"></use>
<g transform="translate(2836,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="2777" height="60" x="0" y="220"></rect>
<g transform="translate(60,676)">
 <use xlink:href="#MJMATHI-62" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-78" x="607" y="513"></use>
 <use xlink:href="#MJMAIN-2212" x="1156" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="2157" y="0"></use>
</g>
<g transform="translate(749,-698)">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-34" x="778" y="0"></use>
</g>
</g>
</g>
 <use xlink:href="#MJMAIN-21D4" x="6409" y="0"></use>
</g>
<g transform="translate(17613,-1938)">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
<g transform="translate(778,0)">
 <use xlink:href="#MJMAIN-30"></use>
 <use xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-39" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-36" x="1279" y="0"></use>
</g>
 <use xlink:href="#MJMAIN-3D" x="2836" y="0"></use>
<g transform="translate(3892,0)">
 <use xlink:href="#MJMATHI-62" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-78" x="607" y="583"></use>
</g>
 <use xlink:href="#MJMAIN-2212" x="5049" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="6049" y="0"></use>
 <use xlink:href="#MJMAIN-21D4" x="6828" y="0"></use>
</g>
<g transform="translate(17613,-3177)">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
<g transform="translate(778,0)">
 <use xlink:href="#MJMAIN-30"></use>
 <use xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-39" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-36" x="1279" y="0"></use>
</g>
 <use xlink:href="#MJMAIN-2B" x="2780" y="0"></use>
 <use xlink:href="#MJMAIN-31" x="3781" y="0"></use>
 <use xlink:href="#MJMAIN-3D" x="4559" y="0"></use>
<g transform="translate(5615,0)">
 <use xlink:href="#MJMATHI-62" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-78" x="607" y="583"></use>
</g>
 <use xlink:href="#MJMAIN-21D4" x="6828" y="0"></use>
</g>
<g transform="translate(18453,-4442)">
 <use xlink:href="#MJMAIN-6C"></use>
 <use xlink:href="#MJMAIN-6F" x="278" y="0"></use>
 <use xlink:href="#MJMAIN-67" x="779" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMATHI-62" x="1809" y="-343"></use>
 <use xlink:href="#MJMAIN-28" x="1683" y="0"></use>
<g transform="translate(2072,0)">
 <use xlink:href="#MJMAIN-30"></use>
 <use xlink:href="#MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#MJMAIN-30" x="779" y="0"></use>
 <use xlink:href="#MJMAIN-34" x="1279" y="0"></use>
</g>
 <use xlink:href="#MJMAIN-29" x="3852" y="0"></use>
 <use xlink:href="#MJMAIN-3D" x="4519" y="0"></use>
 <use xlink:href="#MJMATHI-78" x="5576" y="0"></use>
</g>
</g>
</svg></span>
</div>
<p>That gives</p>
<pre><code>&gt;&gt;&gt; np.log(0.04)/np.log(metexpfit[0][0])
74.80978286870999
&gt;&gt;&gt; np.log(0.04)/np.log(pbexpfit[0][0])
0.06282811825117969
</code></pre>
<p>less than a day for the PredictionBook predictive horizon, and ~75 days
for the Metaculus predictive horizon.</p>
<p>Of course, don't believe these numbers too much: The difference in dataset
range is probably causing a lot of the difference in fit, the exponential
fit is way more pessimistic, and I haven't performed any <a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">statistical
tests</a>
to determine how to much believe these particular numbers.</p>
<p>But I'm really excited about testing these conclusions with growing
datasets as forecasting platforms exist longer.</p>
<!--TODO: do exactly that-->
<p>Overall, I like the logistic fit <em>much</em> better than the exponential
one: in practice, we know that forecasters don't give quasi-random
predictions for questions that are further out than 100 days (or, as
the PredictionBook fit suggests, that forecasting is impossible!).</p>
<p>But one can also take a look at the quality of the fit to the data:
What is the mean squared error of the predicted and the actual Brier
score for the observed data?</p>
<pre><code>&gt;&gt;&gt; np.mean((shrunk_logistic(pbrngs, pblogifit[0][0], pblogifit[0][1])-pbbriers)**2)
0.05057901068476697
&gt;&gt;&gt; np.mean((shrunk_logistic(metrngs, metlogifit[0][0], metlogifit[0][1])-metbriers)**2)
0.031372382650708616
&gt;&gt;&gt; np.mean((shift_exp(pbrngs, pbexpfit[0][0])-pbbriers)**2)
0.058142052832572635
&gt;&gt;&gt; np.mean((shift_exp(metrngs, metexpfit[0][0])-metbriers)**2)
0.0352617381522454
</code></pre>
<p>The fits agree (very slightly) with me here: in both cases the logistic
fit has a marginally smaller mean squared error in predicting the
Brier score.</p>
<h3 id="Why_Assume_Accuracy_will_Increase"><a class="hanchor" href="#Why_Assume_Accuracy_will_Increase">Why Assume Accuracy will Increase?</a></h3>
<p>I believe that the finding for the PredictionBook data is quite
surprising.</p>
<p>A priori, one would believe that beliefs about the near future
are generally more accurate than beliefs about the far future: We
can predict the weather in 2 minutes far better than the weather
in 6 months, we can say much more about the position of a rock in
an hour than in 100 years, more about the popularity of a political
party in 2 months as opposed to 10 years. Even in reasonably <a href="https://en.wikipedia.org/wiki/Chaos_theory">chaotic
systems</a>, one should expect to
become more and more accurate the closer one comes to the expected time.</p>
<p>One example for this is a roulette wheel (the resolution being the number
of the slot the ball eventually rolls into): I am able to give a much
narrower probability distribution on values 100ms before the ball falls
into the slot than 1s before, and 5s before resolution my prediction is
going to be nearly uniform. Information, like nearly everything else, has
diminishing value, and posteriors eventually converge towards the truth.</p>
<p>However, there is an interesting effect that takes place with systems
that eventually reach equilibrium. Take, for example, a <a href="https://en.wikipedia.org/wiki/Double_pendulum">double
pendulum</a> in an environment
with gravity: If I am at the start of the swinging of the double pendulum,
I can predict the state in 100ms better than in 1s (because it becomes
more chaotic over time), but I am also better able to predict the state
in 1h (or how long it takes to reach equilibrium) than in 1s (because
it reaches equilibrium in hanging straight down).</p>
<p>(I got this observation from “The World as
Holocaust” by Stanisław Lem, though it is obvious <a href="https://www.lesswrong.com/s/zpCiuR4T343j9WkcK/p/WnheMGAka4fL99eae" title="Hindsight Devalues Science">in
hindsight</a>).</p>
<!--TODO: Also, what are some probability theory & information theory
theorems for this?-->
<h3 id="Possible_Explanations"><a class="hanchor" href="#Possible_Explanations">Possible Explanations</a></h3>
<p>So, what is the reason for this rather weird finding? Several possible
reasons come to mind.</p>
<h4 id="Range_and_Biased_Questions"><a class="hanchor" href="#Range_and_Biased_Questions">Range and Biased Questions</a></h4>
<p>The most obvious solution is that the analysis above is absolute bogus and
completely meaningless: It compares <a href="https://www.metaculus.com/questions/2568/ragnar%25C3%25B6k-question-series-results-so-far/">questions about global catastrophic
risks</a>
to <a href="https://www.metaculus.com/questions/1558/the-rise-and-fall-of-the-banana-will-the-current-main-export-cultivar-the-cavendish-be-replaced-by-2035/">questions about the extinction of banana
brands</a>,
different kinds of questions with different kinds of forecasts.</p>
<!--TODO: replace these with PredictionBook questions that are that
different, since the weird result is for PredictionBook, not Metaculus-->
<p>Here, one would assume that the longer-term questions asked are generally
easier to predict, and that the effect goes away when one compares
predictions among similary questions (or, better, within questions).</p>
<p>Generally, the long-term questions we prefer asking seem to be more
menable to forecasting than short-term questions: development of
population sizes, the climate, especially the movement of interstellar
bodies is much more thoroughly modelled than the development of markets,
elections and the weather. This is of course only a weak trend, but
one that could influence the questions (as will be investigated in
<a href="#Accuracy_Between_Questions">this section</a>).</p>
<h5 id="Simpsons_Paradox"><a class="hanchor" href="#Simpsons_Paradox">Simpson's Paradox</a></h5>
<p><a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson's Paradox</a>
is the phenomenon that while two features are correlated in a dataset,
it can be true that the features are negatively correlated for some
distinct subsets of the dataset.</p>
<p>It is best explained visually:</p>
<p><img alt="Simpson's paradox, taken from Wikipedia" src="./img/range_and_forecasting_accuracy/simpsons_paradox.gif" title="An animated gif of a plot. In the plot there is a set of points in a grid. The set of points is elongated, from the top-left corner to the bottom-right corner. It can be clearly separated into five subsets. Each subset is elongated from the bottom-left corner to the top-right corner. The animation first shows one line going from top-left to bottom-right, through the whole set of points, and then highlights the five subsets, while also showing five lines, each going through the subsets from the bottom-left to the top-right corner."></p>
<p>It might be the case that this analysis for PredictionBook data has come
up against an instance of Simpson's paradox: The accuracy of forecasts
is negatively correlated with range within the same question, but the
accuracy of forecasts is positively correlated with range across questions
(because the kinds of questions with longer time horizons generally allow
more accurate forecasts). Unfortunately, whether Simpson's paradox applies
or not can not always be easily judged from the scatterplot of datapoints.</p>
<p>However, <a href="#Results_2">below</a> I check the correlation of range and
forecast accuracy between questions, and find that they are negatively
correlated, and furthermore find that they are <em>positively</em> <a href="#Aggregating_Linear_Regressions">related
within questions</a>, which strongly
indicates that the effect probably comes from questions with a long
range receiving more accurate predictions (in the PredictionBook dataset).</p>
<!--TODO: scatterplot for forecasts for Predictionbook, different forecasts have different colors-->
<h4 id="Low_Sample_Sizes_With_High_Ranges"><a class="hanchor" href="#Low_Sample_Sizes_With_High_Ranges">Low Sample Sizes With High Ranges</a></h4>
<p>Another question one might ask is: How big are the sample sizes at the
tails when the range is high?</p>
<p>This is important: low sample sizes increase noise dramatically, and
make findings much less reliable.</p>
<p>To get a rough overview over the sample sizes, on can look at the number
of samples for each bucket. The sample sizes were calculated such that
at position <code>i</code> in the array <code>{pb,met}ss</code> was the sample size for week <code>i</code>:</p>
<pre><code>metss=np.bincount(np.sort(np.floor(metrngs/30)).astype(int))
pbss=np.bincount(np.sort(np.floor(pbrngs/30)).astype(int))
</code></pre>
<p>I generated charts for the sample sizes in days:</p>
<pre><code>fig=plt.figure(figsize=(8,8), clear=True)
plt.xlabel("Range (months)")
plt.ylabel("Number of datapoints)")

plt.plot(metss, '-', color='red')
plt.plot(pbss, '-', color='blue')

plt.savefig("ss_plot.png")
</code></pre>
<p><img alt="Sample sizes for predictions with a range of n months, sorted and graphed." src="./img/range_and_forecasting_accuracy/ss_plot.png" title="Sample sizes for predictions with a range (in months), sorted and graphed."></p>
<p>The red graphs stands for Metaculus sample sizes, the blue graph stands
for PredictionBook sample sizes.</p>
<p>As one can see, the sample sizes have a drastical skew towards recent
predictions, not surprising for relatively young platforms (although 10
years for PredictionBook is sizable by internet standards, it's not that
much compared to the expected range of some predictions on the platform,
which might go into the thousands of years).</p>
<p>This can be seen in the data as well: The median range of Metaculus and
PredictionBook predictions is only a couple of months, and less than 25%
of questions have a range of more than one year:</p>
<pre><code>&gt;&gt;&gt; np.quantile(metrngs/365, 0.25)
0.0938035443856715
&gt;&gt;&gt; np.quantile(metrngs/365, 0.5)
0.3411479925867841
&gt;&gt;&gt; np.quantile(metrngs/365, 0.75)
0.9173088057010588
&gt;&gt;&gt; np.quantile(pbrngs/365, 0.25)
0.04357030060882801
&gt;&gt;&gt; np.quantile(pbrngs/365, 0.5)
0.3080797501268392
&gt;&gt;&gt; np.quantile(pbrngs/365, 0.75)
0.9775999492643329
</code></pre>
<h5 id="Statistical_Significance_of_Truncated_Datasets"><a class="hanchor" href="#Statistical_Significance_of_Truncated_Datasets">Statistical Significance of Truncated Datasets</a></h5>
<p>Moved to <a href="#Appendix_B_Statistical_Significance_of_Truncated_Datasets">Appendix B</a>.</p>
<hr>
<p>I hope that the dataset becomes richer the older these platforms become.</p>
<p>Because in the linear regression all datapoints are weighted equally,
it could well be that a tiny bit of noise at the tails dominates the
entire regression.</p>
<h2 id="Accuracy_Between_Questions"><a class="hanchor" href="#Accuracy_Between_Questions">Accuracy Between Questions</a></h2>
<p>Another way to determine at the relation between forecasting accuracy
and range is to look at the range of questions and not of individual
forecasts.</p>
<p>In this case, this means taking the forecasts on all questions with
a given range and calculating the brier score on these forecasts.</p>
<h3 id="Determining_the_Range_of_a_Question"><a class="hanchor" href="#Determining_the_Range_of_a_Question">Determining the Range of a Question</a></h3>
<p>The range of a question is determined by taking the time difference
between the opening time (the time when the first prediction on the
question could have been made) and the resolution time. One could imagine
other metrics to determine the range of a question: the mean range
for forecasts of that question, the median range for forecasts on that
question, time differences between writing/opening and closing/resolution
times of the question, and probably many more.</p>
<p>Here, the range of a question was set to the time difference between opening
time and resolution time. The reasons for this were threefold:</p>
<p>First, I had no clear idea about the time when people were making
forecasts on questions. Are most of the forecasts made just after
opening, or just before closing? Or is the distribution uniform on the
time between opening and closing? And are these distributions different
on long-range as opposed to short-range questions? Also, I was unsure
whether taking the mean time for forecasts would just be the same as
comparing forecasts directly. So taking the median or the mean of the
forecasts made was less preferable.</p>
<p>Second, what I cared about here was the uncertainty of questions at time
of writing, not at time of prediction. This is much better tracked by
opening time than by proxy on the forecasts.</p>
<p>Third, there was the question of data availability. Both Metaculus and
PredictionBook publish opening/resolution times, but PredictionBook has
no clear distinction between closing and resolution time (there is,
however, a distinction between effective resolution time and planned
resolution time ("When was the question resolved?" vs. "When should the
question have been resolved?")).</p>
<h3 id="Analysis_1"><a class="hanchor" href="#Analysis_1">Analysis</a></h3>
<p>First, the dataset grouped by forecasts had to be grouped by the question
ID, in both cases a positive integer. The resulting datastructure should
have the structure</p>
<pre><code>[[id, open-resolve-timediff, [outcomes], [forecasts], [forecast-resolve-timediffs]]*]
</code></pre>
<p>where the splat just indicates the inner list can be repeated. This
is achieved by first finding the grouping of forecasts by question ID,
then concatenating the ID, the question range, the list of outcomes,
the list of forecasts and the list of forecast ranges:</p>
<pre><code>def group(d):
    a=[]
    for e in np.unique(d[0]):
        indices=np.where(d[0]==e)
        a.append([e, d[1][indices[0][0]], d[2][indices], d[3][indices], d[4][indices]])
    return a

metquestions=group(met)
pbquestions=group(pb)
</code></pre>
<p>Strictly speaking, the outcomes could be a single element, since for
every question there is only one well-defined outcome, but this makes
it easier to later compute the brier score.</p>
<p>Showcase:</p>
<pre><code>&gt;&gt;&gt; metquestions[10]
[13.0, 119.99914351851852, array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0.2 , 0.4 , 0.2 , 0.3 , 0.15, 0.3 , 0.4 , 0.4 , 0.4 , 0.4 , 0.45,
      0.4 , 0.44, 0.4 , 0.44, 0.4 , 0.38]), array([119.94258413, 118.91094545, 118.71650504, 115.99830505,
      113.03583134,  89.66780818,  87.76008922,  87.12385685,
      85.12093715,  85.08304395,  83.7246415 ,  83.19617587,
      82.69982874,  73.11635207,  71.99461814,  71.21645502,
      64.07551593])]
&gt;&gt;&gt; brier(metquestions[10][3],metquestions[10][2])
0.13509411764705884
</code></pre>
<p>One can now also see how many questions there are in the two datasets
(with the relatively unsurprising result that PredictionBook has much
more resolved questions):</p>
<pre><code>&gt;&gt;&gt; len(metquestions)
557
&gt;&gt;&gt; len(pbquestions)
13356
</code></pre>
<p>The next step involves computing the Brier score for the forecasts on
each question:</p>
<pre><code>&gt;&gt;&gt; metqbrier=np.array([[i[1], brier(i[3], i[2])] for i in metquestions])
&gt;&gt;&gt; pbqbrier=np.array([[i[1], brier(i[3], i[2])] for i in pbquestions])
</code></pre>
<p><code>metqbrier</code> is a list that contains sublists, one for each question,
the sublist containing the range for the question and the brier score
for all predictions on the question (<code>pbqbrier</code> has the same structure).</p>
<h3 id="Results_2"><a class="hanchor" href="#Results_2">Results</a></h3>
<p>Again I use linear regressions, correlation coefficients and scatter
plots to inadequately analyze the data.</p>
<p>For accuracy between questions, the results were pretty surprising:</p>
<pre><code>&gt;&gt;&gt; np.corrcoef(metqbrier.T)
array([[ 1.       , -0.0099402],
    [-0.0099402,  1.       ]])
&gt;&gt;&gt; np.corrcoef(pbqbrier.T)
array([[ 1.        , -0.05180824],
    [-0.05180824,  1.        ]])
&gt;&gt;&gt; sps.linregress(metqbrier.T[0], metqbrier.T[1])
LinregressResult(slope=-5.199153608270726e-06, intercept=0.1751301126619239, rvalue=-0.009940204896962441, pvalue=0.8149259597777081, stderr=2.2200837795403376e-05)
&gt;&gt;&gt; sps.linregress(pbqbrier.T[0], pbqbrier.T[1])
LinregressResult(slope=-2.1538793571528e-05, intercept=0.1952547647088438, rvalue=-0.05180823990580795, pvalue=2.0875245782500886e-09, stderr=3.5928014948058268e-06)
</code></pre>
<p>For Metaculus, the slope off the linear regression is approximately
<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.307ex" height="2.843ex" style="vertical-align: -0.505ex;" viewBox="0 -1006.6 4007.3 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-29-Title">
<title id="MathJax-SVG-29-Title">-5 \cdot 10^{-6}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-35" x="778" y="0"></use>
 <use xlink:href="#MJMAIN-22C5" x="1501" y="0"></use>
<g transform="translate(2001,0)">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-30" x="500" y="0"></use>
<g transform="translate(1001,393)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-36" x="778" y="0"></use>
</g>
</g>
</g>
</svg></span>, compared that with <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.499ex" height="2.676ex" style="vertical-align: -0.338ex;" viewBox="0 -1006.6 3228.8 1152.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-30-Title">
<title id="MathJax-SVG-30-Title">1 \cdot 10^{-5}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-31" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-22C5" x="722" y="0"></use>
<g transform="translate(1223,0)">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-30" x="500" y="0"></use>
<g transform="translate(1001,393)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="778" y="0"></use>
</g>
</g>
</g>
</svg></span> for the
slope for the linear regression between forecasts—the slope is less
steep, but also negative. For PredictionBook, the slope of the linear
regression is <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.307ex" height="2.843ex" style="vertical-align: -0.505ex;" viewBox="0 -1006.6 4007.3 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-31-Title">
<title id="MathJax-SVG-31-Title">-2 \cdot 10^{-5}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-32" x="778" y="0"></use>
 <use xlink:href="#MJMAIN-22C5" x="1501" y="0"></use>
<g transform="translate(2001,0)">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-30" x="500" y="0"></use>
<g transform="translate(1001,393)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="778" y="0"></use>
</g>
</g>
</g>
</svg></span>, compared with <span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.307ex" height="2.843ex" style="vertical-align: -0.505ex;" viewBox="0 -1006.6 4007.3 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-32-Title">
<title id="MathJax-SVG-32-Title">-8 \cdot 10^{-6}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use xlink:href="#MJMAIN-38" x="778" y="0"></use>
 <use xlink:href="#MJMAIN-22C5" x="1501" y="0"></use>
<g transform="translate(2001,0)">
 <use xlink:href="#MJMAIN-31"></use>
 <use xlink:href="#MJMAIN-30" x="500" y="0"></use>
<g transform="translate(1001,393)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-2212" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-36" x="778" y="0"></use>
</g>
</g>
</g>
</svg></span>
for the data between forecasts, which is slightly steeper.</p>
<p>However, look at the p-value for the Metaculus correlation/linear
regression! 0.8! So that number is basically worthless.</p>
<p>In both cases, there is a small negative correlation between the brier
score and the range (to be precise, the larger the range, the lower
the brier score/the higher the accuracy). For the Metaculus data, this
effect is not as pronounced as for the PredictionBook data, though both
correlations are quite weak. The two linear regressions also show the
same effect (lower accuracy at shorter ranges/higher accuracy at higher
ranges), but again the slope of the linear regression is not very steep.</p>
<p>And now: linear regressions and scatterplots!</p>
<p>The following are scatterplots with range on the X-axis and accuracy
(calculated using the Brier score) on the Y-axis. Again, red dots/lines
are for Metaculus data (twice as big as PredictionBook data points,
to make them visible in the sea of blue), and blue dots/lines are for
PredictionBook data.</p>
<pre><code>fig=plt.figure(figsize=(8,8))
plt.xlabel("Range (days)")
plt.ylabel("Accuracy (Brier score)")

plt.plot(pbqbrier.T[0], pbqbrier.T[1], '.', color='blue', markersize=1)
plt.plot(pbqbrier.T[0], pbqintercept+pbqslope*pbqbrier.T[0], 'blue', label='PredictionBook linear regression', linewidth=1)
plt.plot(metqbrier.T[0], metqbrier.T[1], '.', color='red', markersize=2)
plt.plot(pbqbrier.T[0], mqintercept+mqslope*pbqbrier.T[0], 'red', label='Metaculus linear regression', linewidth=1)

plt.legend()

plt.savefig("allq.png")
</code></pre>
<p><img alt="Scatterplot with linear regression for Metaculus &amp; PredictionBook question accuracy by range" src="./img/range_and_forecasting_accuracy/allq.png" title="Scatterplot with linear regression for Metaculus &amp; PredictionBook question accuracy by range"></p>
<p>The general trend seems to be: questions with a higher range tend to
receive forecasts that have a higher accuracy than questions with a
lower range. In itself, this is already a fascinating finding, and might
explain some of the effect seen with accuracy between forecasts in the
<a href="#Accuracy_Between_Forecasts">previous section</a>). On the other hand,
the data is still quite noisy, the correlations found are quite weak,
and the slopes of the linear regressions are are very near 0.</p>
<p>All in all, it's plausible that the relation of range and accuracy between
questions explains a large part of the the weird relation for accuracy and
range between forecasts, but I don't know enough statistics to tease these
out exactly. My intuition tells me that the effect on accuracy between
questions is too small to explain the whole anomaly between forecasts.</p>
<h4 id="NonLinear_CurveFitting_1"><a class="hanchor" href="#NonLinear_CurveFitting_1">Non-Linear Curve-Fitting</a></h4>
<p>Again, one can fit the nonlinear exponential/logistic function defined
<a href="#NonLinear_CurveFitting">above</a> to the data between questions.</p>
<pre><code>&gt;&gt;&gt; pblogifit_betweenq=spo.curve_fit(shrunk_logistic, pbqbrier.T[0], pbqbrier.T[1], bounds=([-np.inf, 0], [0, np.inf]))
(array([-2.70329933e+00,  5.32716622e-52]), array([[ 0.16764075, -0.01981014],
    [-0.01981014,  0.00898443]]))
&gt;&gt;&gt; metlogifit_betweenq=spo.curve_fit(shrunk_logistic, metqbrier.T[0], metqbrier.T[1], bounds=([-np.inf, 0], [0, np.inf]))
(array([-7.92206883, 33.48197   ]), array([[ 199420.41507448, -811407.37948018],
    [-811407.37948018, 3301492.9741521 ]]))
&gt;&gt;&gt; pbexpfit_betweenq=spo.curve_fit(shift_exp, pbqbrier.T[0], pbqbrier.T[1], bounds=([-np.inf, 0], [0, 1]))
(array([4.77613047e-20]), array([[5.82829061e-18]]))
&gt;&gt;&gt; metexpfit_betweenq=spo.curve_fit(shift_exp, metqbrier.T[0], metqbrier.T[1], bounds=([-np.inf, 0], [0, 1]))
(array([0.70814538]), array([[0.01386776]]))
</code></pre>
<p>But these numbers don't tell us much by themselves, do they become
clearer when plotted?</p>
<pre><code>fig=plt.figure(figsize=(8,8))

plt.title("Scatterplot with logistic-ish regression for Metaculus &amp; PredictionBook forecasts by range")
plt.xlabel("Range (days)")
plt.ylabel("Accuracy (Brier score)")

fullrng=np.array(range(0, round(max(pbrngs))+1))

plt.plot(pbqbrier.T[0], pbqbrier.T[1], '.', color='blue', markersize=1)
plt.plot(metqbrier.T[0], metqbrier.T[1], '.', color='red', markersize=2)
plt.plot(fullrng, shrunk_logistic(fullrng, metlogifit_betweenq[0][0], metlogifit_betweenq[0][1]), 'red', label='Metaculus shrunk logistic-ish regression', linewidth=2)
plt.plot(fullrng, shrunk_logistic(fullrng, pblogifit_betweenq[0][0], pblogifit_betweenq[0][1]), 'blue', label='PredictionBook shrunk logistic-ish regression', linewidth=2)

plt.legend()

plt.savefig("allq_logi.png")

fig=plt.figure(figsize=(8,8))
</code></pre>
<p><img alt="Scatterplot with logistic regression for Metaculus &amp; PredictionBook question accuracy by range" src="./img/range_and_forecasting_accuracy/allq_logi.png" title="Scatterplot with logistic regression for Metaculus &amp; PredictionBook question accuracy by range"></p>
<p><img alt="Scatterplot with exponential-ish regression for Metaculus &amp; PredictionBook question accuracy by range" src="./img/range_and_forecasting_accuracy/allq_exp.png" title="Scatterplot with exponential-ish regression for Metaculus &amp; PredictionBook question accuracy by range"></p>
<p>Not—quite?</p>
<p>(The Metaculus regression is not visibile because it lies <em>just</em> under
the PredictionBook regression, the short red line in the logistic plot
is the Metaculus regression that starts at 0, while the PredictionBook
regression starts at 0.125).</p>
<p>Basically, the regressions here conclude that the best is that
predictions on questions with any time horizons longer than a couple of
days are indistinguishable from randomness, given the assumptions made
<a href="#NonLinear_CurveFitting">here</a>.</p>
<p>This <em>actually makes sense</em>: We observe that the correlation between
range and accuracy is positive, so the best curve that fits the data
under the assumption of falling accuracy with higher range will conclude
that we're immediately in a domain with uniform randomness.</p>
<p>The predictive horizons here are</p>
<pre><code>&gt;&gt;&gt; (np.log(1/(0.96)-1)-metlogifit_betweenq[0][1])/metlogifit_betweenq[0][0]
4.627582089426849
&gt;&gt;&gt; (np.log(1/(0.96)-1)-pblogifit_betweenq[0][1])/pblogifit_betweenq[0][0]
1.1756203958314926
</code></pre>
<p>~4.5 days for Metaculus, and around a day for PredictionBook with logistic
functions, and</p>
<pre><code>&gt;&gt;&gt; np.log(0.04)/np.log(metexpfit_betweenq[0][0])
9.327212826230811
&gt;&gt;&gt; np.log(0.04)/np.log(pbexpfit_betweenq[0][0])
0.07235368359483728
</code></pre>
<p>similarly short timespans for the exponential fit.</p>
<p>And, comparing the quality (mean squared error) of the nonlinear fits to
one another reveals that the two methods are remarkably similar at fitting
the data (which is not surprising, since they look nearly identical):</p>
<pre><code>&gt;&gt;&gt; np.mean((shrunk_logistic(pbqbrier.T[0], pblogifit_betweenq[0][0], pblogifit_betweenq[0][1])-pbqbrier.T[1])**2)
0.04466653583438647
&gt;&gt;&gt; np.mean((shrunk_logistic(metqbrier.T[0], metlogifit_betweenq[0][0], metlogifit_betweenq[0][1])-metqbrier.T[1])**2)
0.029639024718816995
&gt;&gt;&gt; np.mean((shift_exp(pbqbrier.T[0], pbexpfit_betweenq[0][0])-pbqbrier.T[1])**2)
0.0466620438028492
&gt;&gt;&gt; np.mean((shift_exp(metqbrier.T[0], metexpfit_betweenq[0][0])-metqbrier.T[1])**2)
0.029795384871374987
</code></pre>
<h4 id="Why_Longer_Range_Questions_More_Accurate"><a class="hanchor" href="#Why_Longer_Range_Questions_More_Accurate">Why Longer Range Questions More Accurate?</a></h4>
<p>The big question now is: Why do forecasts on predictions on questions
with a higher range generally receive better Brier scores?</p>
<p>First, it's important to consider the p-value for the correlation with
the Metaculus data. It's 80% likely we would have had the same result,
given that the correlation was 0: not solid foundation to base further
understanding on. But we got the same result with the PredictionBook data,
with a decent p-value, so what is going on?</p>
<p>The explanation falls back to the considerations in <a href="#Range_and_Biased_Questions">the section on
range and biased questions</a>: the long-range
questions we might be asking could be "easier" to predict, at least in
the medium term, than the short-range questions.</p>
<p>How could one test this? Metaculus contains categories for questions,
and one might want to examine whether the negative trend between
question range and accuracy of predictions on that question still hold
when questions in the same category are examined (although one might run
into problems with the dataset size here—even the 557 questions in the
dataset aren't enough to provide a decent p-value). Unfortunately, no
such categorization system exists for PredictionBook, one <em>might</em> try to
analyze the titles of the questions, but it doesn't seem worth the effort.</p>
<!--TODO: maybe implement the analysis described above?-->
<h4 id="This_Partially_Explains_the_Result_Between_Forecasts"><a class="hanchor" href="#This_Partially_Explains_the_Result_Between_Forecasts">This Partially Explains the Result Between Forecasts</a></h4>
<p>For PredictionBook data, this explains why range and forecast
accuracy were negatively correlated between forecasts:
the negative correlation between range and accuracy between
questions <a href="https://en.wikipedia.org/wiki/Confounding">confounds</a> the
relationship. We can test whether this is true by looking at the relation
of range and accuracy within questions, where two forecasts at the same
time are in some sense "equally difficult".</p>
<h2 id="Accuracy_Within_Questions"><a class="hanchor" href="#Accuracy_Within_Questions">Accuracy Within Questions</a></h2>
<p>If there exists any bias in regard to what kinds of questions get asked in
relation to their range, how can we correct for this bias?</p>
<p>One approach could be to compare similar questions, such as only questions
about artificial intelligence, the cost &amp; speed of gene sequencing or
autonomous cars, and examine the relation of range and accuracy within
these categories. This might eliminate bias resulting from questions in
different kinds of domains being easier or harder to forecast.</p>
<p>Here, I take a simpler approach. I examine the relation of range and accuracy
within questions; are forecasts made on the same question later generally
more accurate than forecasts made on a question earlier?</p>
<h3 id="Analysis_2"><a class="hanchor" href="#Analysis_2">Analysis</a></h3>
<!--TODO: how about excluding regressions that have a p-value below a
certain cutoff-value?-->
<p>In order to do this, one can compute the Brier score for each prediction,
and then perform one linear regression/compute the correlation per
question to discern whether the relation is positive or not.</p>
<p>With <code>metquestions</code> and <code>pbquestions</code>, we already have the necessary
data available to perform the analysis.</p>
<p>We can create a list of the form <code>[[[brier_scores],[ranges]]*]</code>:</p>
<pre><code>wmetqbrier=[[i[4], (i[3]-i[2])**2] for i in metquestions]
wpbqbrier=[[i[4], (i[3]-i[2])**2] for i in pbquestions]
</code></pre>
<p>Since <code>lreg</code> can't deal with datasets of size 1, we have to filter
those out of the dataset (the Metaculus dataset doesn't contain these,
but I want to prepare for a possible future dataset where it does),
and they don't make much sense in our analysis anyway:</p>
<pre><code>wmetqbrier=list(filter(lambda x: len(x[0])&gt;1, wmetqbrier))
wpbqbrier=list(filter(lambda x: len(x[0])&gt;1, wpbqbrier))
</code></pre>
<p>One can play around and calculate the correlation between range and
accuracy for some questions:</p>
<pre><code>&gt;&gt;&gt; list(map(np.corrcoef, wmetqbrier[:4]))
[array([[1.        , 0.53853205],
    [0.53853205, 1.        ]]),
  array[[1.       , 0.6569835],
    [0.6569835, 1.       ]]),
  array([[1.        , 0.05048498],
    [0.05048498, 1.        ]]),
  array([[1.        , 0.28412936],
    [0.28412936, 1.        ]])]
&gt;&gt;&gt; list(map(np.corrcoef, wpbqbrier[:4]))
[array([[1.        , 0.52609801],
    [0.52609801, 1.        ]]),
  array([[1.        , 0.89254317],
    [0.89254317, 1.        ]]),
  array([[ 1.        , -0.39887059],
    [-0.39887059,  1.        ]]),
  array([[ 1., -1.],
    [-1.,  1.]])]
</code></pre>
<p>The perfect negative correlation come from the fact that some of the
questions in the dataset have only two predictions, which all by chance
anti-correlate with the range. This is not the case for all questions,
as one can see.</p>
<!--TODO: examine the correlations here, & define metqcorrs!-->
<p>For the linear regression, one can simply map <code>sps.linregress</code> over
the lists:</p>
<pre><code>&gt;&gt;&gt; wmetqregs=list(map(lambda x: sps.linregress(x[0], x[1]), wmetqbrier))
&gt;&gt;&gt; wpbqregs=list(map(lambda x: sps.linregress(x[0], x[1]), wpbqbrier))
/usr/local/lib/python3.8/dist-packages/scipy/stats/_stats_mstats_common.py:130: RuntimeWarning: invalid value encountered in double_scalars
slope = r_num / ssxm
</code></pre>
<p>The result for <code>wpbqbrier</code> is unexpected. The culprits turn out to be
a set of questions on which the same prediction has been made, twice,
at the same second, which confuses the linear regression algorithm:</p>
<pre><code>&gt;&gt;&gt; list(filter(lambda x: x[0][0]==x[0][1] and len(x[0]==2) and x[1][0]==x[1][1] and len(x[1])==2, wpbqbrier))
[[array([367.09616898, 367.09616898]), array([0.2025, 0.2025])], [array([367.09637731, 367.09637731]), array([0.2025, 0.2025])], [array([367.09899306, 367.09899306]), array([0.0225, 0.0225])], [array([367.09908565, 367.09908565]), array([0.25, 0.25])], [array([367.09936343, 367.09936343]), array([0.16, 0.16])], [array([367.10018519, 367.10018519]), array([0.0225, 0.0225])], [array([0.25236111, 0.25236111]), array([0.0025, 0.0025])], [array([0.36797454, 0.36797454]), array([0.25, 0.25])], [array([0.25259259, 0.25259259]), array([0.0625, 0.0625])], [array([0.36671296, 0.36671296]), array([0.04, 0.04])], [array([0.40542824, 0.40542824]), array([0.09, 0.09])]]
</code></pre>
<p>However, they can be filtered out pretty easily, and we recompute <code>wpbqregs</code>:</p>
<pre><code>&gt;&gt;&gt; wpbqbrier=list(filter(lambda x: not (x[0][0]==x[0][1] and len(x[0]==2) and x[1][0]==x[1][1] and len(x[1])==2), wpbqbrier))
&gt;&gt;&gt; len(wpbqbrier)
7596
&gt;&gt;&gt; wpbqregs=list(map(lambda x: sps.linregress(x[0], x[1]), wpbqbrier))
</code></pre>
<h3 id="Results_3"><a class="hanchor" href="#Results_3">Results</a></h3>
<p>Again, the results are split in three parts: linear regression,
logistic curve-fit and exponential curve-fit.</p>
<h4 id="Linear_Regression"><a class="hanchor" href="#Linear_Regression">Linear Regression</a></h4>
<p>We can now visualise the linear regression for each question by setting
plotting all linear regressions with random colors (the horizontal length
of the linear regression indicates the time between the first prediction
and the last prediction on the question: a question that was opened three
years ago, closed two years ago, and resolves now appears on the X-axis
between 730 and 1095):</p>
<pre><code>fig=plt.figure(figsize=(8,8))
plt.xlabel("Range (days)")
plt.ylabel("Linear regression")

for i in range(0, len(wmetqregs)):
        r=wmetqregs[i]
        rngs=wmetqbrier[i][0]
        slope, intercept, _, _, _=r
        cl=hex(random.sample(range(0, 256*256*256), 1)[0]) #random rgb code
        #left padding with zeros, can't be bothered to read the formatting docs right now
        cl='#'+('0'*(6-len(cl[2:])))+cl[2:]
        plt.plot(rngs, intercept+slope*rngs, color=cl, linewidth=1)

plt.savefig("permetquestion.png")
</code></pre>
<p><img alt="Linear regressions for the accuracy of questions by range" src="./img/range_and_forecasting_accuracy/permetquestion.png" title="Linear regressions for the accuracy of questions by range, which looks like someone threw a bunch of randomly-colored random-length lines onto a white canvas and then haphazardly shoved them into the bottom-left corner. Or, alternatively, like a failed attempt at modern art."></p>
<p>Basically the same code for image generation is used also for the
PredictionBook data:</p>
<p><img alt="Linear regressions for the accuracy of questions by range" src="./img/range_and_forecasting_accuracy/perpbquestion.png" title="Linear regressions for the accuracy of questions by range, which, as above, looks like someone  threw a bunch of randomly-colored random-length lines onto a white canvas and then haphazardly shoved them into the bottom-left corner. But, like, way more of them, so that it's way too busy to look at."></p>
<p>Although the plots are kind of cool to look at, I'm not really sure what
they can tell us. My <em>guess</em> would be that it somewhat shows a trend
with higher ranges responding to higher Brier scores (and therefore
lower accuracy).</p>
<h5 id="Aggregating_Linear_Regressions"><a class="hanchor" href="#Aggregating_Linear_Regressions">Aggregating Linear Regressions</a></h5>
<p>We can test whether this suspicion is acually correct by
calculating the average offset and the average ascension—if
the ascension is positive, our suspicion is confirmed. We have
to weight questions by how many predictions they have received,
otherwise the result is skewed by questions with few predictions (if
you're trying to find out whether, in basketball, making more <a href="https://en.wikipedia.org/wiki/Free_throw">free
throws</a> makes you better at it,
you'd also want to more strongly weight data from players with a larger
number of shots).</p>
<p>This is done by computing the linear regression for range/accuracy for
each question (we did that with <code>w{met,pb}qregs</code>), multiplying it by the
number of predictions on that question, adding up the linear regressions,
and then dividing the result by the total number of predictions in the
dataset (<code>clean_{met,pb}forecasts</code>):</p>
<pre><code>&gt;&gt;&gt; clean_metforecasts=np.sum([len(wmetqbrier[i][0]) for i in range(0, len(wmetqbrier))])
&gt;&gt;&gt; awmetqslope=np.sum([len(wmetqbrier[i][0])*wmetqregs[i][0] for i in range(0, len(wmetqregs))])/clean_metforecasts
0.003048078896358434
&gt;&gt;&gt; awmetqintercept=np.sum([len(wmetqbrier[i][0])*wmetqregs[i][1] for i in range(0, len(wmetqregs))])/clean_metforecasts
0.0388493550172143
&gt;&gt;&gt; clean_pbforecasts=np.sum([len(wpbqbrier[i][0]) for i in range(0, len(wpbqbrier))])
&gt;&gt;&gt; awpbqslope=np.sum([len(wpbqbrier[i][0])*wpbqregs[i][0] for i in range(0, len(wpbqregs))])/clean_pbforecasts
1.3731897568280482
&gt;&gt;&gt; awpbqintercept=np.sum([len(wpbqbrier[i][0])*wpbqregs[i][1] for i in range(0, len(wpbqregs))])/clean_pbforecasts
-98.59072648628822
</code></pre>
<p>The PredictionBook data—how do I put this—simply makes no sense.
I am pretty confident that this code <em>is</em> correct, but I think that
the questions with few predictions are producing incorrect results,
especially when the predictions are very close to each other. So let's
arbitrarily exclude questions with less than ten predictions (actually
an arbitrary choice I did not iterate over to get a "desired" result):</p>
<pre><code>&gt;&gt;&gt; fwpbqbrier=list(filter(lambda x: len(x[0])&gt;=10, wpbqbrier))
&gt;&gt;&gt; len(fwpbqbrier)
849
&gt;&gt;&gt; # Recomputing linear regressions
&gt;&gt;&gt; clean_fpbforecasts=np.sum([len(fwpbqbrier[i][0]) for i in range(0, len(fwpbqbrier))])
12865
&gt;&gt;&gt; fwpbqregs=list(map(lambda x: sps.linregress(x[0], x[1]), fwpbqbrier))
&gt;&gt;&gt; fawpbqslope=np.sum([len(fwpbqbrier[i][0])*fwpbqregs[i][0] for i in range(0, len(fwpbqregs))])/clean_fpbforecasts
0.0024623252612491924
&gt;&gt;&gt; fawpbqintercept=np.sum([len(fwpbqbrier[i][0])*fwpbqregs[i][1] for i in range(0, len(fwpbqregs))])/clean_fpbforecasts
0.00030707364984746446
</code></pre>
<p>This looks much better.</p>
<p>So it is true that accuracy within question <em>generally</em> is higher
with lower range for Metaculus data, and similar for PredictionBook
data. Everything else would have been surprising.</p>
<pre><code>fig=plt.figure(figsize=(8,8))

plt.title("Mean of linear regressions on accuracy within questions (red is Metaculus data, blue is PredictionBook data)")
plt.xlabel("Range (days)")
plt.ylabel("Accuracy (Brier score)")

plt.plot(pbrngs, awmetqintercept+awmetqslope*pbrngs, 'red', label='Metaculus aggregate linear regression', linewidth=1)
plt.plot(pbrngs, fawpbqintercept+fawpbqslope*pbrngs, 'blue', label='PredictionBook aggregate linear regression', linewidth=1)

plt.legend()

plt.savefig("withintotal.png")
</code></pre>
<p><img alt="Mean of linear regressions on accuracy within questions" src="./img/range_and_forecasting_accuracy/withintotal.png" title="Mean of linear regressions on accuracy within questions, with filtered PredictionBook data"></p>
<p>This chart, however, shows that the result is not as clean as one might
hope: both linear regressions are very steep, predicting Brier scores
of &gt;1 for ranges of more than a year, which is clearly nonsensical.</p>
<p>This probably results from the probabilities being treated linearly,
while handling them in logspace would be much more appropriate.</p>
<h4 id="Logistic_CurveFit"><a class="hanchor" href="#Logistic_CurveFit">Logistic Curve-Fit</a></h4>
<p>One can now similarly fit the logistic curve to the data within every
question, yielding a list of parameters for the logistic function.</p>
<p>Doing this naively via a list comprehension fails:</p>
<pre><code>&gt;&gt;&gt; within_logi_fits=list(map(lambda x: spo.curve_fit(shrunk_logistic, x[0], x[1], bounds=([-np.inf, 0], [0, np.inf])), wmetqbrier))
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "&lt;stdin&gt;", line 1, in &lt;lambda&gt;
  File "/usr/local/lib/python3.8/dist-packages/scipy/optimize/minpack.py", line 799, in curve_fit
    raise RuntimeError("Optimal parameters not found: " + res.message)
RuntimeError: Optimal parameters not found: The maximum number of function evaluations is exceeded.
</code></pre>
<p>To both find the culprit and then ignore it, we have to write the code iteratively:</p>
<pre><code>within_logi_fits_met=[]

for e in wmetqbrier:
        try:
                within_logi_fits_met.append(spo.curve_fit(shrunk_logistic, e[0], e[1], bounds=([-np.inf, 0], [0, np.inf])))
        except RuntimeError:
        within_logi_fits_met.append([])
                print(e)
                continue
</code></pre>
<p>The resonsible data for the question looks completely innocuous:</p>
<pre><code>[array([20.11263452, 19.95414332, 19.86404009, 19.80523882, 19.68123836,
19.30289307, 19.08148786, 18.67971381, 17.57324535, 16.17246518,
14.64708341]), array([0.49  , 0.5184, 0.49  , 0.4225, 0.3481, 0.4225, 0.3481, 0.3481,
0.16  , 0.3481, 0.16  ])]
</code></pre>
<p>I decide to just ignore any instances that give errors, and calculate
<code>within_logi_fits_pb</code> the same way as above, just with <code>fwpbqbrier</code>. This
removes data from 1 question from the Metaculus dataset, and from 10
questions from the PredictionBook dataset:</p>
<pre><code>&gt;&gt;&gt; len(list(filter(lambda x: len(x)==0, within_logi_fits_met)))
1
&gt;&gt;&gt; len(list(filter(lambda x: len(x)==0, within_logi_fits_pb)))
10
</code></pre>
<p>These can now be plotted, as the linear regressions were above:</p>
<pre><code>fig=plt.figure(figsize=(8,8))

plt.title("Logistic curve-fits for the accuracy of questions by range (only Metaculus data)")
plt.xlabel("Range (days)")
plt.ylabel("Logistic curve-fit")

for i in range(0, len(within_logi_fits_met)):
        r=within_logi_fits_met[i]
        if len(r)==0:
                continue
        rngs=wmetqbrier[i][0]
        slope, intercept=r[0][0], r[0][1]
        cl=hex(random.sample(range(0, 256*256*256), 1)[0]) #random rgb code
        #left padding with zeros, can't be bothered to read the formatting docs right now
        cl='#'+('0'*(6-len(cl[2:])))+cl[2:]
        plt.plot(fullrng_met, shrunk_logistic(fullrng_met, slope, intercept))

plt.savefig("permetquestion_logi.png")
</code></pre>
<p><img alt="Logistic curve-fits for the accuracy of questions by range" src="./img/range_and_forecasting_accuracy/permetquestion_logi.png" title="Logistic curve-fits for the accuracy of questions by range. Most of the logistic curve-fits go to 0.25 around 0, but some of them are constant at various values <0.125 over 0 up to 1400 days, and some just rise quite slowly."></p>
<p>Again, basically the same code, but for PredictionBook data, gives us
these plots:</p>
<p><img alt="Logistic curve-fits for the accuracy of questions by range" src="./img/range_and_forecasting_accuracy/perpbquestion_logi.png" title="Logistic curve-fits for the accuracy of questions by range. Most of the logistic curve-fits go to 0.25 around 0, but some of them are constant at various values <0.125 over 0 up to 1400 days, and some just rise quite slowly, just as above with the Metaculus data."></p>
<p>These charts look like what I would have expected:</p>
<ol>
<li>On many questions, the predictions might be more accurate with longer ranges, which results in sigmoids which go to 0.25 almost immediately.</li>
<li>On some questions, the slope is <em>very slight</em>, resulting in the lines parallel to the x-axis. This happens when there is basically no relation between range and accuracy.</li>
<li>A few questions were posed long ago, but also have more accurate predictions at higher ranges, and therefore their plot is approximately a <a href="https://en.wikipedia.org/wiki/Step_function">step function</a> around the time when they were posed.</li>
<li>And, finally, some questions have more accurate predictions at lower ranges, resulting in the functions that <em>actually look like sigmoids</em>.</li>
</ol>
<p>I'm unsure about the best way to aggregate these different sigmoids
into one, as I did with the linear regressions above.</p>
<h5 id="Logistic_Forecast_Horizons_for_Questions"><a class="hanchor" href="#Logistic_Forecast_Horizons_for_Questions">Logistic Forecast Horizons for Questions</a></h5>
<blockquote>
<p>for there is in a god's face more of marvel than prediction can tell,
and when that face is vaster than a great temple and seen looking down at
sunset in the cryptic silences of that upper world from whose dark lava it
was divinely hewn of old, the marvel is so strong that none may escape it.</p>
</blockquote>
<p><em>— <a href="https://en.wikipedia.org/wiki/H._P._Lovecraft">Howard Phillips Lovecraft</a>, <a href="http://www.hplovecraft.com/writings/texts/fiction/dq.aspx">“The Dream-Quest of Unknown Kadath”</a>, 1943</em></p>
<p>We now can calculate the forecast horizon defined in <a href="#This_Is_Cool">this
section</a> for every question, and then calculate some
summary statistics of the forecast horizons on all questions in the
two datasets.</p>
<p>First, we have to compute the horizons discovered by the fit (ignoring
the invalid fits represented by <code>[]</code>):</p>
<pre><code>&gt;&gt;&gt; within_logi_fits_met_filt=list(filter(lambda x: len(x)&gt;0, within_logi_fits_met))
&gt;&gt;&gt; within_logi_fits_pb_filt=list(filter(lambda x: len(x)&gt;0, within_logi_fits_pb))
&gt;&gt;&gt; met_logi_horizons=[(np.log((1/0.96)-1)-f[0][1])/f[0][0] for f in within_logi_fits_met_filt]
&gt;&gt;&gt; pb_logi_horizons=[(np.log((1/0.96)-1)-f[0][1])/f[0][0] for f in within_logi_fits_pb_filt]
</code></pre>
<p>So, what horizons do we have?</p>
<table>
<thead>
<tr>
<th></th>
<th>Mean</th>
<th>Median</th>
<th>Mode</th>
<th>Variance</th>
<th>Maximum</th>
<th>Minimum</th>
</tr>
</thead>
<tbody>
<tr>
<td>Metaculus</td>
<td>1.93e+23</td>
<td>4.18</td>
<td>4.18</td>
<td>1.42e+49</td>
<td>8.79e+25</td>
<td>0.0043</td>
</tr>
<tr>
<td>PredictionBook</td>
<td>3.93e+23</td>
<td>4.18</td>
<td>4.18</td>
<td>1.11e+50</td>
<td>3.04e+26</td>
<td>0.000137</td>
</tr>
</tbody>
</table>
<p>This shouldn't be <em>that</em> surprising: some of the logistic fits were
basically flat, and some were basically vertical, so it is to be
expected that we have lots of outliers present. What is interesting is
that the median &amp; mode in both datasets are the same number, ~4.17. This
is probably due to many questions having a slope of -1 and an intercept
1<!--TODO: when do they?-->, leading to the same logistic fit.</p>
<p>We can plot a histogram of the horizons for questions (with the horizon
length being logarithmic, base 10):</p>
<pre><code>plt.savefig("perpbquestion_logi.png")

fig=plt.figure(figsize=(8,8))

plt.title("Horizons for logistic curve-fits within questions")
plt.xlabel("Horizon length")
plt.ylabel("Number of questions")

plt.hist([np.log10(met_logi_horizons), np.log10(pb_logi_horizons)], bins=20, color=('red', 'blue'))

plt.savefig("logi_horizons.png")
</code></pre>
<p><img alt="Horizons for the questions" src="./img/range_and_forecasting_accuracy/logi_horizons.png" title="Horizons for the questions in a barplot. Most horizon lengths center around 0, with ~400 for Metaculus and ~500 for PredictionBook, with the number of questions with a specific horizon falling monotonically in the positive direction (Metaculus numbers falling faster than PredictionBook numbers). The number of questions with a specific horizon reaches ~0 at ~10⁵, with a few outliers in the negative (~10⁻⁴) and positive (10²⁵) direction."></p>
<p>From this we can glean that:</p>
<ol>
<li>Most questions supposedly have really short horizon lengths (becoming impossible to predict basically immediately): <code>len(list(filter(lambda x: x&gt;1 and x&lt;10, met_logi_horizons)))/len(met_logi_horizons)≅68.9%</code></li>
<li>Most others have decent horizon lengths (a few hundred to a few thousand days): <code>len(list(filter(lambda x: x&gt;=10 and x&lt;10000, met_logi_horizons)))/len(met_logi_horizons)≈22.8%</code></li>
<li>A few are strong outliers (mostly in the direction of <em>very</em> long horizons): <code>len(list(filter(lambda x: x&lt;=1 or x&gt;=10000, met_logi_horizons)))/len(met_logi_horizons)≈8.27%</code></li>
</ol>
<h4 id="Exponential_CurveFit"><a class="hanchor" href="#Exponential_CurveFit">Exponential Curve-Fit</a></h4>
<p>We can now perform a similar analysis, just using exponential fits.
Here, for some reason, we don't run into problems with inscrutable errors:</p>
<pre><code>within_exp_fits_met=[spo.curve_fit(shift_exp, e[0], e[1], bounds=([0], [1])) for e in wmetqbrier]
within_exp_fits_pb=[spo.curve_fit(shift_exp, e[0], e[1], bounds=([0], [1])) for e in fwpbqbrier]
</code></pre>
<p>This <a href="https://en.wikipedia.org/wiki/Family_of_curves">family of curves</a> can now be plotted (first the exponential functions fitted to questions from the Metaculus data, and then to questions from the PredictionBook data):</p>
<pre><code>fig=plt.figure(figsize=(8,8))

plt.title("Exponential curve-fits for the accuracy of questions by range (only Metaculus data)")
plt.xlabel("Range (days)")
plt.ylabel("Exponential curve-fit")

for i in range(0, len(within_exp_fits_met)):
        r=within_exp_fits_met[i]
        if len(r)==0:
                continue
        rngs=wmetqbrier[i][0]
        coeff=r[0][0]
        cl=hex(random.sample(range(0, 256*256*256), 1)[0]) #random rgb code
        #left padding with zeros, can't be bothered to read the formatting docs right now
        cl='#'+('0'*(6-len(cl[2:])))+cl[2:]
        plt.plot(fullrng_met, shift_exp(fullrng_met, coeff))

plt.savefig("permetquestion_exp.png")
</code></pre>
<p><img alt="Sets of exponential fits on Metaculus questions" src="./img/range_and_forecasting_accuracy/permetquestion_exp.png" title="A plot, x-axis from 0 to 1400, y-axis from 0 to 0.25. On the plot there is a large number of graphs of functions, all exponential, with different steepnesses (all starting from 0 at 0, many reaching 0.25 immediately, and a few being less steep). Two empty regions (“rivers”) are also visible."></p>
<p><img alt="Sets of exponential fits on PredictionBook questions" src="./img/range_and_forecasting_accuracy/perpbquestion_exp.png" title="A plot, x-axis from 0 to 1400, y-axis from 0 to 0.25. On the plot there is a large number of graphs of functions, all exponential, with different steepnesses (all starting from 0 at 0, many reaching 0.25 immediately, and a few being less steep). Way more graphs of functions that in the Metaculus data. Basically ~0 “rivers”."></p>
<p>I personally believe that these plots
are kind of gorgeous. Interesting are the two
<a href="https://en.wikipedia.org/wiki/River_(typography)">"rivers"</a> in
the Metaculus plots: they indicate that there are some horizons for which
there are ~0 questions with that horizon. But this is possibly just due
to a small sample-size &amp; randomness, as they don't really occur in the
PredictionBook data.</p>
<p>Otherwise, these plots look as expected: Most exponential fits quickly
go to randomness (i.e. from an expected Brier score of 0 to a Brier
score of 0.25 in a short range), and some show longer horizons.</p>
<p>Again, I don't quite know how to aggregate these, but I can calculate
the expected horizons for the questions.</p>
<h5 id="Exponential_Forecast_Horizons_for_Questions"><a class="hanchor" href="#Exponential_Forecast_Horizons_for_Questions">Exponential Forecast Horizons for Questions</a></h5>
<p>Calculating the horizons is as easy as before:</p>
<pre><code>met_exp_horizons=[np.log(0.04)/np.log(f[0][0]) for f in within_exp_fits_met]
pb_exp_horizons=[np.log(0.04)/np.log(f[0][0]) for f in within_exp_fits_pb]
</code></pre>
<p>And the summary statistics (in days):</p>
<table>
<thead>
<tr>
<th></th>
<th>Mean</th>
<th>Median</th>
<th>Mode</th>
<th>Variance</th>
<th>Maximum</th>
<th>Minimum</th>
</tr>
</thead>
<tbody>
<tr>
<td>Metaculus</td>
<td>1613.62</td>
<td>4.64</td>
<td>4.64</td>
<td>478494147</td>
<td>497370.21</td>
<td>0.064</td>
</tr>
<tr>
<td>PredictionBook</td>
<td>45041.92</td>
<td>4.64</td>
<td>4.64</td>
<td>8.29e+11</td>
<td>5.31e+7</td>
<td>0.064</td>
</tr>
</tbody>
</table>
<p>The mean here is ~4.42 years for Metaculus data, and 123.4 years for
PredictionBook data.</p>
<p>We can see that the expected horizons aren't as large (at least ~15 orders
of magnitude smaller), but again we observe that both the median <em>and</em>
the mode take on the same value of 4.64.</p>
<p>So we decide to plot a histogram of the expected horizons for the
questions, scaled logarithmically:</p>
<pre><code>fig=plt.figure(figsize=(8,8))

plt.title("Horizons for expstic curve-fits within questions")
plt.xlabel("Horizon length (days, log₁₀)")
plt.ylabel("Number of questions")

plt.hist([np.log10(met_exp_horizons), np.log10(pb_exp_horizons)], bins=20, color=('red', 'blue'))

plt.savefig("exp_horizons.png")
</code></pre>
<p><img alt="Histogram of expected horizons of forecasts on Metaculus &amp; PredictionBook questions" src="./img/range_and_forecasting_accuracy/exp_horizons.png" title="Histogram of expected horizons of forecasts on Metaculus &amp; PredictionBook questions: Horizons on the x-axis, ranging from 10⁻² to 10⁷, and number of questions in the bin on the y-axis, from 0 to ~450. For PredictionBook data, large peak at ~10 with ~420 (blaze it) questions. Then several bins, all with ~40 questions, to ~10⁴, then declining to ~15 questions per bin. Below 10, no strongly discernible pattern, again with ~20 questions per bin. Metaculus data quite similar: ~350 questions on the 10 bin, then a “hill” pattern that peaks at 10² and then declines to <10 questions per bin at 10⁴. ~20 questions per bin for horizons <10."></p>
<p>I wonder if the regularity I perceive (the nice declining "hill"-like
patterns for horizons &gt;10) is a spurious artifact, a result of the
specific method of analysis, or actually inherent in the data. If not,
it indicates that PredictionBook contains more resolved questions with
longer expected horizons (checks out: questions with longer ranges
can be expected to have longer horizons, and PredictionBook has more &amp;
older resolved questions than Metaculus).</p>
<p>Also, again, most questions have ranges ~10 (probably the 4.64 value
from above), which is likely due to them becoming more accurate at higher
ranges (discussed <a href="#Why_Assume_Accuracy_will_Increase">here</a>).</p>
<h3 id="Sample_Sizes"><a class="hanchor" href="#Sample_Sizes">Sample Sizes</a></h3>
<p>One might, again, be interested in the sample sizes. How many predictions
to questions receive?</p>
<p>As we know, the Metaculus dataset contains predictions on 557 questions,
the PredictionBook dataset 13356, but there are way fewer questions with
more than 1 unique prediction in the PredictionBook dataset:</p>
<pre><code>&gt;&gt;&gt; len(metquestions)
557
&gt;&gt;&gt; len(pbquestions)
13356
&gt;&gt;&gt; len(wmetqbrier)
557
&gt;&gt;&gt; len(wpbqbrier)
7596
</code></pre>
<!--TODO: histograms!-->
<p>Let's first create sorted lists containing the numbers of forecasts on
each question:</p>
<pre><code>pblens=np.sort([len(x[0]) for x in wpbqbrier])
metlens=np.sort([len(x[0]) for x in wmetqbrier])
</code></pre>
<p>One can now look at some central values for those datasets: the maximum,
mimimum, mean, median, and mode:</p>
<pre><code>&gt;&gt;&gt; import statistics
&gt;&gt;&gt; np.min(metlens)
2
&gt;&gt;&gt; np.max(metlens)
101
&gt;&gt;&gt; np.mean(metlens)
86.83482944344703
&gt;&gt;&gt; np.median(metlens)
101.0
&gt;&gt;&gt; statistics.mode(metlens)
101
&gt;&gt;&gt; np.min(pblens)
2
&gt;&gt;&gt; np.max(pblens)
99
&gt;&gt;&gt; np.mean(pblens)
5.072538177988415
&gt;&gt;&gt; np.median(pblens)
3.0
&gt;&gt;&gt; statistics.mode(pblens)
2
</code></pre>
<p>This is—surprising, to say the least. Metaculus makes creating
new questions much harder, and more strongly encourages users to
predict on existing questions, with an elaborate tagging system for
questions. PredictionBook on the other hand simplifies the questions
creation process, leaving out moderation, complex resolution criteria
etc. Still, I'm surprised—there must be at least <em>one</em> PredictionBook
question popular enough for 100 forecasts! But apparently not.</p>
<h4 id="Interlude_Its_Under_102"><a class="hanchor" href="#Interlude_Its_Under_102">Interlude: It's Under 102</a></h4>
<p>One result here is, to say the least, confusing—where did
all those 101s come from in the Metaculus data‽ Surely,
there are questions with more than 101 forecasts (which
I <strong>know</strong>, <a href="https://www.metaculus.com/questions/126/will-2016-be-the-warmest-year-on-record/">this question about 2016 being the warmest year on
record</a>
has 765 forecasts)!</p>
<p><img alt="If an item does not appear in our records, it does not exist" src="./img/range_and_forecasting_accuracy/api_incomplete.png" title="Image of confused Obi-Wan Kenobi, with the text “Impossible. Perhaps the api is incomplete.” (If an item does not appear in our records, it does not exist)"></p>
<p>I initially suspected a bug in my code, but to my surprise, after further
investigation, it turns out that the Metaculus API returned timeseries
with elements removed so that the length was always 101.</p>
<p>I can think of two reasons to do this:</p>
<ul>
<li>Metaculus wants to prevent other entities from using the predictions to create stronger forecasting algorithms that could rival the Metaculus algorithm</li>
<li>It was programmed in as a hard limit when Metaculus wasn't as big as it is now, and never changed</li>
</ul>
<p>I mailed the support address on the site, asking for a full timeseries
on resolved binary questions.</p>
<p>After the support address had not responded to my inquiry, I contacted
one of the admins of the site on the Discord, but was informed that
updating the API would be too difficult to do (which is understandable,
the Metaculus developers do not exist to cater to my whims, and are doing
a phenomenal job).</p>
<p>More than a year later, I got hold off the private Metaculus data via
my job, luckily the Metaculus admins also allowed me to use it for my
private investigations.</p>
<p>I subsequently <a href="./range_and_forecasting_accuracy.html#Appendix_A_Replicating_Metaculus_Findings_With_Full_Data">tried to replicate my previous
findings</a>
with the private data, finding that the findings <a href="#Replication_Inbound">mostly replicate,
or are only slightly different</a>.</p>
<h2 id="Limitations"><a class="hanchor" href="#Limitations">Limitations</a></h2>
<p>This analysis is still quite lacking in several aspects and could be
significantly improved.</p>
<h3 id="Metaculus_Dataset_is_Only_Community_Timeseries"><a class="hanchor" href="#Metaculus_Dataset_is_Only_Community_Timeseries">Metaculus Dataset is Only Community Timeseries</a></h3>
<p>The Metaculus dataset and the PredictionBook dataset are quite different:
For PredictionBook, the full dataset of all predictions is available,
while the Metaculus API only offers data of the weighted average of the
community as a timeseries (with ≤101 datapoints). Due to this limitation,
the PredictionBook results and the Metaculus results can't be easily compared.</p>
<p>This is the reason why I reported the results for the Metaculus dataset
and the PredictionBook dataset separately, so that future work can
work either with aggregated timeseries data or with full datasets of
individual forecasts.</p>
<h3 id="PredictionBook_Forecasts_can_be_Resolved_by_Anyone"><a class="hanchor" href="#PredictionBook_Forecasts_can_be_Resolved_by_Anyone">PredictionBook Forecasts can be Resolved by Anyone</a></h3>
<p>PredictionBook, unlike Metaculus, makes no attempts to generate a shared
notion of <a href="https://en.wikipedia.org/wiki/Ground_truth">ground truth</a>:
Any user can resolve any question as they like, with the question-writer
having the final verdict. This would make it quite easy to manipulate
the dataset.</p>
<p>In contrast, Metaculus has a set of admins and moderators that share a
notion of how the questions relate to events in the world, which keeps
questions and resolutions consistent with each other.</p>
<h2 id="Acknowledgements"><a class="hanchor" href="#Acknowledgements">Acknowledgements</a></h2>
<p>I am grateful to Nuño Sempere for pointing out a fatal flaw in my
previous version of this analysis, which caused me to rewrite it nearly
completely.</p>
<p>Im am incredibly indebted to the Long-Term Future Fund, who
gave me enough money for this project that I could justify to my
parents that I wasn't wasting my time, and to pay my <a href="./considerations_on_cryonics.html">cryonics
membership</a> for the year on top
of that.</p>
<h2 id="Miscellaneous"><a class="hanchor" href="#Miscellaneous">Miscellaneous</a></h2>
<p>The code for image generation can be found
<a href="./code/range_and_forecasting_accuracy/draw_all.py">here</a>,
the complete code for analyzing the data can be found
<a href="./code/range_and_forecasting_accuracy/load.py">here</a>.</p>
<p>The code for previous versions was written in
<a href="http://t3x.org/klong/index.html">Klong</a>, but abandoned for reasons
concerning performance &amp; replicability. The previous code for analysis
can be found <a href="./code/range_and_forecasting_accuracy/load.kg">here</a>,
the previous code for image generation can be found
<a href="./code/range_and_forecasting_accuracy/draw_all.kg">here</a> (in some
ways the previous code was much nicer, especially when calculating
<code>metquestions</code>).</p>
<h2 id="See_Also"><a class="hanchor" href="#See_Also">See Also</a></h2>
<ul>
<li><a href="https://www.quantamagazine.org/can-scientists-predict-the-future-of-evolution-20140717/">The New Science of Evolutionary Forecasting (Carl Zimmer, 2014)</a></li>
<li>Discussions
<ul>
<li><a href="https://www.lesswrong.com/posts/MquvZCGWyYinsN49c/range-and-forecasting-accuracy">LessWrong</a></li>
<li><a href="https://forum.effectivealtruism.org/posts/nfEWwLH8qSqNATxmr/range-and-forecasting-accuracy">Effective Altruism Forum</a></li>
<li><a href="https://old.reddit.com/r/forecasting/comments/hrl9on/range_and_forecasting_accuracy_jul_2020/">/r/forecasting</a></li>
</ul></li>
</ul>
<h2 id="Appendix_A_Replicating_Metaculus_Findings_With_Full_Data"><a class="hanchor" href="#Appendix_A_Replicating_Metaculus_Findings_With_Full_Data">Appendix A: Replicating Metaculus Findings With Full Data</a></h2>
<p>After receiving the private data from the Metaculus admins, I decided to
check whether my previous findings would still bear out with the full
dataset, or whether equally shrinking the data on questions with many
forecasts and fewer forecasts had introduced significant amounts of bias.</p>
<h3 id="Some_Predictions_About_The_Results"><a class="hanchor" href="#Some_Predictions_About_The_Results">Some Predictions About The Results</a></h3>
<p>This also gave me an excellent opportunity to test my own calibration
on the findings: Would I be correct about which findings would
and wouldn't hold up to scrutiny with nicer datasets? I used
<a href="https://predictionbook.com/">PredictionBook</a> to record my predictions
about the results before running the code on the data (relying on
the reader's trust that I hadn't just run the code beforehand and
predicted with the benefit of hindsight). The private dataset was
much bigger and more up-to-date than the compressed one from the
<a href="https://www.metaculus.com/api2/questions/">API</a> I had used.</p>
<p>(Yo bro, I heard you like forecasts, so I made forecasts about my
forecasting research…)</p>
<ul>
<li><a href="#Accuracy_Between_Forecasts">Accuracy Between Forecasts</a>
<ul>
<li><a href="#Results_1">Standard Results</a>
<ul>
<li>"<a href="https://predictionbook.com/predictions/209328">Will the Brier score on all resolved Metaculus binary forecasts be greater than or equal to 0.17085?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-33-Title">
<title id="MathJax-SVG-33-Title">_{10\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes, with the Brier score being ≈0.171305)</li>
<li>"<a href="https://predictionbook.com/predictions/209329">Will the correlation between range and Brier score be non-negative for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-34-Title">
<title id="MathJax-SVG-34-Title">_{45\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. The correlation is ≈0.0831)</li>
<li>"<a href="https://predictionbook.com/predictions/209330">Will the correlation between range and Brier score be greater than or equal to 0.02166 for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-35-Title">
<title id="MathJax-SVG-35-Title">_{40\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. Same value as above.)</li>
<li>"<a href="https://predictionbook.com/predictions/209331">Will the slope for the linear regression between range and Brier score be non-negative for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-36-Title">
<title id="MathJax-SVG-36-Title">_{45\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes, with the actual value being ≈6.814357e-5)</li>
<li>"<a href="https://predictionbook.com/predictions/209332">Will the slope for the linear regression between range and Brier score be greater than or equal to 1.4922e-5 for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-37-Title">
<title id="MathJax-SVG-37-Title">_{40\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes, same value as above.)</li>
<li>"<a href="https://predictionbook.com/predictions/209333">Will the intercept for the linear regression between range and Brier score be non-negative for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-38-Title">
<title id="MathJax-SVG-38-Title">_{95\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-39"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes, actual value is ≈0.156991.)</li>
<li>"<a href="https://predictionbook.com/predictions/209334">Will the intercept for the linear regression between range and Brier score be greater than or equal to 0.1675 for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-39-Title">
<title id="MathJax-SVG-39-Title">_{20\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No, same value as above.)</li>
<li>"<a href="https://predictionbook.com/predictions/209335">Will the p-value for the linear regression between range and Brier score be greater than or equal to 1.8994e-6 for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-40-Title">
<title id="MathJax-SVG-40-Title">_{35\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-33"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No, actual value scipy gives is 0.0 (?))</li>
</ul></li>
<li><a href="#NonLinear_CurveFitting">Computing Horizons</a>
<ul>
<li><a href="#Fitting_a_Logistic_Functbion">Fitting a Logistic Function</a>
<ul>
<li>"<a href="https://predictionbook.com/predictions/209342">Will the slope for the logistic-ish fit between range and Brier score be greater than or equal to -1.08226e-6 for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-41-Title">
<title id="MathJax-SVG-41-Title">_{40\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No. Real answer is ≈-4.98313e-3.)</li>
<li>"<a href="https://predictionbook.com/predictions/209343">Will the intercept for the logistic-ish fit between range and Brier score be greater than or equal to 3.5976667e-4 for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-42-Title">
<title id="MathJax-SVG-42-Title">_{20\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No. Real value is ≈5.50015e-18.)</li>
</ul></li>
<li><a href="#Fitting_an_Exponential_Function">Fitting an Exponential Function</a>
<ul>
<li>"<a href="https://predictionbook.com/predictions/209344">Will the parameter b for the exponential-ish fit between range and Brier score be greater than or equal to 0.9579 for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-43-Title">
<title id="MathJax-SVG-43-Title">_{55\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. Actual value is ≈0.971513.)</li>
<li>"<a href="https://predictionbook.com/predictions/209345">Will the parameter b for the exponential-ish fit between range and Brier score be greater than or equal to 0.5 for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-44-Title">
<title id="MathJax-SVG-44-Title">_{80\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-38"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. Actual value same as above.)</li>
</ul></li>
<li><a href="#This_Is_Cool">Horizons</a>
<ul>
<li>"<a href="https://predictionbook.com/predictions/209346">Will the horizon for the logistic-ish fit between range and Brier score be greater than or equal to 1340 days for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-45-Title">
<title id="MathJax-SVG-45-Title">_{60\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-36"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No. Actual value is ≈637.7 days.)</li>
<li>"<a href="https://predictionbook.com/predictions/209347">Will the horizon for the exponential-ish fit between range and Brier score be greater than or equal to 75 days for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-46-Title">
<title id="MathJax-SVG-46-Title">_{55\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. Actual value is ≈111.4 days.)</li>
<li>"<a href="https://predictionbook.com/predictions/209348">Will the mean squared error of the predicted to the actual Brier score for the forecasts be better on logistic fit than the exponential fit, for all resolved Metaculus binary forecasts?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-47-Title">
<title id="MathJax-SVG-47-Title">_{55\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. The <a href="https://en.wikipedia.org/wiki/Mean_squared_error">MSE</a> is ≈0.052517 for exponential fit, ≈0.050224 for logistic fit. Makes logistic better, and resolves this positively.)</li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#Accuracy_Between_Questions">Accuracy Between Questions</a>
<ul>
<li><a href="#Results_2">Standard Results</a>
<ul>
<li>"<a href="https://predictionbook.com/predictions/209349">Will the correlation between range and Brier score be non-negative for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-48-Title">
<title id="MathJax-SVG-48-Title">_{45\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. The correlation is ≈0.017356.)</li>
<li>"<a href="https://predictionbook.com/predictions/209350">Will the correlation between range and Brier score be greater than or equal to -0.00994 for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-49-Title">
<title id="MathJax-SVG-49-Title">_{48\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-38" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. Same value as above.)</li>
<li>"<a href="https://predictionbook.com/predictions/209351">Will the slope for the linear regression between range and Brier score be non-negative for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-50-Title">
<title id="MathJax-SVG-50-Title">_{45\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes, the slope for the linear regression is ≈1.17605e-10.)</li>
<li>"<a href="https://predictionbook.com/predictions/209352">Will the slope for the linear regression between range and Brier score be greater than or equal to -5.19915e-6 for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-51-Title">
<title id="MathJax-SVG-51-Title">_{48\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-38" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes, same value as above.)</li>
<li>"<a href="https://predictionbook.com/predictions/209353">Will the intercept for the linear regression between range and Brier score be non-negative for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-52-Title">
<title id="MathJax-SVG-52-Title">_{98\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-39"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-38" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes, the actual value is ≈0.178096.)</li>
<li>"<a href="https://predictionbook.com/predictions/209354">Will the intercept for the linear regression between range and Brier score be greater than or equal to 0.17513 for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-53-Title">
<title id="MathJax-SVG-53-Title">_{40\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes, same value as above.)</li>
<li>"<a href="https://predictionbook.com/predictions/209355">Will the p-value for the linear regression between range and Brier score be greater than or equal to 0.81493 for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-54-Title">
<title id="MathJax-SVG-54-Title">_{10\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No, actual p-value is ≈0.0.5999 (still very big))</li>
</ul></li>
<li><a href="#NonLinear_CurveFitting_1">Computing Horizons</a>
<ul>
<li>"<a href="https://predictionbook.com/predictions/209356">Will the slope for the logistic-ish fit between range and Brier score be greater than or equal to -7.9206883 for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-55-Title">
<title id="MathJax-SVG-55-Title">_{38\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-33"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-38" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. Actual value is (apparently) -1.)</li>
<li>"<a href="https://predictionbook.com/predictions/209357">Will the intercept for the logistic-ish fit between range and Brier score be greater than or equal to 33.48197 for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-56-Title">
<title id="MathJax-SVG-56-Title">_{50\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No. Actual value is (allegedly) 1.)</li>
<li>"<a href="https://predictionbook.com/predictions/209358">Will the parameter b for the exponential-ish fit between range and Brier score be greater than or equal to 4.77613e-20 for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-57-Title">
<title id="MathJax-SVG-57-Title">_{55\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. Actual value is 0.5 (which still confuses me).)</li>
<li>"<a href="https://predictionbook.com/predictions/209359">Will the parameter b for the exponential-ish fit between range and Brier score be greater than or equal to 0.5 for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-58-Title">
<title id="MathJax-SVG-58-Title">_{99\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-39"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-39" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes, <em>barely</em>, with the same value as above.)</li>
<li>"<a href="https://predictionbook.com/predictions/209360">Will the horizon for the logistic-ish fit between range and Brier score be greater than or equal to 4.5 days for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-59-Title">
<title id="MathJax-SVG-59-Title">_{55\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No, the actual value being ≈4.1781.)</li>
<li>"<a href="https://predictionbook.com/predictions/209361">Will the horizon for the exponential-ish fit between range and Brier score be greater than or equal to 9 days for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-60-Title">
<title id="MathJax-SVG-60-Title">_{45\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No, the actual value being ≈4.6439.)</li>
<li>"<a href="https://predictionbook.com/predictions/209362">Will the mean squared error of the predicted to the actual Brier score for the questions be better on logistic fit than the exponential fit, for all resolved Metaculus binary questions?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-61-Title">
<title id="MathJax-SVG-61-Title">_{60\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-36"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No, their mean squared errors are <em>equally good</em> at predicting the data (≈0.02445 in both cases).)</li>
</ul></li>
</ul></li>
<li><a href="#Accuracy_Within_Questions">Accuracy Within Questions</a>
<ul>
<li><a href="#Results_3">Standard Results</a>
<ul>
<li>"<a href="https://predictionbook.com/predictions/209368">Will the slope of the aggregated linear regressions on resolved Metaculus binary questions with ≥10 predictions be greater or equal to zero?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-62-Title">
<title id="MathJax-SVG-62-Title">_{85\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-38"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. Actual value is ≈0.00272)</li>
<li>"<a href="https://predictionbook.com/predictions/209369">Will the slope of the aggregated linear regressions on resolved Metaculus binary questions with ≥10 predictions be greater or equal to 0.00305?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-63-Title">
<title id="MathJax-SVG-63-Title">_{83\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-38"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-33" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No. Same value as above.)</li>
<li>"<a href="https://predictionbook.com/predictions/209370">Will the intercept of the aggregated linear regressions on resolved Metaculus binary questions with ≥10 predictions be greater or equal to zero?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-64-Title">
<title id="MathJax-SVG-64-Title">_{52\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-32" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. Actual value is ≈0.06956.)</li>
<li>"<a href="https://predictionbook.com/predictions/209371">Will the intercept of the aggregated linear regressions on resolved Metaculus binary questions with ≥10 predictions be greater or equal to 0.0388?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-65-Title">
<title id="MathJax-SVG-65-Title">_{50\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. Actual value same as above.)</li>
</ul></li>
<li>Computing Horizons
<ul>
<li><a href="#Logistic_Forecast_Horizons_for_Questions">Logistic-ish Horizons</a>
<ul>
<li>"<a href="https://predictionbook.com/predictions/209372">Will the median forecast horizon of the logistic regressions on resolved Metaculus binary questions with ≥10 predictions be greater or equal to 4.18 days?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-66-Title">
<title id="MathJax-SVG-66-Title">_{52\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-32" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No. Actual value is ≈4.178.)</li>
<li>"<a href="https://predictionbook.com/predictions/209373">Will the mean forecast horizon of the logistic regressions on resolved Metaculus binary questions with ≥10 predictions be greater or equal to 1.93e+23 days?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-67-Title">
<title id="MathJax-SVG-67-Title">_{45\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No. Actual value is ≈5.1999e+20 days.)</li>
<li>"<a href="https://predictionbook.com/predictions/209374">Will the modal forecast horizon of the logistic regressions on resolved Metaculus binary questions with ≥10 predictions be greater or equal to 4.18 days?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-68-Title">
<title id="MathJax-SVG-68-Title">_{55\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No. Actual value is ≈4.178 (this is what happens when you round numbers in your forecasting questions).)</li>
<li>"<a href="https://predictionbook.com/predictions/209375">Will the variance of the forecast horizon of the logistic regressions on resolved Metaculus binary questions with ≥10 predictions be greater or equal to 1.42e+49?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-69-Title">
<title id="MathJax-SVG-69-Title">_{55\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No. Actual value is ≈2.231076e+20 days.)</li>
</ul></li>
<li><a href="#Exponential_Forecast_Horizons_for_Questions">Exponential-ish Horizons</a>
<ul>
<li>"<a href="https://predictionbook.com/predictions/209376">Will the median forecast horizon of the exponential-ish regressions on resolved Metaculus binary questions with ≥10 predictions be greater or equal to 4.64 days?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-70-Title">
<title id="MathJax-SVG-70-Title">_{48\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-38" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Answer: Yes. Actual answer is ≈4.6439.)</li>
<li>"<a href="https://predictionbook.com/predictions/209377">Will the mean forecast horizon of the exponential-ish regressions on resolved Metaculus binary questions with ≥10 predictions be greater or equal to 1613.62 days?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-71-Title">
<title id="MathJax-SVG-71-Title">_{60\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-36"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-30" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No. Actual answer is ≈256.0893 days.)</li>
<li>"<a href="https://predictionbook.com/predictions/209378">Will the modal forecast horizon of the exponential-ish regressions on resolved Metaculus binary questions with ≥10 predictions be greater or equal to 4.64 days?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-72-Title">
<title id="MathJax-SVG-72-Title">_{55\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (Yes. Actual answer is ≈4.64386 days.)</li>
<li>"<a href="https://predictionbook.com/predictions/209379">Will the variance of the forecast horizon of the exponential-ish regressions on resolved Metaculus binary questions with ≥10 predictions be greater or equal to 478494147?</a>"<span class="mjpage"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.245ex" height="1.843ex" style="vertical-align: -0.838ex;" viewBox="0 -432.6 1397.2 793.3" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-73-Title">
<title id="MathJax-SVG-73-Title">_{55\%}</title>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(0,-187)">
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-35" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#MJMAIN-25" x="1001" y="0"></use>
</g>
</g>
</svg></span> (No. Actual answer is ≈1503031.6 days.)</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p>So, how well did I predict the outcome of my own research? I'll use the
log score for a change:</p>
<pre><code>probs=[0.1, 0.45, 0.4, 0.45, 0.4, 0.95, 0.2, 0.35, 0.4, 0.2, 0.55, 0.8, 0.6, 0.55, 0.55, 0.45, 0.48, 0.45, 0.98, 0.4, 0.1, 0.38, 0.5, 0.55, 0.99, 0.55, 0.45, 0.6, 0.85, 0.83, 0.52, 0.5, 0.52, 0.45, 0.55, 0.55, 0.48, 0.6, 0.55, 0.55]
outcs=[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]
&gt;&gt;&gt; np.mean(list(map(lambda x: math.log(x[0]) if x[1]==1 else math.log(1-x[0]), zip(probs, outcs))))
-0.7255765152440997
</code></pre>
<p>Would a uniformly random guesser have beaten me?</p>
<pre><code>&gt;&gt;&gt; np.mean(list(map(lambda x: math.log(x[0]) if x[1]==1 else math.log(1-x[0]), zip([0.5]*40, outcs))))
-0.6931471805599453
</code></pre>
<p>Apparently yes. So either making predictions about the replication of
your own research is hard, or I'm just bad at it. Yours to decide.</p>
<h3 id="Analysis__Results"><a class="hanchor" href="#Analysis__Results">Analysis &amp; Results</a></h3>
<p>I use <a href="./iqisa.html">iqisa</a> and the private Metaculus data to reproduce
the analysis.</p>
<pre><code>$ python3
&gt;&gt;&gt; import metaculus
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import scipy.stats as sps
&gt;&gt;&gt; import scipy.optimize as spo
&gt;&gt;&gt; daysec=24*60*60
&gt;&gt;&gt; m=metaculus.load_private_binary('../prediction_data/metaculus/private.json')
&gt;&gt;&gt; pmetbriers=(m['probability']-pd.to_numeric(m['outcome']))**2
&gt;&gt;&gt; pmetrngs=m['resolve_time']-(pd.to_datetime(m['timestamp'], utc=True))
&gt;&gt;&gt; pmetrngs=pmetrngs.values.astype(np.int64) / (10 ** 9 * daysec)
</code></pre>
<p>Again we filter out forecasts with negative ranges:</p>
<pre><code>&gt;&gt;&gt; m=m.loc[pmetrngs&gt;0]
&gt;&gt;&gt; pmetbriers=pmetbriers[pmetrngs&gt;0]
&gt;&gt;&gt; pmetrngs=pmetrngs[pmetrngs&gt;0]
</code></pre>
<p>And can see that the Brier score isn't much different from the squashed
data (even though there are many more forecasts:</p>
<pre><code>&gt;&gt;&gt; np.mean(pmetbriers)
0.1713050461310057
&gt;&gt;&gt; len(pmetbriers)
228872
</code></pre>
<h4 id="Analysis_Between_Forecasts"><a class="hanchor" href="#Analysis_Between_Forecasts">Analysis Between Forecasts</a></h4>
<pre><code>&gt;&gt;&gt; np.corrcoef(pmetbriers, pmetrngs)
array([[1.        , 0.08314111],
    [0.08314111, 1.        ]])
&gt;&gt;&gt; sps.linregress(pmetrngs, pmetbriers)
LinregressResult(slope=6.814357486306815e-05, intercept=0.15699128148663716, rvalue=0.08314111171996655, pvalue=0.0, stderr=1.7072944201034568e-06, intercept_stderr=0.000589651206310534)
</code></pre>
<p>And now onto the horizons between forecasts:</p>
<pre><code>&gt;&gt;&gt; def shrunk_logistic(x, slope, intercept):
...     return 0.25*1/(1+np.exp(slope*x+intercept))
...
&gt;&gt;&gt; pmetlogifit=spo.curve_fit(shrunk_logistic, pmetrngs, pmetbriers, bounds=([-np.inf, 0], [0, np.inf]))
(array([-4.98313302e-03,  5.50014913e-18]), array([[ 9.12453976e-09, -8.09152901e-07],
    [-8.09152901e-07,  1.53512973e-04]]))
</code></pre>
<p>The exponential fit is less stocky:</p>
<pre><code>&gt;&gt;&gt; def shift_exp(x, b):
...     return ((b**x)-1)/(-4)
&gt;&gt;&gt; pmetexpfit=spo.curve_fit(shift_exp, pmetrngs, pmetbriers, bounds=([0], [1]))
(array([0.97151306]), array([[7.70042249e-08]]))
</code></pre>
<p>And now onto the horizons:</p>
<pre><code>&gt;&gt;&gt; (np.log((1/0.96)-1)-pmetlogifit[0][1])/pmetlogifit[0][0]
637.762190036701
&gt;&gt;&gt; np.log(0.04)/np.log(pmetexpfit[0][0])
111.37758594236286
</code></pre>
<p>The horizon for the logistic fit is ~2 years, the one for the exponential
fit is less than half a year.</p>
<p>The <a href="https://en.wikipedia.org/wiki/Mean_squared_error">mean squared
errors</a> of the two
methods are</p>
<pre><code>&gt;&gt;&gt; np.mean((shrunk_logistic(pmetrngs, pmetlogifit[0][0], pmetlogifit[0][1])-pmetbriers)**2)
0.05022431479118167
&gt;&gt;&gt; np.mean((shift_exp(pmetrngs, pmetexpfit[0][0])-pmetbriers)**2)
0.052517437982678494
</code></pre>
<p>As one can see, the logistic fit <em>barely</em> beats the exponential fit.</p>
<h4 id="Analysis_Between_Questions"><a class="hanchor" href="#Analysis_Between_Questions">Analysis Between Questions</a></h4>
<p>First we have to rewrite the code that groups the forecasts by question.</p>
<pre><code>pmetquestions=[]

for e in np.unique(m['question_id']):
    indices=np.where(m['question_id']==e)[0]
    subdata=m.loc[m['question_id']==e]
    questionrange=list(subdata['days_open'])[0].total_seconds()
    outcomes=np.array(pd.to_numeric(subdata['outcome']))
    probabilities=np.array(subdata['probability'])
    franges=pmetrngs[indices]
    pmetquestions.append([e, questionrange, outcomes, probabilities, franges])
</code></pre>
<p>We now have slightly more questions (nearly twice as many):</p>
<pre><code>&gt;&gt;&gt; len(pmetquestions)
916
</code></pre>
<p>We define the Brier score again, and then already calculate the Brier scores for the questions:</p>
<pre><code>&gt;&gt;&gt; def brier(x, y):
... return np.mean((x-y)**2)
&gt;&gt;&gt; pmetqbrier=np.array([[i[1], brier(i[3], i[2])] for i in pmetquestions])
</code></pre>
<p>And now we're ready to calcuate the results:</p>
<pre><code>&gt;&gt;&gt; np.corrcoef(pmetqbrier.T)
array([[1.       , 0.0173564],
    [0.0173564, 1.       ]])
&gt;&gt;&gt; sps.linregress(pmetqbrier.T[0], pmetqbrier.T[1])
LinregressResult(slope=1.1760476061621512e-10, intercept=0.17809615527756018, rvalue=0.01735639826497777, pvalue=0.5998458799770909, stderr=2.240922169316534e-10, intercept_stderr=0.0057047415146507935)
</code></pre>
<p>And now we can again look at the non-linear curve-fits:</p>
<pre><code>&gt;&gt;&gt; pmetlogifit_betweenq=spo.curve_fit(shrunk_logistic, pmetqbrier.T[0], pmetqbrier.T[1], bounds=([-np.inf, 0], [0, np.inf]))
(array([-1.,  1.]), array([[0., 0.],
    [0., 0.]]))
&gt;&gt;&gt; pmetexpfit_betweenq=spo.curve_fit(shift_exp, pmetqbrier.T[0], pmetqbrier.T[1], bounds=([0], [1]))
(array([0.5]), array([[0.]]))
</code></pre>
<p>The exponential fit gives quite odd results—maybe a bug (another one‽)?</p>
<p>Meanwhile, here's the (resulting) predictive horizons:</p>
<pre><code>&gt;&gt;&gt; (np.log(1/(0.96)-1)-pmetlogifit_betweenq[0][1])/pmetlogifit_betweenq[0][0]
4.1780538303479435
&gt;&gt;&gt; np.log(0.04)/np.log(pmetexpfit_betweenq[0][0])
4.643856189774724
</code></pre>
<p>And the MSE for both methods (where something <em>really odd</em> happens):
The two methods have the <em>same</em> MSE for fitting the data.</p>
<pre><code>&gt;&gt;&gt; np.mean((shrunk_logistic(pmetqbrier.T[0], pmetlogifit_betweenq[0][0], pmetlogifit_betweenq[0][1])-pmetqbrier.T[1])**2)
0.024506121283245946
&gt;&gt;&gt; np.mean((shift_exp(pmetqbrier.T[0], pmetexpfit_betweenq[0][0])-pmetqbrier.T[1])**2)
0.024506121283245946
</code></pre>
<p><img alt="Image of an old overweight woman with open mouth, looking very confused, caption “Wat”" src="./img/range_and_forecasting_accuracy/wat.jpg" title="Image of an old overweight woman with open mouth, looking very confused, caption “Wat”"></p>
<p>I have no idea why this should be the case. Nice thing that I wrote
the resolution criterion for the question comparing MSE unambigiously
(though I still loose Brier points on this one :-/).</p>
<h3 id="Analysis_Within_Questions"><a class="hanchor" href="#Analysis_Within_Questions">Analysis Within Questions</a></h3>
<p>First, one can again calculate the Brier scores for each forecast on
each question.</p>
<pre><code>&gt;&gt;&gt; pwmetqbrier=[[i[4], (i[3]-i[2])**2] for i in pmetquestions]
&gt;&gt;&gt; pwmetqbrier=list(filter(lambda x: len(x[0])&gt;1, pwmetqbrier))
</code></pre>
<p>And now one can compute the correlations and linear regressions:</p>
<pre><code>&gt;&gt;&gt; pmetqcorrs=np.array(list(map(lambda x: np.corrcoef(x)[0][1], pwmetqbrier)))
&gt;&gt;&gt; np.mean(pmetqcorrs)
0.18631554785062648
&gt;&gt;&gt; pwmetqregs=list(map(lambda x: sps.linregress(x[0], x[1]), pwmetqbrier))
&gt;&gt;&gt; clean_pmetforecasts=np.sum([len(pwmetqbrier[i][0]) for i in range(0, len(pwmetqbrier))])
&gt;&gt;&gt; pawmetqslope=np.sum([len(pwmetqbrier[i][0])*pwmetqregs[i][0] for i in range(0, len(pwmetqregs))])/clean_pmetforecasts
0.0027204188974885805
&gt;&gt;&gt; pawmetqintercept=np.sum([len(pwmetqbrier[i][0])*pwmetqregs[i][1] for i in range(0, len(pwmetqregs))])/clean_pmetforecasts
0.06956244334109736
</code></pre>
<!--TODO: examine the correlations here!-->
<p>The number of forecasts on each question shouldn't be a problem here:</p>
<pre><code>&gt;&gt;&gt; np.sort(list(map(lambda x: len(x[0]), pwmetqbrier)))
array([   2,    7,   11,   12,   12,   13,   16,   17,   17,   20,   24,
25,   26,   27,   28,   28,   29,   30,   30,   31,   31,   32,
32,   33,   34,   34,   36,   36,   37,   38,   39,   39,   39,
40,   40,   41,   42,   42,   43,   44,   44,   44,   44,   45,
[...]
900,  901,  912,  924,  946, 1001, 1007, 1032, 1035, 1075, 1083,
1178, 1191, 1201, 1271, 1319, 1346, 1405, 1472, 1706, 1978, 2290,
3144, 6483, 6543])
</code></pre>
<p>Now one can calculate the logistic-ish fits on the private metaculus data:</p>
<pre><code>within_logi_fits_pmet=[]
for e in pwmetqbrier:
    try:
        within_logi_fits_pmet.append(spo.curve_fit(shrunk_logistic, e[0], e[1], bounds=([-np.inf, 0], [0, np.inf])))
    except RuntimeError:
        within_logi_fits_pmet.append([])
        print(e)
        continue
</code></pre>
<p>Again there are datapoints for which the logistic fit fails (two of them:
<code>len(list(filter(lambda x: len(x)==0, within_logi_fits_pmet)))==2</code>).</p>
<p>Now, onto the logistic horizons:</p>
<pre><code>&gt;&gt;&gt; within_logi_fits_pmet_filt=list(filter(lambda x: len(x)&gt;0, within_logi_fits_pmet))
&gt;&gt;&gt; pmet_logi_horizons=[(np.log((1/0.96)-1)-f[0][1])/f[0][0] for f in within_logi_fits_pmet_filt]
&gt;&gt;&gt; np.mean(pmet_logi_horizons)
5.1599872031050446e+20
&gt;&gt;&gt; np.median(pmet_logi_horizons)
4.1780538303479435
&gt;&gt;&gt; import statistics
&gt;&gt;&gt; statistics.mode(pmet_logi_horizons)
4.1780538303479435
&gt;&gt;&gt; np.var(pmet_logi_horizons)
2.310750917165898e+44
&gt;&gt;&gt; np.max(pmet_logi_horizons)
4.597770789879067e+23
&gt;&gt;&gt; np.min(pmet_logi_horizons)
0.0039049963844999995
</code></pre>
<p>And onto the exponential-ish horizons:</p>
<pre><code>&gt;&gt;&gt; within_exp_fits_pmet=[spo.curve_fit(shift_exp, e[0], e[1], bounds=([0], [1])) for e in pwmetqbrier]
&gt;&gt;&gt; pmet_exp_horizons=[np.log(0.04)/np.log(f[0][0]) for f in within_exp_fits_pmet]
&gt;&gt;&gt; np.mean(pmet_exp_horizons)
256.0893331713647
&gt;&gt;&gt; np.median(pmet_exp_horizons)
4.643856189774724
&gt;&gt;&gt; statistics.mode(pmet_exp_horizons)
4.643856189774724
&gt;&gt;&gt; np.var(pmet_exp_horizons)
1503031.5933197956
&gt;&gt;&gt; np.max(pmet_exp_horizons)
27452.431682813913
&gt;&gt;&gt; np.min(pmet_exp_horizons)
0.07308535616222363
</code></pre>
<h3 id="Replication_Inbound"><a class="hanchor" href="#Replication_Inbound">Replication Inbound?</a></h3>
<p>And that concludes the replication attempt. Does it replicate the
original findings?</p>
<ul>
<li>Between forecasts
<ul>
<li>The positive correlation between range and accuracy stays the same ✓</li>
<li> The linear regression is similar too (very small positive slope, intercept at ~0.16). ✓</li>
<li>The logistic-ish fit gives values within ~2 orders of magnitude for the slope &amp; intercept, and both have the right sign. ✓</li>
<li>The exponential-ish fit, though, gives a <em>much</em> different value close to 1, while the original was one close to zero. ✗</li>
<li>The logistic-ish horizon is ~half as long as the one with the restricted data. ~</li>
<li>The exponential-ish horizon is ~60 times shorter than in the original finding. ✗</li>
<li>The logistic-ish fit is better than the exponential-ish fit, again. ✓</li>
</ul></li>
<li>Between questions
<ul>
<li>The correlation between range and accuracy flips sign, but stays very small. ✗</li>
<li>The slope of the linear regression also flips sign, but the intercept is remarkably similar. ~</li>
<li>The p-value is still abysmal. ✓</li>
<li>The sign of the logistic-ish fit is the same for both parameters, though the original parameters were more extreme. ~</li>
<li>The exponential-ish fit has a slightly smaller parameter, which discounts even more aggressively. ~</li>
<li>The logistic-ish predictive horizon is sightly smaller, but in the same ballpark. ✓</li>
<li>The exponential-ish horizon is ~half as long. ~</li>
<li>The mean squared errors of both methods are again remarkably close. ✓</li>
</ul></li>
<li>Within questions
<ul>
<li>Slope for linear regressions is surprising close, intercept off by a factor of ~2. Still ok. ✓</li>
<li>Mean logistic-ish horizon is ~3 orders of magnitude away from original estimate, median &amp; mode are the same (?), variance is smaller (~5 orders of magnitude), maximum &amp; minimum are kind of close. Estimating the slope of a <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a> is difficult. ~</li>
<li>Mean exponential-ish horizon is factor ~7 smaller than original estimate, median &amp; mode again are the same, variance smaller, maximum smaller and minimum slightly larger. ~</li>
</ul></li>
</ul>
<h2 id="Appendix_B_Statistical_Significance_of_Truncated_Datasets"><a class="hanchor" href="#Appendix_B_Statistical_Significance_of_Truncated_Datasets">Appendix B: Statistical Significance of Truncated Datasets</a></h2>
<p>One could also be interested in how the statistical significance of the
linear regression and correlation develops when we remove the forecasts
with short ranges. This can be implemented quite easily by creating a
function <code>val_shrinking_dataset</code> which first sorts the pre-computed
Brier scores by range, and then calculates <a href="https://en.wikipedia.org/wiki/p-value">p-values</a> and correlation
coefficients, afterwards removing the earliest prediction from the dataset (I
have no idea whether this is statistically acceptable, but it seemed like
a reasonable thing to do, lest there's some problem here with p-hacking).
The values are concatenated into arrays, which are then returned.</p>
<pre><code>def val_shrinking_dataset(briers, ranges):
    sortind=np.argsort(ranges)
        chronbriers=briers[sortind]
        chronranges=ranges[sortind]/30
        dropranges=[]
        pvalues=[]
        rvalues=[]
        for i in range(0, len(ranges)-2):
                _, _, rval, pval, _=sps.linregress(chronranges, chronbriers)
                pvalues.append(pval)
                rvalues.append(rval)
                dropranges.append(chronranges[0])
                chronranges=chronranges[1::]
                chronbriers=chronbriers[1::]
        return np.vstack([pvalues, rvalues, dropranges])

metpvals=val_shrinking_dataset(metbriers, metrngs)
pbpvals=val_shrinking_dataset(pbbriers, pbrngs)
</code></pre>
<p>The resulting data can be plotted (correlation cofficients on the left
y-axis, p-values on the (logarithmic) right y-axis). Here, the datapoint
at range <code>x</code> would be the correlation coefficient and its p-value for
all Brier scores <em>after</em> <code>x</code> (sorry for the legend in the upper right
corner, I couldn't figure out how to move it to the right middle-bottom).</p>
<pre><code>fig=plt.figure(figsize=(10,10), clear=True)

_, ax1 = plt.subplots()

ax1.set_xlabel("Range (months)")
ax1.set_ylabel("Correlation value")
ax1.plot(metpvals[2], metpvals[1], '-', linewidth=3, color='#ff4500', label="Metaculus truncated correlations")
ax1.plot(pbpvals[2], pbpvals[1], '-', linewidth=3, color='#00bfff', label="PredictionBook truncated correlations")
ax1.legend(loc='lower right')

ax2=ax1.twinx()
ax2.set_ylabel("p value")
ax2.semilogy(metpvals[2], metpvals[0], '-', color='#ffa500', linewidth=1, label="Metaculus truncated p-values")
ax2.semilogy(pbpvals[2], pbpvals[0], '-', color='cyan', linewidth=1, label="PredictionBook truncated p-values")
ax2.legend(loc='upper right')

plt.savefig("pvals_ss_plot.png")
</code></pre>
<p><img alt="Plot with four lines. Two are correlation coefficients, of Metaculus truncated correlations and PredictionBook truncated correlations. The Metaculus correlations are close to zero in the first ~15 months, then dip into negative correlations (around -0.2) until month ~35, then rise to positive correlations (around 0.15) until month 40, and then start oscillating wildly (shortly afterwards the data for Metaculus correlations ends). The PredictionBook correlations also start around 0, then rise slowly to ~0.05 at 60 months, at which point they start oscillating around 0 with larger and larger amplitudes until month 120. The p-values for Metaculus start out around 10⁻⁶, then jump around between 10⁻⁵ to 10⁻² in the first 15 months, and then dip down in the range of 10⁻²⁵ to 10⁻³⁵, and then recover back to 10⁻⁵ to 10⁻² until the end of the Metaculus dataset. The PredictionBook p-values start out at around 10⁻⁵, where they stay until 25 months, then rise to 10⁻¹ to 10⁻² until month 40, then drop down back to 10⁻⁵ until month 65, and then finally rise back up to 10⁻² to 10⁻³ month where they stay until the dataset ends." src="./img/range_and_forecasting_accuracy/pvals_plot.png" title="Plot with four lines. Two are correlation coefficients, of Metaculus truncated correlations and PredictionBook truncated correlations. The Metaculus correlations are close to zero in the first ~15 months, then dip into negative correlations (around -0.2) until month ~35, then rise to positive correlations (around 0.15) until month 40, and then start oscillating wildly (shortly afterwards the data for Metaculus correlations ends). The PredictionBook correlations also start around 0, then rise slowly to ~0.05 at 60 months, at which point they start oscillating around 0 with larger and larger amplitudes until month 120. The p-values for Metaculus start out around 10⁻⁶, then jump around between 10⁻⁵ to 10⁻² in the first 15 months, and then dip down in the range of 10⁻²⁵ to 10⁻³⁵, and then recover back to 10⁻⁵ to 10⁻² until the end of the Metaculus dataset. The PredictionBook p-values start out at around 10⁻⁵, where they stay until 25 months, then rise to 10⁻¹ to 10⁻² until month 40, then drop down back to 10⁻⁵ until month 65, and then finally rise back up to 10⁻² to 10⁻³ month where they stay until the dataset ends."></p>
<p>And the same chart, just without the Metaculus data to make it easier
to read (<em>allegedly</em>):</p>
<p><img alt="The same plot, but without the outlier Metaculus p-values" src="./img/range_and_forecasting_accuracy/pvals_pb_plot.png" title="The same plot, but without the outlier Metaculus p-values"></p>
<p>These graphs are quite interesting in several regards. First, we can see
that the correlation coefficients don't have a clear development as one
removes forecasts with low ranges from the dataset: for Metaculus the
correlation first goes down, then up again. (This might be an artifact
of having very little data for long ranges in the Metaculus dataset,
though). PredictionBook data is a bit more consistent: the correlation
between range and accuracy rises the more early datapoints we remove
(again with the coefficient flailing around in the end because it just
doesn't have enough data).</p>
<p>But truly odd is the p-value here: The dip in the correlation coefficient
for Metaculus data is judged to be <em>extremely unlikely</em> to have occurred
randomly, down to <code>$10^{-35}$</code>, so that it makes the chart nearly unreadable
even on a log-scale.</p>
<p>I am…not quite sure what to make of this. Intuitively, I would expect
the correlation between range and accuracy to start out strong with the
whole dataset, and then become weaker, noisier and more likely to be
random the more values I remove from the start of the dataset. Perhaps
the short-range Metaculus forecasts just introduce a bunch of noise,
because people scramble to get a last prediction in? But that doesn't
explain why the correlation is then negative with an extremely low
p-value with predictions with a range of less than 18 months removed.</p>
<p>The changes in Metaculus correlations might coincide with new years,
perhaps?</p>
<p>For PredictionBook, there is a more straight-forward story to tell,
namely that short-range predictions seem to just introduce noise,
and the longer the range, the stronger the correlation (although the
relation to p-values doesn't look strong in any way, I wonder whether
there is a way to test that).</p>
<h2 id="Appendix_C_Quotes_About_the_Horizon_of_Forecasts"><a class="hanchor" href="#Appendix_C_Quotes_About_the_Horizon_of_Forecasts">Appendix C: Quotes About the Horizon of Forecasts</a></h2>
<blockquote>
<p>Demographers disagree about many things, but not that the further into
the future we try to look, the more likely our forecasts are to be wrong.</p>
</blockquote>
<p><em>— <a href="https://en.wikipedia.org/wiki/Richard_J._Herrnstein">Richard J. Hernstein</a> &amp; <a href="https://en.wikipedia.org/wiki/Charles_Murray_(political_scientist)">Charles Murray</a>, <a href="https://en.wikipedia.org/wiki/The_Bell_Curve">“The Bell Curve”</a> ch. 15, 1994</em></p>
<blockquote>
<p>The future is hard to predict. We may feel confident that eventually
space will be colonized, or that eventually we'll make stuff by putting
each atom just where we want it. But so many other changes may happen
before and during those changes that it is hard to say with much
confidence how space travel or nanotechnology may affect the ordinary
person. Our vision seems to fade into a fog of possibilities.</p>
<p>The scenario I am about to describe excites me because it seems
an exception to this general rule --[sic] more like a crack of dawn than
a fog, like a sharp transition with sharp implications regardless of
the night that went before. Or like a sight on the horizon much clearer
than the terrain inbetween. And, as scenarios go, this one seems rather
likely. Here it is.</p>
</blockquote>
<p><em>— <a href="https://en.wikipedia.org/wiki/Robin_Hanson">Robin Hanson</a>, <a href="http://mason.gmu.edu/~rhanson/uploads.html">“If Uploads Come First”</a>, 1994</em></p>
<blockquote>
<p>As time passes, the outcomes of most events become more predictable. It
is therefore important to update probability estimates. We did this in
the aggregation method by using an exponential decay (a time constant
of a couple days was optimal in most of our tests), so that out-of-date
predictions counted less.</p>
</blockquote>
<p><em>— <a href="https://en.wikipedia.org/wiki/Lyle_Ungar">Lyle Ungar</a> et al., <a href="./doc/prediction/the_good_judgement_project_a_large_scale_test_of_different_methods_of_combining_expert_predictions_ungar_et_al_2012.pdf">“The Good Judgment Project: A large scale test of different methods of combining expert predictions”</a> p. 3, 2012</em></p>
<blockquote>
<p>It was easiest to beat chance on the shortest-range questions that
only required looking one year out, and accuracy fell off the further
out experts tried to forecast—approaching the dart-throwing-chimpanzee
level three to five years out.</p>
</blockquote>
<p><em>— <a href="https://en.wikipedia.org/wiki/Philip_E._Tetlock">Philip E. Tetlock</a> &amp; Dan Gardner, “Superforecasting” p. 12, 2015</em></p>
<blockquote>
<p>Take something as seemingly simple as the relationship between time and
predictability: it is generally true that the further we try to look into
the future, the harder it is to see. But there can be prolonged exceptions
to the rule. Predicting the continuation of a long bull market in stocks
can prove profitable for many years—until it suddenly proves to be
your undoing. And predicting that dinosaurs would continue to preside
at the top of the food chain was a safe bet for tens of millions of
years—until an asteroid set off a cataclysm that opened up ecological
niches for a tiny mammal that eventually evolved into a species that
tries to predict the future.<br>
[…]<br>
The further out the forecaster tries to look, the more opportunity there
is for chaos to flap its butterfly wings and blow away expectations. Big
leaps in computing power and continued refinement of forecasting models
may nudge the limits a little further into the future but those advances
gradually get harder and the payoffs shrink toward zero. How good can
it get? No one knows. But knowing the current limits is itself a success.</p>
</blockquote>
<p><em>— <a href="https://en.wikipedia.org/wiki/Philip_E._Tetlock">Philip E. Tetlock</a> &amp; Dan Gardner, “Superforecasting” p. 20/21, 2015</em></p>
<blockquote>
<p>Across all four years of the tournament, superforecasters looking out
three hundred days were more accurate than regular forecasters looking
out one hundred days. In other words, regular forecasters needed to
triple their foresight to see as far as superforecasters.</p>
</blockquote>
<p><em>— <a href="https://en.wikipedia.org/wiki/Philip_E._Tetlock">Philip E. Tetlock</a> &amp; Dan Gardner, “Superforecasting” p. 94, 2015</em></p>
<blockquote>
<p>Taleb, Kahneman, and I agree there is no evidence that geopolitical
or economic forecasters can predict anything ten years out beyond the
excruciatingly obvious—“there will be conflicts”—and the odd
lucky hits that are inevitable whenever lots of forecasters make lots of
forecasts. These limits on predictability are the predictable results
of the butterfly dynamics of nonlinear systems. In my EPJ research,
the accuracy of expert predictions declined toward chance five years out.</p>
</blockquote>
<p><em>— <a href="https://en.wikipedia.org/wiki/Philip_E._Tetlock">Philip E. Tetlock</a> &amp; Dan Gardner, “Superforecasting” p. 234, 2015</em></p>
<blockquote>
<p>The future is usually "absurd" - it is unstable in its surface rules
over fifty-year intervals.</p>
</blockquote>
<p><em>— <a href="https://www.yudkowsky.net/">Eliezer Yudkowsky</a>, <a href="https://www.lesswrong.com/posts/P792Z4QA9dzcLdKkE/absurdity-heuristic-absurdity-bias">“Absurdity Heuristic, Absurdity Bias”</a>, 2007</em></p>
<blockquote>
<p>Successfully predicting the unimaginably far future - that is, more
than 2 or 3 years out, or sometimes less - is something that human beings
seem to be quite bad at, by and large.</p>
</blockquote>
<p><em>— <a href="https://www.yudkowsky.net/">Eliezer Yudkowsky</a>, <a href="https://www.lesswrong.com/s/EcKbpm4f7fBwhxRZs/p/ax695frGJEzGxFBK4">“Biology-Inspired AGI Timelines: The Trick That Never Works”</a>, 2021</em></p>
<blockquote>
<p>Near-term is more predictable and hence conclusions are more likely to be true, but far futures may be more entertaining since more extreme things are possible.</p>
</blockquote>
<p><em>—Anders Sandberg, “Grand Futures” p. 32, 2023</em></p>
<blockquote>
<p>Two main indicators of forecasting ease are the forecast's size and time
horizon. More extreme probability estimates reflect greater certainty,
which may correlate with easier questions. Nearer-term events may also
be easier for analysts to predict.</p>
</blockquote>
<p><em>—Barbara A. Mellers et al., “The Value of Precision in Probability Assessment: Evidence from a Large-Scale Geopolitical Forecasting Tournament” p. 7, 2018</em></p>

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs id="MathJax_SVG_glyphs"><path stroke-width="1" id="MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path stroke-width="1" id="MJMAIN-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path stroke-width="1" id="MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="1" id="MJMAIN-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path><path stroke-width="1" id="MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path><path stroke-width="1" id="MJMAIN-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path stroke-width="1" id="MJMAIN-37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path><path stroke-width="1" id="MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="1" id="MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="1" id="MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path stroke-width="1" id="MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="1" id="MJMAIN-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path stroke-width="1" id="MJMAIN-38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path stroke-width="1" id="MJMAIN-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path stroke-width="1" id="MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="1" id="MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path stroke-width="1" id="MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path stroke-width="1" id="MJMATHI-42" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path><path stroke-width="1" id="MJMATHI-53" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path><path stroke-width="1" id="MJMATHI-4E" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path stroke-width="1" id="MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path><path stroke-width="1" id="MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="1" id="MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="1" id="MJMATHI-72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="1" id="MJMAIN-2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path><path stroke-width="1" id="MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path stroke-width="1" id="MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="1" id="MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path stroke-width="1" id="MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path><path stroke-width="1" id="MJMAIN-2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path><path stroke-width="1" id="MJMAIN-3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path><path stroke-width="1" id="MJMAIN-21D2" d="M580 514Q580 525 596 525Q601 525 604 525T609 525T613 524T615 523T617 520T619 517T622 512Q659 438 720 381T831 300T927 263Q944 258 944 250T935 239T898 228T840 204Q696 134 622 -12Q618 -21 615 -22T600 -24Q580 -24 580 -17Q580 -13 585 0Q620 69 671 123L681 133H70Q56 140 56 153Q56 168 72 173H725L735 181Q774 211 852 250Q851 251 834 259T789 283T735 319L725 327H72Q56 332 56 347Q56 360 70 367H681L671 377Q638 412 609 458T580 514Z"></path><path stroke-width="1" id="MJMAIN-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path stroke-width="1" id="MJMAIN-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path stroke-width="1" id="MJMAIN-67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path><path stroke-width="1" id="MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path><path stroke-width="1" id="MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path><path stroke-width="1" id="MJMAIN-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path stroke-width="1" id="MJMAIN-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path stroke-width="1" id="MJMAIN-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="1" id="MJMAIN-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path><path stroke-width="1" id="MJMAIN-221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path><path stroke-width="1" id="MJMATHI-3B5" d="M190 -22Q124 -22 76 11T27 107Q27 174 97 232L107 239L99 248Q76 273 76 304Q76 364 144 408T290 452H302Q360 452 405 421Q428 405 428 392Q428 381 417 369T391 356Q382 356 371 365T338 383T283 392Q217 392 167 368T116 308Q116 289 133 272Q142 263 145 262T157 264Q188 278 238 278H243Q308 278 308 247Q308 206 223 206Q177 206 142 219L132 212Q68 169 68 112Q68 39 201 39Q253 39 286 49T328 72T345 94T362 105Q376 103 376 88Q376 79 365 62T334 26T275 -8T190 -22Z"></path><path stroke-width="1" id="MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="1" id="MJMAIN-21D4" d="M308 524Q318 526 323 526Q340 526 340 514Q340 507 336 499Q326 476 314 454T292 417T274 391T260 374L255 368Q255 367 500 367Q744 367 744 368L739 374Q734 379 726 390T707 416T685 453T663 499Q658 511 658 515Q658 525 680 525Q687 524 690 523T695 519T701 507Q766 359 902 287Q921 276 939 269T961 259T966 250Q966 246 965 244T960 240T949 236T930 228T902 213Q763 137 701 -7Q697 -16 695 -19T690 -23T680 -25Q658 -25 658 -15Q658 -11 663 1Q673 24 685 46T707 83T725 109T739 126L744 132Q744 133 500 133Q255 133 255 132L260 126Q265 121 273 110T292 84T314 47T336 1Q341 -11 341 -15Q341 -25 319 -25Q312 -24 309 -23T304 -19T298 -7Q233 141 97 213Q83 221 70 227T51 235T41 239T35 243T34 250T35 256T40 261T51 265T70 273T97 287Q235 363 299 509Q305 522 308 524ZM792 319L783 327H216Q183 294 120 256L110 250L120 244Q173 212 207 181L216 173H783L792 181Q826 212 879 244L889 250L879 256Q826 288 792 319Z"></path><path stroke-width="1" id="MJMAIN-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path stroke-width="1" id="MJMAIN-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="1" id="MJMAIN-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path stroke-width="1" id="MJMAIN-70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z"></path><path stroke-width="1" id="MJMAIN-62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"></path><path stroke-width="1" id="MJMAIN-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path stroke-width="1" id="MJMAIN-63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path stroke-width="1" id="MJMAIN-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path stroke-width="1" id="MJMAIN-75" d="M383 58Q327 -10 256 -10H249Q124 -10 105 89Q104 96 103 226Q102 335 102 348T96 369Q86 385 36 385H25V408Q25 431 27 431L38 432Q48 433 67 434T105 436Q122 437 142 438T172 441T184 442H187V261Q188 77 190 64Q193 49 204 40Q224 26 264 26Q290 26 311 35T343 58T363 90T375 120T379 144Q379 145 379 161T380 201T380 248V315Q380 361 370 372T320 385H302V431Q304 431 378 436T457 442H464V264Q464 84 465 81Q468 61 479 55T524 46H542V0Q540 0 467 -5T390 -11H383V58Z"></path><path stroke-width="1" id="MJMAIN-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path stroke-width="1" id="MJMAIN-77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path stroke-width="1" id="MJMAIN-68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="1" id="MJMAIN-221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path><path stroke-width="1" id="MJMAIN-2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path><path stroke-width="1" id="MJMAIN-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path><path stroke-width="1" id="MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path stroke-width="1" id="MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMAIN-39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path><path stroke-width="1" id="MJMAIN-25" d="M465 605Q428 605 394 614T340 632T319 641Q332 608 332 548Q332 458 293 403T202 347Q145 347 101 402T56 548Q56 637 101 693T202 750Q241 750 272 719Q359 642 464 642Q580 642 650 732Q662 748 668 749Q670 750 673 750Q682 750 688 743T693 726Q178 -47 170 -52Q166 -56 160 -56Q147 -56 142 -45Q137 -36 142 -27Q143 -24 363 304Q469 462 525 546T581 630Q528 605 465 605ZM207 385Q235 385 263 427T292 548Q292 617 267 664T200 712Q193 712 186 709T167 698T147 668T134 615Q132 595 132 548V527Q132 436 165 403Q183 385 203 385H207ZM500 146Q500 234 544 290T647 347Q699 347 737 292T776 146T737 0T646 -56Q590 -56 545 0T500 146ZM651 -18Q679 -18 707 24T736 146Q736 215 711 262T644 309Q637 309 630 306T611 295T591 265T578 212Q577 200 577 146V124Q577 -18 647 -18H651Z"></path><path stroke-width="1" id="MJMAIN-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></defs></svg></body></html>