
<title>niplav</title>
<link rel="shortcut icon" type="image/png" href="./favicon.png">
<link rel="stylesheet" type="text/css" href="main.css">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<!DOCTYPE HTML>

<style TYPE="text/css">
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
</style>

<script type="text/javascript" async
	src="./mathjax/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	extensions: ["tex2jax.js"],
	jax: ["input/TeX", "output/HTML-CSS"],
	tex2jax: {
		inlineMath: [ ['$','$'], ["\\(","\\)"] ],
		displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
		processEscapes: true,
		skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
	},
	"HTML-CSS": { availableFonts: ["TeX"] }
	});
</script>

<script>
var anchorhash={}
function addAnchor(element) {
	var cnt=element.textContent
	if(cnt==="home")
		return;
	var ref=element.textContent.replace(/[^a-zA-Z0-9 ]/mg, "")
	ref=ref.replace(/ /mg, "-")
	var newref=ref;
	if(anchorhash[ref]===1)
		for(i=1, newref=ref+"_"+i;anchorhash[ref+"_"+i]===1;i++, newref=ref+"_"+i)
			;
	ref=newref
	element.setAttribute("id", `${ref}`)
	element.innerHTML=`<a href="#${ref}" class="hanchor">${cnt}</a>`
	anchorhash[ref]=1
}
document.addEventListener('DOMContentLoaded', function () {
	// Add anchor links to all headings
	var headers = document.querySelectorAll('h1, h2, h3, h4, h5, h6')
	if (headers) {
		headers.forEach(addAnchor)
	}
	// Change the title to the h1 header
	var title = document.querySelector('h1')
	if(title) {
		var title_elem = document.querySelector('title')
		title_elem.textContent=title.textContent + " â€“ niplav"
	}
});
</script>

<h2><a href="./index.html">home</a></h2>

<p><em>author: niplav, created: 2022-04-04, modified: 2022-04-04, language: english, status: notes, importance: 7, confidence: highly likely</em></p>

<blockquote>
  <p><strong>Beginnings of a research agenda about judgmental forecasting.</strong></p>
</blockquote>

<h1>Forecasters! What do they know? Do they know things? Let's find out!</h1>

<ul>
<li>How good are we at forecasting?
<ul>
<li>How good are long-term forecasts?</li>
<li>How good are our forecasts on low-probability events?</li>
<li>How quickly/slowly do our forecasts converge to the final answer? When don't they converge?</li>
<li>How do prediction markets, professional forecasting teams and internet enthusiasts compare?</li>
<li>What is a good formalization of the idea of a forecaster being accurate at a level of n%?</li>
</ul></li>
<li>How can we become better at forecasting?
<ul>
<li>What possible forecasting scoring rules could we develop?
<ul>
<li>Taking into account:
<ul>
<li>Accuracy compared to others</li>
<li>Importance of question</li>
</ul></li>
<li>That incentivize collaboration and positive-sum interactions instead of information-hiding</li>
</ul></li>
<li>Related: How can we compare the skill and reliability of forecasters to one another?
<ul>
<li>Metaculus at the moment does this by "who writes good comments". That seems inadequate.</li>
<li>Taking into account:
<ul>
<li>Number of questions each forecaster predicted on</li>
<li>Calibration</li>
<li>Resolution</li>
<li>Importance of questions</li>
</ul></li>
<li>Two boundary methods:
<ul>
<li>Compare using a scoring rule on any question the forecasters predicted on</li>
<li>Compare using a scoring rule on the intersection of the questions the forecasters predicted on</li>
</ul></li>
<li>Two functions of scoring rules: Rewarding or comparing forecasters</li>
<li>Related field: information elicitation
<ul>
<li>See also: Chapter 27 from Algorithmic Game Theory (Nisan et al. 2007)</li>
</ul></li>
</ul></li>
<li>How can we deal with questions with unclear resolution criteria?</li>
<li>How do we incentivise good predictions on long-term questions?</li>
<li>How do we incentivise good predictions on low-probability events?</li>
<li>Is there any conceivable way of incentivizing good predictions on extinction events?</li>
<li>Are better short-term forecasters also better long-term forecasters?</li>
<li>Do forecasters become better at forecasting over time?
<ul>
<li>How quickly?</li>
</ul></li>
<li>How much does forecaster quantity affect forecast quality on continuous questions? (i.e., extend <a href="https://rethinkpriorities.org/publications/how-does-forecast-quantity-impact-forecast-quality-on-metaculus">Dillon 2021</a> to continuous data)
<ul>
<li>How much does forecasting time affect forecast quality?
<ul>
<li>Generally, scaling laws for forecasting would be interesting/cool to see</li>
</ul></li>
</ul></li>
</ul></li>
<li>How difficult is it to manipulate real existing prediction markets?
<ul>
<li>PredictIt</li>
<li>BetFair</li>
</ul></li>
</ul>
</html>
