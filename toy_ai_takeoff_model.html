
<title>niplav</title>
<link rel="shortcut icon" type="image/png" href="./favicon.png">
<link rel="stylesheet" type="text/css" href="main.css">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<!DOCTYPE HTML>

<style TYPE="text/css">
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
</style>

<script type="text/javascript" async
	src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	extensions: ["tex2jax.js"],
	jax: ["input/TeX", "output/HTML-CSS"],
	tex2jax: {
		inlineMath: [ ['$','$'], ["\\(","\\)"] ],
		displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
		processEscapes: true,
		skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
	},
	"HTML-CSS": { availableFonts: ["TeX"] }
	});
</script>

<script>
var anchorhash={}
function addAnchor(element) {
	var cnt=element.textContent
	if(cnt==="home")
		return;
	var ref=element.textContent.replace(/[^a-zA-Z0-9 ]/mg, "")
	ref=ref.replace(/ /mg, "-")
	var newref=ref;
	if(anchorhash[ref]===1)
		for(i=1, newref=ref+"_"+i;anchorhash[ref+"_"+i]===1;i++, newref=ref+"_"+i)
			;
	ref=newref
	element.setAttribute("id", `${ref}`)
	element.innerHTML=`<a href="#${ref}" class="hanchor">${cnt}</a>`
	anchorhash[ref]=1
}
document.addEventListener('DOMContentLoaded', function () {
	// Add anchor links to all headings
	var headers = document.querySelectorAll('h1, h2, h3, h4, h5, h6')
	if (headers) {
		headers.forEach(addAnchor)
	}
	// Change the title to the h1 header
	var title = document.querySelector('h1')
	if(title) {
		var title_elem = document.querySelector('title')
		title_elem.textContent=title.textContent + " – niplav"
	}
});
</script>

<h2><a href="./index.html">home</a></h2>

<p><em>author: niplav, created: 2020-07-22, modified: 2020-07-26, language: english, status: draft, importance: 7, confidence: unlikely</em></p>

<blockquote>
  <p><strong>In <a href="https://en.wikipedia.org/wiki/AI_control_problem">AI safety</a>,
  significant time has been spent on the question of
  the intelligence of AI systems over time, especially during
  <a href="https://en.wikipedia.org/wiki/Technological_singularity#Hard_vs._soft_takeoff">takeoff</a>.
  An underappreciated argument in the debate has been the idea that the more
  intelligent an AI system becomes, the better it can search the space of
  possible optimization algorithms. This post proposes a computational model
  of this process by creating a search space using the <a href="https://en.wikipedia.org/wiki/Diamond-square_algorithm">diamond-square
  algorithm</a>
  generalized to n dimensions and then running a very simple
  <a href="https://en.wikipedia.org/wiki/Hill_climbing">hill-climbing</a> algorithm
  and brute-force search on that space. Possible further improvements to
  the model are suggested.</strong></p>
</blockquote>

<h1>An Exploratory Toy AI Takeoff Model</h1>

<blockquote>
  <p>Libre de la metáfora y del mito <br />
  labra un arduo cristal: el infinito <br />
  mapa de Aquel que es todas Sus estrellas.</p>
</blockquote>

<p><em>– <a href="https://en.wikipedia.org/wiki/Jorge_Luis_Borges">Jorge Luis Borges</a>, <a href="https://thefunambulist.net/literature/litterature-spinoza-by-borges">“Spinoza”</a>, 1964</em></p>

<blockquote>
  <p>Paraphrasing Roache (2008) the state of play is such that nobody
  believes the result of a simulation, except the person who performed
  the simulation, and everybody believes the result of an experiment,
  except the person who ran the experiment.</p>
</blockquote>

<p><em>– Ryan G. McClarren, “Uncertainty Quantification and Predictive Computational Science“ p. 9, 2018</em></p>

<p>(Although the quote apparently goes back to Einstein, see “The
advancement of science, and its burdens” p. 13, only there with "theory"
instead of "simulation").</p>

<!--Articles:
* https://aiimpacts.org/historical-growth-trends/
* https://aiimpacts.org/likelihood-of-discontinuous-progress-around-the-development-of-agi/
* https://intelligence.org/ai-foom-debate/
* https://intelligence.org/files/IEM.pdf
* https://longtermrisk.org/the-future-of-growth-near-zero-growth-rates/
* https://sideways-view.com/2018/02/24/takeoff-speeds/
* https://www.lesswrong.com/posts/5WECpYABCT62TJrhY/will-ai-undergo-discontinuous-progress
* https://www.lesswrong.com/posts/66FKFkWAugS8diydF/modelling-continuous-progress
* https://www.lesswrong.com/posts/77xLbXs6vYQuhT8hq/why-ai-may-not-foom
* https://www.lesswrong.com/posts/CjW4axQDqLd2oDCGG/misconceptions-about-continuous-takeoff
* https://www.lesswrong.com/posts/JBadX7rwdcRFzGuju/recursive-self-improvement
* https://www.lesswrong.com/posts/YgNYA6pj2hPSDQiTE/distinguishing-definitions-of-takeoff
* https://www.lesswrong.com/posts/cxgtQXnH2uDGBJJGa/redefining-fast-takeoff
* https://www.lesswrong.com/posts/tjH8XPxAnr6JRbh7k/hard-takeoff
-->

<!--
https://en.wikipedia.org/wiki/Brownian_surface
https://en.wikipedia.org/wiki/Fractal_landscape
https://en.wikipedia.org/wiki/Fractional_Brownian_motion
https://en.wikipedia.org/wiki/Gradient_descent
https://en.wikipedia.org/wiki/Hill_climbing
https://en.wikipedia.org/wiki/Newton%27s_method
https://en.wikipedia.org/wiki/OpenSimplex_noise
https://en.wikipedia.org/wiki/Perlin_noise
https://en.wikipedia.org/wiki/Simplex_noise
https://github.com/buckinha/DiamondSquare
https://nullprogram.com/blog/2007/11/20/
-->

<h2>Introduction</h2>

<h3>Existing Approaches</h3>

<h2>The Argument</h2>

<h2>The Model</h2>

<h3>Generating the Search Space</h3>

<h4>Desiderata for the Search Space</h4>

<h4>N-Dimensional Diamond Square</h4>

<h5>Square</h5>

<h5>Diamond</h5>

<h4>Results</h4>

<h3>Searching the Space</h3>

<h4>Hill Climbing</h4>

<h4>Brute Force Search</h4>

<h2>Results</h2>

<h3>Uniform Values</h3>

<h3>Lognormal Values</h3>

<h2>Limitations</h2>

<h2>Conclusion</h2>
